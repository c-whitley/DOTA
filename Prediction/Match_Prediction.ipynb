{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/b/Git_Projects/DOTA2Project/Stats_Data/small_dataset.pickle'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2f4822c5eb42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/mnt/b/Git_Projects/DOTA2Project/Stats_Data/small_dataset.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# 1) try standard library Pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/b/Git_Projects/DOTA2Project/Stats_Data/small_dataset.pickle'"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_pickle(\"/mnt/b/Git_Projects/DOTA2Project/Stats_Data/small_dataset.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e976a60e4d0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataset.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "eval() arg 1 must be a string, bytes or code object",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-44cf22bf4e6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: eval() arg 1 must be a string, bytes or code object"
     ]
    }
   ],
   "source": [
    "eval(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "t    3752\nf    3691\nName: Radiant_win, dtype: int64"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "dataset.reset_index()[\"Radiant_win\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Imputer\", SimpleImputer()),\n",
    "    (\"Scaler\", StandardScaler()),\n",
    "    (\"LDA\", LinearDiscriminantAnalysis(n_components=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = pipe.fit_transform(dataset.iloc[:,:-2], dataset.loc[:, \"Radiant_win\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = pd.DataFrame(transformed, index=dataset.index)\n",
    "transformed[\"Radiant_win\"] = dataset[\"Radiant_win\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"263.63625pt\" version=\"1.1\" viewBox=\"0 0 381.65 263.63625\" width=\"381.65pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 263.63625 \nL 381.65 263.63625 \nL 381.65 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 39.65 239.758125 \nL 374.45 239.758125 \nL 374.45 22.318125 \nL 39.65 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#pe3c096210b)\" d=\"M 54.868182 239.758125 \nL 54.868182 238.165158 \nL 81.862504 238.165158 \nL 81.862504 227.545378 \nL 108.856826 227.545378 \nL 108.856826 193.208088 \nL 135.851147 193.208088 \nL 135.851147 133.20633 \nL 162.845469 133.20633 \nL 162.845469 56.212924 \nL 189.839791 56.212924 \nL 189.839791 72.142594 \nL 216.834113 72.142594 \nL 216.834113 140.109187 \nL 243.828435 140.109187 \nL 243.828435 211.261715 \nL 270.822757 211.261715 \nL 270.822757 234.094242 \nL 297.817079 234.094242 \nL 297.817079 238.342154 \nL 324.8114 238.342154 \nL 324.8114 239.758125 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#pe3c096210b)\" d=\"M 73.832681 239.758125 \nL 73.832681 236.218198 \nL 102.372595 236.218198 \nL 102.372595 219.580543 \nL 130.912509 219.580543 \nL 130.912509 164.711678 \nL 159.452422 164.711678 \nL 159.452422 88.249261 \nL 187.992336 88.249261 \nL 187.992336 32.672411 \nL 216.53225 32.672411 \nL 216.53225 111.435781 \nL 245.072163 111.435781 \nL 245.072163 180.818345 \nL 273.612077 180.818345 \nL 273.612077 224.182447 \nL 302.151991 224.182447 \nL 302.151991 236.749187 \nL 330.691904 236.749187 \nL 330.691904 238.873143 \nL 359.231818 238.873143 \nL 359.231818 239.758125 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#pe3c096210b)\" d=\"M 41.563982 239.758125 \nL 41.563982 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mc2e29e360a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"41.563982\" xlink:href=\"#mc2e29e360a\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −4 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(34.192888 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#pe3c096210b)\" d=\"M 79.400774 239.758125 \nL 79.400774 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"79.400774\" xlink:href=\"#mc2e29e360a\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −3 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(72.02968 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#pe3c096210b)\" d=\"M 117.237566 239.758125 \nL 117.237566 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"117.237566\" xlink:href=\"#mc2e29e360a\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- −2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(109.866472 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#pe3c096210b)\" d=\"M 155.074358 239.758125 \nL 155.074358 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"155.074358\" xlink:href=\"#mc2e29e360a\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- −1 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(147.703264 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#pe3c096210b)\" d=\"M 192.911149 239.758125 \nL 192.911149 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"192.911149\" xlink:href=\"#mc2e29e360a\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(189.729899 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#pe3c096210b)\" d=\"M 230.747941 239.758125 \nL 230.747941 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.747941\" xlink:href=\"#mc2e29e360a\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1 -->\n      <g transform=\"translate(227.566691 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#pe3c096210b)\" d=\"M 268.584733 239.758125 \nL 268.584733 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"268.584733\" xlink:href=\"#mc2e29e360a\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 2 -->\n      <g transform=\"translate(265.403483 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#pe3c096210b)\" d=\"M 306.421525 239.758125 \nL 306.421525 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"306.421525\" xlink:href=\"#mc2e29e360a\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 3 -->\n      <g transform=\"translate(303.240275 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#pe3c096210b)\" d=\"M 344.258317 239.758125 \nL 344.258317 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"344.258317\" xlink:href=\"#mc2e29e360a\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 4 -->\n      <g transform=\"translate(341.077067 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#pe3c096210b)\" d=\"M 39.65 239.758125 \nL 374.45 239.758125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m0c095c805f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0c095c805f\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0 -->\n      <g transform=\"translate(26.2875 243.557344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#pe3c096210b)\" d=\"M 39.65 204.358858 \nL 374.45 204.358858 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0c095c805f\" y=\"204.358858\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 200 -->\n      <g transform=\"translate(13.5625 208.158076)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#pe3c096210b)\" d=\"M 39.65 168.95959 \nL 374.45 168.95959 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0c095c805f\" y=\"168.95959\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 400 -->\n      <g transform=\"translate(13.5625 172.758809)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_25\">\n      <path clip-path=\"url(#pe3c096210b)\" d=\"M 39.65 133.560323 \nL 374.45 133.560323 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0c095c805f\" y=\"133.560323\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 600 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(13.5625 137.359542)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_27\">\n      <path clip-path=\"url(#pe3c096210b)\" d=\"M 39.65 98.161055 \nL 374.45 98.161055 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0c095c805f\" y=\"98.161055\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 800 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(13.5625 101.960274)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_29\">\n      <path clip-path=\"url(#pe3c096210b)\" d=\"M 39.65 62.761788 \nL 374.45 62.761788 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_30\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0c095c805f\" y=\"62.761788\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1000 -->\n      <g transform=\"translate(7.2 66.561007)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_31\">\n      <path clip-path=\"url(#pe3c096210b)\" d=\"M 39.65 27.362521 \nL 374.45 27.362521 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_32\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m0c095c805f\" y=\"27.362521\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 1200 -->\n      <g transform=\"translate(7.2 31.161739)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 39.65 239.758125 \nL 39.65 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 374.45 239.758125 \nL 374.45 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 39.65 239.758125 \nL 374.45 239.758125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 39.65 22.318125 \nL 374.45 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_17\">\n    <!-- 0 -->\n    <g transform=\"translate(203.2325 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-48\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe3c096210b\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"39.65\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "transformed.groupby(\"Radiant_win\").hist(ax = ax, histtype=\"step\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import keras\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-2]\n",
    "y = dataset.loc[:,\"Radiant_win\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Input(shape=X.shape[1]))\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(50, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(20, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(5, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/5\n163/163 [==============================] - 1s 5ms/step - loss: 0.6944 - accuracy: 0.5035 - val_loss: 0.6938 - val_accuracy: 0.5060\nEpoch 2/5\n163/163 [==============================] - 1s 9ms/step - loss: 0.6918 - accuracy: 0.5184 - val_loss: 0.6939 - val_accuracy: 0.5007\nEpoch 3/5\n163/163 [==============================] - 1s 7ms/step - loss: 0.6906 - accuracy: 0.5265 - val_loss: 0.6948 - val_accuracy: 0.5092\nEpoch 4/5\n163/163 [==============================] - 1s 6ms/step - loss: 0.6851 - accuracy: 0.5499 - val_loss: 0.7061 - val_accuracy: 0.4908\nEpoch 5/5\n163/163 [==============================] - 1s 4ms/step - loss: 0.6782 - accuracy: 0.5726 - val_loss: 0.6995 - val_accuracy: 0.4993\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\ncross_validate(pipe, X, y, scoring=\"accuracy\", cv=5, fit_params={\"callbacks\":[tensorboard_callback]})\\n'"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y/%m/%d-%H:%M:%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"Imputer\", SimpleImputer())#,\n",
    "    #(\"Scaler\", StandardScaler()),\n",
    "    #(\"NN\", KerasClassifier(build_fn=create_model, epochs=5))\n",
    "])\n",
    "\n",
    "y_bin = np.array([1 if i==\"t\" else 0 for i in y])\n",
    "\n",
    "\n",
    "preprocessed = pd.DataFrame(pipe.fit_transform(X,y_bin), index=X.index, columns=X.columns)\n",
    "\n",
    "\n",
    "create_model().fit(x=preprocessed,\n",
    "y=y_bin,\n",
    "validation_split=0.3,\n",
    "epochs=5,\n",
    "batch_size=32,\n",
    "callbacks=[tensorboard_callback])\n",
    "\n",
    "\"\"\"\n",
    "cross_validate(pipe, X, y, scoring=\"accuracy\", cv=5, fit_params={\"callbacks\":[tensorboard_callback]})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Reusing TensorBoard on port 6006 (pid 1578), started 0:29:47 ago. (Use '!kill 1578' to kill it.)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Input(shape=X.shape[1]))\n",
    "\n",
    "    n_layers = hp.Int(\"n_layers\", min_value=5,max_value=10)\n",
    "\n",
    "    for layer_n in range(n_layers):\n",
    "\n",
    "        n_nodes = hp.Int(\"n_nodes\", min_value=5,max_value=20)\n",
    "        model.add(keras.layers.Dense(n_nodes, activation=\"relu\"))\n",
    "\n",
    "    model.add(keras.layers.Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner = kt.BayesianOptimization(create_model,\n",
    "                     objective = 'val_accuracy',\n",
    "                     max_trials = 10,\n",
    "                     #factor = 3,\n",
    "                     directory = 'my_dir',\n",
    "                     project_name = 'intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=0.3)\n",
    "\n",
    "X_train_p = pd.DataFrame(pipe.fit_transform(X_train,y_train), index=X_train.index, columns=X_train.columns)\n",
    "X_test_p = pd.DataFrame(pipe.fit_transform(X_test,y_test), index=X_test.index, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "All callbacks used during a search should be deep-copyable (since they are reused across trials). It is not possible to do `copy.deepcopy([<tensorflow.python.keras.callbacks.TensorBoard object at 0x7fbccc408730>])`",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/site-packages/kerastuner/engine/tuner.py\u001b[0m in \u001b[0;36m_deepcopy_callbacks\u001b[0;34m(self, callbacks)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    160\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreductor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                         \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreductor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle '_thread.RLock' object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-0db2cfaa0002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m tuner.search(X_train_p,\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m callbacks=[tensorboard_callback])\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/site-packages/kerastuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/site-packages/kerastuner/engine/multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexecution\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutions_per_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mcopied_fit_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deepcopy_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_tensorboard_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuner_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTunerCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/PHD/lib/python3.8/site-packages/kerastuner/engine/tuner.py\u001b[0m in \u001b[0;36m_deepcopy_callbacks\u001b[0;34m(self, callbacks)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    238\u001b[0m                 \u001b[0;34m'All callbacks used during a search '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0;34m'should be deep-copyable (since they are '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: All callbacks used during a search should be deep-copyable (since they are reused across trials). It is not possible to do `copy.deepcopy([<tensorflow.python.keras.callbacks.TensorBoard object at 0x7fbccc408730>])`"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train_p,\n",
    "y_train,\n",
    "epochs=10,\n",
    "validation_data=(X_test_p, y_test),\n",
    "callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/5\n  1/163 [..............................] - ETA: 0s - loss: 0.7159 - accuracy: 0.31  2/163 [..............................] - ETA: 10s - loss: 0.7082 - accuracy: 0.375  4/163 [..............................] - ETA: 7s - loss: 0.7007 - accuracy: 0.42 18/163 [==>...........................] - ETA: 2s - loss: 0.6951 - accuracy: 0.47 32/163 [====>.........................] - ETA: 1s - loss: 0.6950 - accuracy: 0.47 44/163 [=======>......................] - ETA: 0s - loss: 0.6946 - accuracy: 0.47 56/163 [=========>....................] - ETA: 0s - loss: 0.6942 - accuracy: 0.49 68/163 [===========>..................] - ETA: 0s - loss: 0.6941 - accuracy: 0.49 82/163 [==============>...............] - ETA: 0s - loss: 0.6937 - accuracy: 0.50 94/163 [================>.............] - ETA: 0s - loss: 0.6938 - accuracy: 0.49100/163 [=================>............] - ETA: 0s - loss: 0.6937 - accuracy: 0.49111/163 [===================>..........] - ETA: 0s - loss: 0.6937 - accuracy: 0.49119/163 [====================>.........] - ETA: 0s - loss: 0.6937 - accuracy: 0.49132/163 [=======================>......] - ETA: 0s - loss: 0.6936 - accuracy: 0.49145/163 [=========================>....] - ETA: 0s - loss: 0.6936 - accuracy: 0.49159/163 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.49162/163 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.49163/163 [==============================] - 1s 9ms/step - loss: 0.6936 - accuracy: 0.4942 - val_loss: 0.6931 - val_accuracy: 0.5002\nEpoch 2/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6915 - accuracy: 0.50  3/163 [..............................] - ETA: 3s - loss: 0.6925 - accuracy: 0.41  5/163 [..............................] - ETA: 4s - loss: 0.6927 - accuracy: 0.42  6/163 [>.............................] - ETA: 5s - loss: 0.6926 - accuracy: 0.43 11/163 [=>............................] - ETA: 3s - loss: 0.6923 - accuracy: 0.50 17/163 [==>...........................] - ETA: 2s - loss: 0.6925 - accuracy: 0.50 22/163 [===>..........................] - ETA: 2s - loss: 0.6926 - accuracy: 0.50 29/163 [====>.........................] - ETA: 1s - loss: 0.6928 - accuracy: 0.50 41/163 [======>.......................] - ETA: 1s - loss: 0.6931 - accuracy: 0.48 51/163 [========>.....................] - ETA: 1s - loss: 0.6932 - accuracy: 0.48 60/163 [==========>...................] - ETA: 0s - loss: 0.6932 - accuracy: 0.49 61/163 [==========>...................] - ETA: 1s - loss: 0.6931 - accuracy: 0.49 62/163 [==========>...................] - ETA: 1s - loss: 0.6931 - accuracy: 0.49 63/163 [==========>...................] - ETA: 1s - loss: 0.6931 - accuracy: 0.49 66/163 [===========>..................] - ETA: 1s - loss: 0.6931 - accuracy: 0.49 68/163 [===========>..................] - ETA: 1s - loss: 0.6931 - accuracy: 0.49 78/163 [=============>................] - ETA: 1s - loss: 0.6931 - accuracy: 0.49 89/163 [===============>..............] - ETA: 0s - loss: 0.6931 - accuracy: 0.49102/163 [=================>............] - ETA: 0s - loss: 0.6930 - accuracy: 0.50112/163 [===================>..........] - ETA: 0s - loss: 0.6930 - accuracy: 0.50129/163 [======================>.......] - ETA: 0s - loss: 0.6931 - accuracy: 0.50138/163 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.50147/163 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.50157/163 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.50163/163 [==============================] - 2s 10ms/step - loss: 0.6930 - accuracy: 0.5052 - val_loss: 0.6930 - val_accuracy: 0.5132\nEpoch 3/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6926 - accuracy: 0.46  5/163 [..............................] - ETA: 1s - loss: 0.6935 - accuracy: 0.48 10/163 [>.............................] - ETA: 1s - loss: 0.6925 - accuracy: 0.50 14/163 [=>............................] - ETA: 1s - loss: 0.6927 - accuracy: 0.50 17/163 [==>...........................] - ETA: 2s - loss: 0.6925 - accuracy: 0.50 18/163 [==>...........................] - ETA: 2s - loss: 0.6925 - accuracy: 0.51 19/163 [==>...........................] - ETA: 2s - loss: 0.6926 - accuracy: 0.50 21/163 [==>...........................] - ETA: 2s - loss: 0.6926 - accuracy: 0.50 24/163 [===>..........................] - ETA: 2s - loss: 0.6924 - accuracy: 0.51 25/163 [===>..........................] - ETA: 2s - loss: 0.6924 - accuracy: 0.51 31/163 [====>.........................] - ETA: 2s - loss: 0.6926 - accuracy: 0.51 38/163 [=====>........................] - ETA: 2s - loss: 0.6927 - accuracy: 0.51 44/163 [=======>......................] - ETA: 1s - loss: 0.6926 - accuracy: 0.51 49/163 [========>.....................] - ETA: 1s - loss: 0.6926 - accuracy: 0.51 50/163 [========>.....................] - ETA: 1s - loss: 0.6925 - accuracy: 0.52 52/163 [========>.....................] - ETA: 1s - loss: 0.6926 - accuracy: 0.51 53/163 [========>.....................] - ETA: 1s - loss: 0.6926 - accuracy: 0.51 64/163 [==========>...................] - ETA: 1s - loss: 0.6929 - accuracy: 0.50 76/163 [============>.................] - ETA: 1s - loss: 0.6930 - accuracy: 0.50 87/163 [===============>..............] - ETA: 0s - loss: 0.6929 - accuracy: 0.50 99/163 [=================>............] - ETA: 0s - loss: 0.6929 - accuracy: 0.50110/163 [===================>..........] - ETA: 0s - loss: 0.6929 - accuracy: 0.50118/163 [====================>.........] - ETA: 0s - loss: 0.6929 - accuracy: 0.50128/163 [======================>.......] - ETA: 0s - loss: 0.6929 - accuracy: 0.50135/163 [=======================>......] - ETA: 0s - loss: 0.6929 - accuracy: 0.50151/163 [==========================>...] - ETA: 0s - loss: 0.6929 - accuracy: 0.51161/163 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.50163/163 [==============================] - 2s 10ms/step - loss: 0.6929 - accuracy: 0.5079 - val_loss: 0.6932 - val_accuracy: 0.5074\nEpoch 4/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6851 - accuracy: 0.53 12/163 [=>............................] - ETA: 0s - loss: 0.6885 - accuracy: 0.51 13/163 [=>............................] - ETA: 1s - loss: 0.6896 - accuracy: 0.50 26/163 [===>..........................] - ETA: 0s - loss: 0.6924 - accuracy: 0.50 34/163 [=====>........................] - ETA: 0s - loss: 0.6925 - accuracy: 0.50 45/163 [=======>......................] - ETA: 0s - loss: 0.6917 - accuracy: 0.51 56/163 [=========>....................] - ETA: 0s - loss: 0.6915 - accuracy: 0.51 71/163 [============>.................] - ETA: 0s - loss: 0.6913 - accuracy: 0.51 84/163 [==============>...............] - ETA: 0s - loss: 0.6916 - accuracy: 0.51 86/163 [==============>...............] - ETA: 0s - loss: 0.6916 - accuracy: 0.51 87/163 [===============>..............] - ETA: 0s - loss: 0.6916 - accuracy: 0.51101/163 [=================>............] - ETA: 0s - loss: 0.6919 - accuracy: 0.50116/163 [====================>.........] - ETA: 0s - loss: 0.6922 - accuracy: 0.50129/163 [======================>.......] - ETA: 0s - loss: 0.6922 - accuracy: 0.50139/163 [========================>.....] - ETA: 0s - loss: 0.6923 - accuracy: 0.50145/163 [=========================>....] - ETA: 0s - loss: 0.6924 - accuracy: 0.50156/163 [===========================>..] - ETA: 0s - loss: 0.6923 - accuracy: 0.50158/163 [============================>.] - ETA: 0s - loss: 0.6923 - accuracy: 0.50160/163 [============================>.] - ETA: 0s - loss: 0.6923 - accuracy: 0.50163/163 [==============================] - 1s 7ms/step - loss: 0.6923 - accuracy: 0.5058 - val_loss: 0.6930 - val_accuracy: 0.5087\nEpoch 5/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6917 - accuracy: 0.56 14/163 [=>............................] - ETA: 0s - loss: 0.6928 - accuracy: 0.50 26/163 [===>..........................] - ETA: 0s - loss: 0.6930 - accuracy: 0.50 43/163 [======>.......................] - ETA: 0s - loss: 0.6926 - accuracy: 0.51 58/163 [=========>....................] - ETA: 0s - loss: 0.6925 - accuracy: 0.51 71/163 [============>.................] - ETA: 0s - loss: 0.6915 - accuracy: 0.51 80/163 [=============>................] - ETA: 0s - loss: 0.6916 - accuracy: 0.51 94/163 [================>.............] - ETA: 0s - loss: 0.6917 - accuracy: 0.51107/163 [==================>...........] - ETA: 0s - loss: 0.6917 - accuracy: 0.52118/163 [====================>.........] - ETA: 0s - loss: 0.6917 - accuracy: 0.52131/163 [=======================>......] - ETA: 0s - loss: 0.6915 - accuracy: 0.52143/163 [=========================>....] - ETA: 0s - loss: 0.6916 - accuracy: 0.52144/163 [=========================>....] - ETA: 0s - loss: 0.6916 - accuracy: 0.52149/163 [==========================>...] - ETA: 0s - loss: 0.6918 - accuracy: 0.51163/163 [==============================] - 1s 5ms/step - loss: 0.6917 - accuracy: 0.5213 - val_loss: 0.6931 - val_accuracy: 0.5110\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: f1f9372e42f6a6c14d496fa12ad04c10</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.5132109522819519</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-n_layers: 5</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-n_nodes: 6</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " loss: 0.6939 - accuracy: 0.49143/163 [=========================>....] - ETA: 0s - loss: 0.6936 - accuracy: 0.50151/163 [==========================>...] - ETA: 0s - loss: 0.6935 - accuracy: 0.50155/163 [===========================>..] - ETA: 0s - loss: 0.6934 - accuracy: 0.50158/163 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.50161/163 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.50163/163 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.50163/163 [==============================] - 2s 15ms/step - loss: 0.6934 - accuracy: 0.5079 - val_loss: 0.6933 - val_accuracy: 0.4980\nEpoch 2/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6910 - accuracy: 0.62 10/163 [>.............................] - ETA: 0s - loss: 0.6897 - accuracy: 0.55 21/163 [==>...........................] - ETA: 0s - loss: 0.6912 - accuracy: 0.52 24/163 [===>..........................] - ETA: 0s - loss: 0.6915 - accuracy: 0.52 25/163 [===>..........................] - ETA: 1s - loss: 0.6911 - accuracy: 0.53 29/163 [====>.........................] - ETA: 1s - loss: 0.6915 - accuracy: 0.52 36/163 [=====>........................] - ETA: 1s - loss: 0.6927 - accuracy: 0.51 44/163 [=======>......................] - ETA: 1s - loss: 0.6924 - accuracy: 0.51 46/163 [=======>......................] - ETA: 1s - loss: 0.6923 - accuracy: 0.52 49/163 [========>.....................] - ETA: 1s - loss: 0.6924 - accuracy: 0.51 54/163 [========>.....................] - ETA: 1s - loss: 0.6921 - accuracy: 0.52 56/163 [=========>....................] - ETA: 1s - loss: 0.6924 - accuracy: 0.52 62/163 [==========>...................] - ETA: 1s - loss: 0.6920 - accuracy: 0.52 64/163 [==========>...................] - ETA: 1s - loss: 0.6919 - accuracy: 0.52 68/163 [===========>..................] - ETA: 1s - loss: 0.6920 - accuracy: 0.52 70/163 [===========>..................] - ETA: 1s - loss: 0.6919 - accuracy: 0.52 71/163 [============>.................] - ETA: 1s - loss: 0.6919 - accuracy: 0.52 77/163 [=============>................] - ETA: 1s - loss: 0.6914 - accuracy: 0.52 82/163 [==============>...............] - ETA: 1s - loss: 0.6917 - accuracy: 0.52 86/163 [==============>...............] - ETA: 0s - loss: 0.6918 - accuracy: 0.52 90/163 [===============>..............] - ETA: 0s - loss: 0.6917 - accuracy: 0.52 95/163 [================>.............] - ETA: 0s - loss: 0.6918 - accuracy: 0.52100/163 [=================>............] - ETA: 0s - loss: 0.6919 - accuracy: 0.52106/163 [==================>...........] - ETA: 0s - loss: 0.6918 - accuracy: 0.52107/163 [==================>...........] - ETA: 0s - loss: 0.6918 - accuracy: 0.52111/163 [===================>..........] - ETA: 0s - loss: 0.6918 - accuracy: 0.52113/163 [===================>..........] - ETA: 0s - loss: 0.6917 - accuracy: 0.52114/163 [===================>..........] - ETA: 0s - loss: 0.6916 - accuracy: 0.52119/163 [====================>.........] - ETA: 0s - loss: 0.6916 - accuracy: 0.52122/163 [=====================>........] - ETA: 0s - loss: 0.6915 - accuracy: 0.52129/163 [======================>.......] - ETA: 0s - loss: 0.6915 - accuracy: 0.52131/163 [=======================>......] - ETA: 0s - loss: 0.6914 - accuracy: 0.52133/163 [=======================>......] - ETA: 0s - loss: 0.6914 - accuracy: 0.52136/163 [========================>.....] - ETA: 0s - loss: 0.6915 - accuracy: 0.52139/163 [========================>.....] - ETA: 0s - loss: 0.6916 - accuracy: 0.52141/163 [========================>.....] - ETA: 0s - loss: 0.6915 - accuracy: 0.52145/163 [=========================>....] - ETA: 0s - loss: 0.6915 - accuracy: 0.52148/163 [==========================>...] - ETA: 0s - loss: 0.6915 - accuracy: 0.52149/163 [==========================>...] - ETA: 0s - loss: 0.6915 - accuracy: 0.52151/163 [==========================>...] - ETA: 0s - loss: 0.6915 - accuracy: 0.52159/163 [============================>.] - ETA: 0s - loss: 0.6909 - accuracy: 0.52162/163 [============================>.] - ETA: 0s - loss: 0.6911 - accuracy: 0.52163/163 [==============================] - 3s 16ms/step - loss: 0.6913 - accuracy: 0.5257 - val_loss: 0.6990 - val_accuracy: 0.4966\nEpoch 3/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6800 - accuracy: 0.65  4/163 [..............................] - ETA: 2s - loss: 0.6978 - accuracy: 0.50 10/163 [>.............................] - ETA: 1s - loss: 0.6890 - accuracy: 0.52 19/163 [==>...........................] - ETA: 1s - loss: 0.6878 - accuracy: 0.53 21/163 [==>...........................] - ETA: 1s - loss: 0.6888 - accuracy: 0.53 22/163 [===>..........................] - ETA: 1s - loss: 0.6891 - accuracy: 0.53 28/163 [====>.........................] - ETA: 1s - loss: 0.6891 - accuracy: 0.53 34/163 [=====>........................] - ETA: 1s - loss: 0.6890 - accuracy: 0.54 39/163 [======>.......................] - ETA: 1s - loss: 0.6889 - accuracy: 0.53 46/163 [=======>......................] - ETA: 1s - loss: 0.6886 - accuracy: 0.54 53/163 [========>.....................] - ETA: 1s - loss: 0.6890 - accuracy: 0.53 55/163 [=========>....................] - ETA: 1s - loss: 0.6893 - accuracy: 0.53 60/163 [==========>...................] - ETA: 1s - loss: 0.6887 - accuracy: 0.53 67/163 [===========>..................] - ETA: 1s - loss: 0.6880 - accuracy: 0.53 72/163 [============>.................] - ETA: 0s - loss: 0.6897 - accuracy: 0.53 78/163 [=============>................] - ETA: 0s - loss: 0.6900 - accuracy: 0.53 80/163 [=============>................] - ETA: 0s - loss: 0.6901 - accuracy: 0.53 81/163 [=============>................] - ETA: 0s - loss: 0.6901 - accuracy: 0.53 83/163 [==============>...............] - ETA: 0s - loss: 0.6900 - accuracy: 0.53 87/163 [===============>..............] - ETA: 0s - loss: 0.6899 - accuracy: 0.53 92/163 [===============>..............] - ETA: 0s - loss: 0.6901 - accuracy: 0.53 96/163 [================>.............] - ETA: 0s - loss: 0.6901 - accuracy: 0.53102/163 [=================>............] - ETA: 0s - loss: 0.6902 - accuracy: 0.53104/163 [==================>...........] - ETA: 0s - loss: 0.6902 - accuracy: 0.53105/163 [==================>...........] - ETA: 0s - loss: 0.6902 - accuracy: 0.53106/163 [==================>...........] - ETA: 0s - loss: 0.6902 - accuracy: 0.53110/163 [===================>..........] - ETA: 0s - loss: 0.6901 - accuracy: 0.53113/163 [===================>..........] - ETA: 0s - loss: 0.6899 - accuracy: 0.53115/163 [====================>.........] - ETA: 0s - loss: 0.6896 - accuracy: 0.54117/163 [====================>.........] - ETA: 0s - loss: 0.6897 - accuracy: 0.54119/163 [====================>.........] - ETA: 0s - loss: 0.6897 - accuracy: 0.54124/163 [=====================>........] - ETA: 0s - loss: 0.6897 - accuracy: 0.53126/163 [======================>.......] - ETA: 0s - loss: 0.6897 - accuracy: 0.53127/163 [======================>.......] - ETA: 0s - loss: 0.6897 - accuracy: 0.53128/163 [======================>.......] - ETA: 0s - loss: 0.6896 - accuracy: 0.53129/163 [======================>.......] - ETA: 0s - loss: 0.6898 - accuracy: 0.53132/163 [=======================>......] - ETA: 0s - loss: 0.6899 - accuracy: 0.53133/163 [=======================>......] - ETA: 0s - loss: 0.6899 - accuracy: 0.53134/163 [=======================>......] - ETA: 0s - loss: 0.6899 - accuracy: 0.53136/163 [========================>.....] - ETA: 0s - loss: 0.6898 - accuracy: 0.53139/163 [========================>.....] - ETA: 0s - loss: 0.6897 - accuracy: 0.53141/163 [========================>.....] - ETA: 0s - loss: 0.6896 - accuracy: 0.53143/163 [=========================>....] - ETA: 0s - loss: 0.6895 - accuracy: 0.54145/163 [=========================>....] - ETA: 0s - loss: 0.6894 - accuracy: 0.54147/163 [==========================>...] - ETA: 0s - loss: 0.6894 - accuracy: 0.54148/163 [==========================>...] - ETA: 0s - loss: 0.6895 - accuracy: 0.54150/163 [==========================>...] - ETA: 0s - loss: 0.6895 - accuracy: 0.54151/163 [==========================>...] - ETA: 0s - loss: 0.6895 - accuracy: 0.54152/163 [==========================>...] - ETA: 0s - loss: 0.6896 - accuracy: 0.54153/163 [===========================>..] - ETA: 0s - loss: 0.6897 - accuracy: 0.54154/163 [===========================>..] - ETA: 0s - loss: 0.6895 - accuracy: 0.54155/163 [===========================>..] - ETA: 0s - loss: 0.6895 - accuracy: 0.54156/163 [===========================>..] - ETA: 0s - loss: 0.6895 - accuracy: 0.54162/163 [============================>.] - ETA: 0s - loss: 0.6897 - accuracy: 0.53163/163 [==============================] - ETA: 0s - loss: 0.6896 - accuracy: 0.53163/163 [==============================] - 3s 21ms/step - loss: 0.6896 - accuracy: 0.5392 - val_loss: 0.6935 - val_accuracy: 0.5123\nEpoch 4/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6861 - accuracy: 0.56  5/163 [..............................] - ETA: 1s - loss: 0.6839 - accuracy: 0.56  8/163 [>.............................] - ETA: 2s - loss: 0.6865 - accuracy: 0.55 11/163 [=>............................] - ETA: 2s - loss: 0.6835 - accuracy: 0.57 16/163 [=>............................] - ETA: 2s - loss: 0.6830 - accuracy: 0.58 24/163 [===>..........................] - ETA: 1s - loss: 0.6854 - accuracy: 0.56 29/163 [====>.........................] - ETA: 1s - loss: 0.6844 - accuracy: 0.56 36/163 [=====>........................] - ETA: 1s - loss: 0.6838 - accuracy: 0.56 37/163 [=====>........................] - ETA: 1s - loss: 0.6833 - accuracy: 0.56 42/163 [======>.......................] - ETA: 1s - loss: 0.6831 - accuracy: 0.56 45/163 [=======>......................] - ETA: 1s - loss: 0.6837 - accuracy: 0.56 46/163 [=======>......................] - ETA: 1s - loss: 0.6834 - accuracy: 0.56 48/163 [=======>......................] - ETA: 1s - loss: 0.6835 - accuracy: 0.56 55/163 [=========>....................] - ETA: 1s - loss: 0.6824 - accuracy: 0.56 60/163 [==========>...................] - ETA: 1s - loss: 0.6830 - accuracy: 0.56 68/163 [===========>..................] - ETA: 1s - loss: 0.6837 - accuracy: 0.56 76/163 [============>.................] - ETA: 1s - loss: 0.6848 - accuracy: 0.55 82/163 [==============>...............] - ETA: 0s - loss: 0.6852 - accuracy: 0.55 85/163 [==============>...............] - ETA: 0s - loss: 0.6849 - accuracy: 0.55 86/163 [==============>...............] - ETA: 0s - loss: 0.6849 - accuracy: 0.55 91/163 [===============>..............] - ETA: 0s - loss: 0.6850 - accuracy: 0.55 92/163 [===============>..............] - ETA: 0s - loss: 0.6854 - accuracy: 0.55 94/163 [================>.............] - ETA: 0s - loss: 0.6852 - accuracy: 0.55 97/163 [================>.............] - ETA: 0s - loss: 0.6852 - accuracy: 0.55100/163 [=================>............] - ETA: 0s - loss: 0.6853 - accuracy: 0.55103/163 [=================>............] - ETA: 0s - loss: 0.6854 - accuracy: 0.55105/163 [==================>...........] - ETA: 0s - loss: 0.6849 - accuracy: 0.55108/163 [==================>...........] - ETA: 0s - loss: 0.6855 - accuracy: 0.55112/163 [===================>..........] - ETA: 0s - loss: 0.6852 - accuracy: 0.55116/163 [====================>.........] - ETA: 0s - loss: 0.6855 - accuracy: 0.55120/163 [=====================>........] - ETA: 0s - loss: 0.6855 - accuracy: 0.55121/163 [=====================>........] - ETA: 0s - loss: 0.6855 - accuracy: 0.55123/163 [=====================>........] - ETA: 0s - loss: 0.6854 - accuracy: 0.54127/163 [======================>.......] - ETA: 0s - loss: 0.6855 - accuracy: 0.54129/163 [======================>.......] - ETA: 0s - loss: 0.6856 - accuracy: 0.54131/163 [=======================>......] - ETA: 0s - loss: 0.6857 - accuracy: 0.54132/163 [=======================>......] - ETA: 0s - loss: 0.6858 - accuracy: 0.54133/163 [=======================>......] - ETA: 0s - loss: 0.6857 - accuracy: 0.54138/163 [========================>.....] - ETA: 0s - loss: 0.6858 - accuracy: 0.54141/163 [========================>.....] - ETA: 0s - loss: 0.6861 - accuracy: 0.54144/163 [=========================>....] - ETA: 0s - loss: 0.6861 - accuracy: 0.54147/163 [==========================>...] - ETA: 0s - loss: 0.6863 - accuracy: 0.54151/163 [==========================>...] - ETA: 0s - loss: 0.6867 - accuracy: 0.54154/163 [===========================>..] - ETA: 0s - loss: 0.6866 - accuracy: 0.54157/163 [===========================>..] - ETA: 0s - loss: 0.6866 - accuracy: 0.54160/163 [============================>.] - ETA: 0s - loss: 0.6868 - accuracy: 0.54161/163 [============================>.] - ETA: 0s - loss: 0.6869 - accuracy: 0.54162/163 [============================>.] - ETA: 0s - loss: 0.6870 - accuracy: 0.54163/163 [==============================] - 3s 18ms/step - loss: 0.6870 - accuracy: 0.5455 - val_loss: 0.6934 - val_accuracy: 0.5181\nEpoch 5/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6524 - accuracy: 0.68  4/163 [..............................] - ETA: 2s - loss: 0.6779 - accuracy: 0.58  6/163 [>.............................] - ETA: 3s - loss: 0.6776 - accuracy: 0.57  8/163 [>.............................] - ETA: 3s - loss: 0.6791 - accuracy: 0.58 11/163 [=>............................] - ETA: 3s - loss: 0.6826 - accuracy: 0.57 15/163 [=>............................] - ETA: 2s - loss: 0.6816 - accuracy: 0.57 17/163 [==>...........................] - ETA: 2s - loss: 0.6808 - accuracy: 0.58 19/163 [==>...........................] - ETA: 3s - loss: 0.6806 - accuracy: 0.58 20/163 [==>...........................] - ETA: 3s - loss: 0.6805 - accuracy: 0.58 21/163 [==>...........................] - ETA: 3s - loss: 0.6814 - accuracy: 0.57 27/163 [===>..........................] - ETA: 2s - loss: 0.6840 - accuracy: 0.56 28/163 [====>.........................] - ETA: 3s - loss: 0.6846 - accuracy: 0.56 31/163 [====>.........................] - ETA: 2s - loss: 0.6853 - accuracy: 0.55 32/163 [====>.........................] - ETA: 3s - loss: 0.6858 - accuracy: 0.55 33/163 [=====>........................] - ETA: 3s - loss: 0.6859 - accuracy: 0.55 35/163 [=====>........................] - ETA: 3s - loss: 0.6866 - accuracy: 0.54 36/163 [=====>........................] - ETA: 3s - loss: 0.6875 - accuracy: 0.54 38/163 [=====>........................] - ETA: 3s - loss: 0.6876 - accuracy: 0.54 39/163 [======>.......................] - ETA: 3s - loss: 0.6871 - accuracy: 0.54 42/163 [======>.......................] - ETA: 3s - loss: 0.6870 - accuracy: 0.54 43/163 [======>.......................] - ETA: 3s - loss: 0.6864 - accuracy: 0.55 51/163 [========>.....................] - ETA: 2s - loss: 0.6870 - accuracy: 0.54 53/163 [========>.....................] - ETA: 2s - loss: 0.6869 - accuracy: 0.54 55/163 [=========>....................] - ETA: 2s - loss: 0.6868 - accuracy: 0.54 58/163 [=========>....................] - ETA: 2s - loss: 0.6869 - accuracy: 0.54 59/163 [=========>....................] - ETA: 2s - loss: 0.6866 - accuracy: 0.55 62/163 [==========>...................] - ETA: 2s - loss: 0.6859 - accuracy: 0.55 66/163 [===========>..................] - ETA: 2s - loss: 0.6853 - accuracy: 0.55 69/163 [===========>..................] - ETA: 2s - loss: 0.6854 - accuracy: 0.55 71/163 [============>.................] - ETA: 2s - loss: 0.6849 - accuracy: 0.55 76/163 [============>.................] - ETA: 2s - loss: 0.6857 - accuracy: 0.55 77/163 [=============>................] - ETA: 2s - loss: 0.6856 - accuracy: 0.55 78/163 [=============>................] - ETA: 2s - loss: 0.6858 - accuracy: 0.55 80/163 [=============>................] - ETA: 2s - loss: 0.6855 - accuracy: 0.55 83/163 [==============>...............] - ETA: 1s - loss: 0.6855 - accuracy: 0.55 84/163 [==============>...............] - ETA: 1s - loss: 0.6856 - accuracy: 0.55 86/163 [==============>...............] - ETA: 1s - loss: 0.6850 - accuracy: 0.55 87/163 [===============>..............] - ETA: 1s - loss: 0.6853 - accuracy: 0.55 90/163 [===============>..............] - ETA: 1s - loss: 0.6850 - accuracy: 0.55 94/163 [================>.............] - ETA: 1s - loss: 0.6853 - accuracy: 0.55 95/163 [================>.............] - ETA: 1s - loss: 0.6853 - accuracy: 0.55 96/163 [================>.............] - ETA: 1s - loss: 0.6855 - accuracy: 0.55 98/163 [=================>............] - ETA: 1s - loss: 0.6853 - accuracy: 0.55102/163 [=================>............] - ETA: 1s - loss: 0.6852 - accuracy: 0.55103/163 [=================>............] - ETA: 1s - loss: 0.6853 - accuracy: 0.55104/163 [==================>...........] - ETA: 1s - loss: 0.6853 - accuracy: 0.55105/163 [==================>...........] - ETA: 1s - loss: 0.6854 - accuracy: 0.55106/163 [==================>...........] - ETA: 1s - loss: 0.6857 - accuracy: 0.55107/163 [==================>...........] - ETA: 1s - loss: 0.6857 - accuracy: 0.55108/163 [==================>...........] - ETA: 1s - loss: 0.6856 - accuracy: 0.55111/163 [===================>..........] - ETA: 1s - loss: 0.6853 - accuracy: 0.55119/163 [====================>.........] - ETA: 1s - loss: 0.6856 - accuracy: 0.55122/163 [=====================>........] - ETA: 1s - loss: 0.6851 - accuracy: 0.55124/163 [=====================>........] - ETA: 1s - loss: 0.6849 - accuracy: 0.55125/163 [======================>.......] - ETA: 1s - loss: 0.6851 - accuracy: 0.55126/163 [======================>.......] - ETA: 1s - loss: 0.6849 - accuracy: 0.55127/163 [======================>.......] - ETA: 1s - loss: 0.6850 - accuracy: 0.55128/163 [======================>.......] - ETA: 1s - loss: 0.6850 - accuracy: 0.55129/163 [======================>.......] - ETA: 1s - loss: 0.6848 - accuracy: 0.55130/163 [======================>.......] - ETA: 1s - loss: 0.6848 - accuracy: 0.55132/163 [=======================>......] - ETA: 0s - loss: 0.6851 - accuracy: 0.55133/163 [=======================>......] - ETA: 0s - loss: 0.6853 - accuracy: 0.55134/163 [=======================>......] - ETA: 0s - loss: 0.6851 - accuracy: 0.55135/163 [=======================>......] - ETA: 0s - loss: 0.6850 - accuracy: 0.55136/163 [========================>.....] - ETA: 0s - loss: 0.6851 - accuracy: 0.55137/163 [========================>.....] - ETA: 0s - loss: 0.6850 - accuracy: 0.55138/163 [========================>.....] - ETA: 0s - loss: 0.6851 - accuracy: 0.55140/163 [========================>.....] - ETA: 0s - loss: 0.6850 - accuracy: 0.55141/163 [========================>.....] - ETA: 0s - loss: 0.6852 - accuracy: 0.55142/163 [=========================>....] - ETA: 0s - loss: 0.6852 - accuracy: 0.55143/163 [=========================>....] - ETA: 0s - loss: 0.6850 - accuracy: 0.55144/163 [=========================>....] - ETA: 0s - loss: 0.6850 - accuracy: 0.55145/163 [=========================>....] - ETA: 0s - loss: 0.6851 - accuracy: 0.55147/163 [==========================>...] - ETA: 0s - loss: 0.6852 - accuracy: 0.55149/163 [==========================>...] - ETA: 0s - loss: 0.6851 - accuracy: 0.55150/163 [==========================>...] - ETA: 0s - loss: 0.6851 - accuracy: 0.55153/163 [===========================>..] - ETA: 0s - loss: 0.6848 - accuracy: 0.55155/163 [===========================>..] - ETA: 0s - loss: 0.6849 - accuracy: 0.55156/163 [===========================>..] - ETA: 0s - loss: 0.6850 - accuracy: 0.55157/163 [===========================>..] - ETA: 0s - loss: 0.6850 - accuracy: 0.55159/163 [============================>.] - ETA: 0s - loss: 0.6850 - accuracy: 0.55160/163 [============================>.] - ETA: 0s - loss: 0.6850 - accuracy: 0.55162/163 [============================>.] - ETA: 0s - loss: 0.6850 - accuracy: 0.55163/163 [==============================] - ETA: 0s - loss: 0.6850 - accuracy: 0.55163/163 [==============================] - 6s 37ms/step - loss: 0.6850 - accuracy: 0.5534 - val_loss: 0.6980 - val_accuracy: 0.5002\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: b2fb32b9318b38db7f81a966f4d915e8</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.5181370377540588</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-n_layers: 5</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-n_nodes: 9</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cy: 0.51 20/163 [==>...........................] - ETA: 4s - loss: 0.6931 - accuracy: 0.51 21/163 [==>...........................] - ETA: 4s - loss: 0.6930 - accuracy: 0.51 22/163 [===>..........................] - ETA: 4s - loss: 0.6930 - accuracy: 0.51 24/163 [===>..........................] - ETA: 4s - loss: 0.6930 - accuracy: 0.52 27/163 [===>..........................] - ETA: 4s - loss: 0.6930 - accuracy: 0.51 30/163 [====>.........................] - ETA: 4s - loss: 0.6930 - accuracy: 0.51 31/163 [====>.........................] - ETA: 4s - loss: 0.6930 - accuracy: 0.52 32/163 [====>.........................] - ETA: 4s - loss: 0.6930 - accuracy: 0.52 33/163 [=====>........................] - ETA: 5s - loss: 0.6930 - accuracy: 0.51 36/163 [=====>........................] - ETA: 4s - loss: 0.6931 - accuracy: 0.51 40/163 [======>.......................] - ETA: 4s - loss: 0.6931 - accuracy: 0.51 43/163 [======>.......................] - ETA: 4s - loss: 0.6931 - accuracy: 0.51 45/163 [=======>......................] - ETA: 4s - loss: 0.6931 - accuracy: 0.51 47/163 [=======>......................] - ETA: 4s - loss: 0.6931 - accuracy: 0.51 48/163 [=======>......................] - ETA: 4s - loss: 0.6931 - accuracy: 0.51 50/163 [========>.....................] - ETA: 4s - loss: 0.6931 - accuracy: 0.51 51/163 [========>.....................] - ETA: 4s - loss: 0.6931 - accuracy: 0.51 52/163 [========>.....................] - ETA: 4s - loss: 0.6931 - accuracy: 0.51 53/163 [========>.....................] - ETA: 4s - loss: 0.6931 - accuracy: 0.51 54/163 [========>.....................] - ETA: 4s - loss: 0.6931 - accuracy: 0.51 58/163 [=========>....................] - ETA: 4s - loss: 0.6931 - accuracy: 0.51 59/163 [=========>....................] - ETA: 4s - loss: 0.6931 - accuracy: 0.51 61/163 [==========>...................] - ETA: 4s - loss: 0.6931 - accuracy: 0.50 62/163 [==========>...................] - ETA: 4s - loss: 0.6931 - accuracy: 0.50 65/163 [==========>...................] - ETA: 4s - loss: 0.6931 - accuracy: 0.51 68/163 [===========>..................] - ETA: 3s - loss: 0.6931 - accuracy: 0.51 69/163 [===========>..................] - ETA: 3s - loss: 0.6931 - accuracy: 0.51 70/163 [===========>..................] - ETA: 3s - loss: 0.6931 - accuracy: 0.50 72/163 [============>.................] - ETA: 3s - loss: 0.6931 - accuracy: 0.51 73/163 [============>.................] - ETA: 3s - loss: 0.6931 - accuracy: 0.50 78/163 [=============>................] - ETA: 3s - loss: 0.6931 - accuracy: 0.51 82/163 [==============>...............] - ETA: 3s - loss: 0.6930 - accuracy: 0.51 89/163 [===============>..............] - ETA: 2s - loss: 0.6930 - accuracy: 0.51 95/163 [================>.............] - ETA: 2s - loss: 0.6930 - accuracy: 0.51 98/163 [=================>............] - ETA: 2s - loss: 0.6931 - accuracy: 0.51104/163 [==================>...........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50108/163 [==================>...........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50110/163 [===================>..........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50111/163 [===================>..........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50114/163 [===================>..........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50116/163 [====================>.........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50124/163 [=====================>........] - ETA: 1s - loss: 0.6932 - accuracy: 0.50130/163 [======================>.......] - ETA: 0s - loss: 0.6932 - accuracy: 0.50133/163 [=======================>......] - ETA: 0s - loss: 0.6932 - accuracy: 0.50139/163 [========================>.....] - ETA: 0s - loss: 0.6932 - accuracy: 0.49142/163 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.49143/163 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.49144/163 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.49146/163 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.50148/163 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.50151/163 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.50153/163 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.50154/163 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.50157/163 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.50160/163 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.50162/163 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.50163/163 [==============================] - 5s 32ms/step - loss: 0.6932 - accuracy: 0.5035 - val_loss: 0.6931 - val_accuracy: 0.5056\nEpoch 3/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6944 - accuracy: 0.31  3/163 [..............................] - ETA: 3s - loss: 0.6933 - accuracy: 0.47  5/163 [..............................] - ETA: 5s - loss: 0.6933 - accuracy: 0.47 10/163 [>.............................] - ETA: 3s - loss: 0.6933 - accuracy: 0.47 12/163 [=>............................] - ETA: 3s - loss: 0.6933 - accuracy: 0.47 13/163 [=>............................] - ETA: 4s - loss: 0.6933 - accuracy: 0.47 19/163 [==>...........................] - ETA: 3s - loss: 0.6933 - accuracy: 0.47 21/163 [==>...........................] - ETA: 3s - loss: 0.6933 - accuracy: 0.47 28/163 [====>.........................] - ETA: 2s - loss: 0.6933 - accuracy: 0.47 33/163 [=====>........................] - ETA: 2s - loss: 0.6932 - accuracy: 0.48 40/163 [======>.......................] - ETA: 2s - loss: 0.6932 - accuracy: 0.49 45/163 [=======>......................] - ETA: 1s - loss: 0.6932 - accuracy: 0.49 49/163 [========>.....................] - ETA: 1s - loss: 0.6932 - accuracy: 0.49 55/163 [=========>....................] - ETA: 1s - loss: 0.6932 - accuracy: 0.50 57/163 [=========>....................] - ETA: 1s - loss: 0.6932 - accuracy: 0.50 59/163 [=========>....................] - ETA: 1s - loss: 0.6932 - accuracy: 0.50 60/163 [==========>...................] - ETA: 1s - loss: 0.6932 - accuracy: 0.50 62/163 [==========>...................] - ETA: 1s - loss: 0.6932 - accuracy: 0.50 66/163 [===========>..................] - ETA: 1s - loss: 0.6932 - accuracy: 0.49 68/163 [===========>..................] - ETA: 1s - loss: 0.6932 - accuracy: 0.49 74/163 [============>.................] - ETA: 1s - loss: 0.6932 - accuracy: 0.49 80/163 [=============>................] - ETA: 1s - loss: 0.6932 - accuracy: 0.49 82/163 [==============>...............] - ETA: 1s - loss: 0.6932 - accuracy: 0.49 83/163 [==============>...............] - ETA: 1s - loss: 0.6932 - accuracy: 0.49 84/163 [==============>...............] - ETA: 1s - loss: 0.6932 - accuracy: 0.49 88/163 [===============>..............] - ETA: 1s - loss: 0.6932 - accuracy: 0.49 91/163 [===============>..............] - ETA: 1s - loss: 0.6932 - accuracy: 0.49 95/163 [================>.............] - ETA: 1s - loss: 0.6932 - accuracy: 0.49 97/163 [================>.............] - ETA: 1s - loss: 0.6932 - accuracy: 0.49103/163 [=================>............] - ETA: 1s - loss: 0.6932 - accuracy: 0.49104/163 [==================>...........] - ETA: 1s - loss: 0.6932 - accuracy: 0.49107/163 [==================>...........] - ETA: 1s - loss: 0.6932 - accuracy: 0.49109/163 [===================>..........] - ETA: 0s - loss: 0.6932 - accuracy: 0.49113/163 [===================>..........] - ETA: 0s - loss: 0.6932 - accuracy: 0.49115/163 [====================>.........] - ETA: 0s - loss: 0.6932 - accuracy: 0.49118/163 [====================>.........] - ETA: 0s - loss: 0.6932 - accuracy: 0.49120/163 [=====================>........] - ETA: 0s - loss: 0.6932 - accuracy: 0.49124/163 [=====================>........] - ETA: 0s - loss: 0.6932 - accuracy: 0.49125/163 [======================>.......] - ETA: 0s - loss: 0.6932 - accuracy: 0.49128/163 [======================>.......] - ETA: 0s - loss: 0.6932 - accuracy: 0.49130/163 [======================>.......] - ETA: 0s - loss: 0.6932 - accuracy: 0.49131/163 [=======================>......] - ETA: 0s - loss: 0.6932 - accuracy: 0.49133/163 [=======================>......] - ETA: 0s - loss: 0.6932 - accuracy: 0.50137/163 [========================>.....] - ETA: 0s - loss: 0.6932 - accuracy: 0.50141/163 [========================>.....] - ETA: 0s - loss: 0.6932 - accuracy: 0.50144/163 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.50147/163 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.50151/163 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.50154/163 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.50156/163 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.50159/163 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.50161/163 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.50162/163 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.50163/163 [==============================] - 4s 22ms/step - loss: 0.6932 - accuracy: 0.5035 - val_loss: 0.6931 - val_accuracy: 0.5056\nEpoch 4/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6936 - accuracy: 0.46  2/163 [..............................] - ETA: 5s - loss: 0.6928 - accuracy: 0.53  4/163 [..............................] - ETA: 6s - loss: 0.6928 - accuracy: 0.53  6/163 [>.............................] - ETA: 6s - loss: 0.6928 - accuracy: 0.53  8/163 [>.............................] - ETA: 5s - loss: 0.6929 - accuracy: 0.52  9/163 [>.............................] - ETA: 6s - loss: 0.6930 - accuracy: 0.51 10/163 [>.............................] - ETA: 6s - loss: 0.6930 - accuracy: 0.50 12/163 [=>............................] - ETA: 6s - loss: 0.6932 - accuracy: 0.49 14/163 [=>............................] - ETA: 5s - loss: 0.6931 - accuracy: 0.50 16/163 [=>............................] - ETA: 5s - loss: 0.6933 - accuracy: 0.49 18/163 [==>...........................] - ETA: 5s - loss: 0.6932 - accuracy: 0.49 19/163 [==>...........................] - ETA: 5s - loss: 0.6933 - accuracy: 0.49 20/163 [==>...........................] - ETA: 5s - loss: 0.6933 - accuracy: 0.49 23/163 [===>..........................] - ETA: 5s - loss: 0.6934 - accuracy: 0.48 39/163 [======>.......................] - ETA: 3s - loss: 0.6933 - accuracy: 0.48 43/163 [======>.......................] - ETA: 2s - loss: 0.6933 - accuracy: 0.49 45/163 [=======>......................] - ETA: 2s - loss: 0.6933 - accuracy: 0.49 46/163 [=======>......................] - ETA: 2s - loss: 0.6933 - accuracy: 0.49 48/163 [=======>......................] - ETA: 2s - loss: 0.6933 - accuracy: 0.49 52/163 [========>.....................] - ETA: 2s - loss: 0.6932 - accuracy: 0.49 55/163 [=========>....................] - ETA: 2s - loss: 0.6933 - accuracy: 0.49 56/163 [=========>....................] - ETA: 2s - loss: 0.6933 - accuracy: 0.49 57/163 [=========>....................] - ETA: 3s - loss: 0.6932 - accuracy: 0.49 58/163 [=========>....................] - ETA: 3s - loss: 0.6932 - accuracy: 0.49 62/163 [==========>...................] - ETA: 2s - loss: 0.6932 - accuracy: 0.49 67/163 [===========>..................] - ETA: 2s - loss: 0.6932 - accuracy: 0.50 68/163 [===========>..................] - ETA: 2s - loss: 0.6932 - accuracy: 0.50 69/163 [===========>..................] - ETA: 2s - loss: 0.6932 - accuracy: 0.50 71/163 [============>.................] - ETA: 2s - loss: 0.6932 - accuracy: 0.50 73/163 [============>.................] - ETA: 2s - loss: 0.6931 - accuracy: 0.50 74/163 [============>.................] - ETA: 2s - loss: 0.6931 - accuracy: 0.50 80/163 [=============>................] - ETA: 2s - loss: 0.6932 - accuracy: 0.50 83/163 [==============>...............] - ETA: 2s - loss: 0.6932 - accuracy: 0.50 84/163 [==============>...............] - ETA: 2s - loss: 0.6932 - accuracy: 0.50 87/163 [===============>..............] - ETA: 2s - loss: 0.6932 - accuracy: 0.49 88/163 [===============>..............] - ETA: 2s - loss: 0.6933 - accuracy: 0.49 91/163 [===============>..............] - ETA: 2s - loss: 0.6932 - accuracy: 0.49 94/163 [================>.............] - ETA: 2s - loss: 0.6933 - accuracy: 0.49 95/163 [================>.............] - ETA: 2s - loss: 0.6932 - accuracy: 0.49 97/163 [================>.............] - ETA: 2s - loss: 0.6932 - accuracy: 0.50 99/163 [=================>............] - ETA: 2s - loss: 0.6932 - accuracy: 0.50100/163 [=================>............] - ETA: 2s - loss: 0.6932 - accuracy: 0.50103/163 [=================>............] - ETA: 1s - loss: 0.6932 - accuracy: 0.50104/163 [==================>...........] - ETA: 1s - loss: 0.6932 - accuracy: 0.50108/163 [==================>...........] - ETA: 1s - loss: 0.6932 - accuracy: 0.50111/163 [===================>..........] - ETA: 1s - loss: 0.6932 - accuracy: 0.50116/163 [====================>.........] - ETA: 1s - loss: 0.6932 - accuracy: 0.50122/163 [=====================>........] - ETA: 1s - loss: 0.6932 - accuracy: 0.50124/163 [=====================>........] - ETA: 1s - loss: 0.6932 - accuracy: 0.50128/163 [======================>.......] - ETA: 1s - loss: 0.6932 - accuracy: 0.50131/163 [=======================>......] - ETA: 0s - loss: 0.6932 - accuracy: 0.50135/163 [=======================>......] - ETA: 0s - loss: 0.6931 - accuracy: 0.50138/163 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.50139/163 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.50141/163 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.50142/163 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.50143/163 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.50146/163 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.50147/163 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.50148/163 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.50149/163 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.50150/163 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.50152/163 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.50154/163 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.50156/163 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.50157/163 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.50159/163 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.50162/163 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.50163/163 [==============================] - 5s 33ms/step - loss: 0.6932 - accuracy: 0.5035 - val_loss: 0.6931 - val_accuracy: 0.5056\nEpoch 5/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6927 - accuracy: 0.53  5/163 [..............................] - ETA: 1s - loss: 0.6932 - accuracy: 0.50  7/163 [>.............................] - ETA: 2s - loss: 0.6933 - accuracy: 0.49 10/163 [>.............................] - ETA: 3s - loss: 0.6931 - accuracy: 0.50 12/163 [=>............................] - ETA: 3s - loss: 0.6930 - accuracy: 0.51 16/163 [=>............................] - ETA: 3s - loss: 0.6931 - accuracy: 0.50 19/163 [==>...........................] - ETA: 3s - loss: 0.6932 - accuracy: 0.49 21/163 [==>...........................] - ETA: 3s - loss: 0.6932 - accuracy: 0.49 22/163 [===>..........................] - ETA: 3s - loss: 0.6933 - accuracy: 0.49 25/163 [===>..........................] - ETA: 3s - loss: 0.6933 - accuracy: 0.49 28/163 [====>.........................] - ETA: 4s - loss: 0.6934 - accuracy: 0.48 30/163 [====>.........................] - ETA: 4s - loss: 0.6933 - accuracy: 0.48 31/163 [====>.........................] - ETA: 4s - loss: 0.6932 - accuracy: 0.49 32/163 [====>.........................] - ETA: 4s - loss: 0.6932 - accuracy: 0.50 34/163 [=====>........................] - ETA: 4s - loss: 0.6931 - accuracy: 0.50 35/163 [=====>........................] - ETA: 4s - loss: 0.6931 - accuracy: 0.50 37/163 [=====>........................] - ETA: 4s - loss: 0.6931 - accuracy: 0.50 39/163 [======>.......................] - ETA: 4s - loss: 0.6932 - accuracy: 0.50 43/163 [======>.......................] - ETA: 3s - loss: 0.6933 - accuracy: 0.49 45/163 [=======>......................] - ETA: 3s - loss: 0.6933 - accuracy: 0.49 50/163 [========>.....................] - ETA: 3s - loss: 0.6933 - accuracy: 0.49 54/163 [========>.....................] - ETA: 3s - loss: 0.6933 - accuracy: 0.49 56/163 [=========>....................] - ETA: 3s - loss: 0.6933 - accuracy: 0.49 58/163 [=========>....................] - ETA: 3s - loss: 0.6932 - accuracy: 0.49 59/163 [=========>....................] - ETA: 3s - loss: 0.6932 - accuracy: 0.49 62/163 [==========>...................] - ETA: 2s - loss: 0.6932 - accuracy: 0.49 66/163 [===========>..................] - ETA: 2s - loss: 0.6932 - accuracy: 0.50 70/163 [===========>..................] - ETA: 2s - loss: 0.6932 - accuracy: 0.50 76/163 [============>.................] - ETA: 2s - loss: 0.6932 - accuracy: 0.49 80/163 [=============>................] - ETA: 2s - loss: 0.6932 - accuracy: 0.49 91/163 [===============>..............] - ETA: 1s - loss: 0.6932 - accuracy: 0.50 97/163 [================>.............] - ETA: 1s - loss: 0.6931 - accuracy: 0.50100/163 [=================>............] - ETA: 1s - loss: 0.6931 - accuracy: 0.50104/163 [==================>...........] - ETA: 1s - loss: 0.6932 - accuracy: 0.50105/163 [==================>...........] - ETA: 1s - loss: 0.6932 - accuracy: 0.50108/163 [==================>...........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50109/163 [===================>..........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50110/163 [===================>..........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50112/163 [===================>..........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50113/163 [===================>..........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50114/163 [===================>..........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50115/163 [====================>.........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50116/163 [====================>.........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50118/163 [====================>.........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50121/163 [=====================>........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50124/163 [=====================>........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50125/163 [======================>.......] - ETA: 1s - loss: 0.6931 - accuracy: 0.50126/163 [======================>.......] - ETA: 1s - loss: 0.6931 - accuracy: 0.50129/163 [======================>.......] - ETA: 0s - loss: 0.6931 - accuracy: 0.50131/163 [=======================>......] - ETA: 0s - loss: 0.6932 - accuracy: 0.50135/163 [=======================>......] - ETA: 0s - loss: 0.6932 - accuracy: 0.50140/163 [========================>.....] - ETA: 0s - loss: 0.6932 - accuracy: 0.50144/163 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.50150/163 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.50151/163 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.50153/163 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.50155/163 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.50158/163 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.50160/163 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.50162/163 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.50163/163 [==============================] - 4s 27ms/step - loss: 0.6932 - accuracy: 0.5035 - val_loss: 0.6931 - val_accuracy: 0.5056\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: ec62732cb1733d83ab86a23823beb9ff</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.5055978298187256</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-n_layers: 9</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-n_nodes: 12</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "125/163 [======================>.......] - ETA: 0s - loss: 0.6933 - accuracy: 0.49128/163 [======================>.......] - ETA: 0s - loss: 0.6933 - accuracy: 0.49137/163 [========================>.....] - ETA: 0s - loss: 0.6933 - accuracy: 0.49142/163 [=========================>....] - ETA: 0s - loss: 0.6933 - accuracy: 0.49146/163 [=========================>....] - ETA: 0s - loss: 0.6933 - accuracy: 0.49149/163 [==========================>...] - ETA: 0s - loss: 0.6933 - accuracy: 0.49150/163 [==========================>...] - ETA: 0s - loss: 0.6933 - accuracy: 0.49151/163 [==========================>...] - ETA: 0s - loss: 0.6933 - accuracy: 0.49153/163 [===========================>..] - ETA: 0s - loss: 0.6933 - accuracy: 0.49154/163 [===========================>..] - ETA: 0s - loss: 0.6933 - accuracy: 0.49155/163 [===========================>..] - ETA: 0s - loss: 0.6933 - accuracy: 0.49156/163 [===========================>..] - ETA: 0s - loss: 0.6933 - accuracy: 0.49158/163 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.49160/163 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.49162/163 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.49163/163 [==============================] - 4s 25ms/step - loss: 0.6933 - accuracy: 0.4944 - val_loss: 0.6932 - val_accuracy: 0.4948\nEpoch 3/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6874 - accuracy: 0.62  3/163 [..............................] - ETA: 3s - loss: 0.6907 - accuracy: 0.53  4/163 [..............................] - ETA: 4s - loss: 0.6910 - accuracy: 0.52  6/163 [>.............................] - ETA: 6s - loss: 0.6912 - accuracy: 0.55  8/163 [>.............................] - ETA: 5s - loss: 0.6913 - accuracy: 0.55  9/163 [>.............................] - ETA: 6s - loss: 0.6914 - accuracy: 0.55 10/163 [>.............................] - ETA: 6s - loss: 0.6917 - accuracy: 0.55 11/163 [=>............................] - ETA: 7s - loss: 0.6921 - accuracy: 0.55 12/163 [=>............................] - ETA: 8s - loss: 0.6920 - accuracy: 0.56 13/163 [=>............................] - ETA: 7s - loss: 0.6918 - accuracy: 0.55 14/163 [=>............................] - ETA: 8s - loss: 0.6919 - accuracy: 0.55 16/163 [=>............................] - ETA: 8s - loss: 0.6934 - accuracy: 0.52 17/163 [==>...........................] - ETA: 8s - loss: 0.6937 - accuracy: 0.52 18/163 [==>...........................] - ETA: 8s - loss: 0.6936 - accuracy: 0.52 19/163 [==>...........................] - ETA: 8s - loss: 0.6933 - accuracy: 0.52 20/163 [==>...........................] - ETA: 8s - loss: 0.6935 - accuracy: 0.52 21/163 [==>...........................] - ETA: 8s - loss: 0.6933 - accuracy: 0.52 22/163 [===>..........................] - ETA: 8s - loss: 0.6932 - accuracy: 0.52 26/163 [===>..........................] - ETA: 7s - loss: 0.6933 - accuracy: 0.52 29/163 [====>.........................] - ETA: 6s - loss: 0.6932 - accuracy: 0.52 30/163 [====>.........................] - ETA: 6s - loss: 0.6935 - accuracy: 0.52 31/163 [====>.........................] - ETA: 6s - loss: 0.6935 - accuracy: 0.51 32/163 [====>.........................] - ETA: 6s - loss: 0.6935 - accuracy: 0.51 33/163 [=====>........................] - ETA: 6s - loss: 0.6934 - accuracy: 0.52 34/163 [=====>........................] - ETA: 7s - loss: 0.6933 - accuracy: 0.52 37/163 [=====>........................] - ETA: 6s - loss: 0.6934 - accuracy: 0.52 38/163 [=====>........................] - ETA: 6s - loss: 0.6934 - accuracy: 0.51 42/163 [======>.......................] - ETA: 5s - loss: 0.6935 - accuracy: 0.51 44/163 [=======>......................] - ETA: 5s - loss: 0.6934 - accuracy: 0.51 46/163 [=======>......................] - ETA: 5s - loss: 0.6934 - accuracy: 0.51 47/163 [=======>......................] - ETA: 5s - loss: 0.6934 - accuracy: 0.51 48/163 [=======>......................] - ETA: 5s - loss: 0.6935 - accuracy: 0.51 51/163 [========>.....................] - ETA: 5s - loss: 0.6936 - accuracy: 0.50 54/163 [========>.....................] - ETA: 5s - loss: 0.6935 - accuracy: 0.50 55/163 [=========>....................] - ETA: 5s - loss: 0.6936 - accuracy: 0.50 57/163 [=========>....................] - ETA: 4s - loss: 0.6935 - accuracy: 0.50 58/163 [=========>....................] - ETA: 4s - loss: 0.6934 - accuracy: 0.51 59/163 [=========>....................] - ETA: 4s - loss: 0.6934 - accuracy: 0.51 61/163 [==========>...................] - ETA: 4s - loss: 0.6934 - accuracy: 0.51 63/163 [==========>...................] - ETA: 4s - loss: 0.6934 - accuracy: 0.50 64/163 [==========>...................] - ETA: 4s - loss: 0.6933 - accuracy: 0.51 65/163 [==========>...................] - ETA: 4s - loss: 0.6933 - accuracy: 0.51 66/163 [===========>..................] - ETA: 4s - loss: 0.6933 - accuracy: 0.51 69/163 [===========>..................] - ETA: 4s - loss: 0.6933 - accuracy: 0.51 70/163 [===========>..................] - ETA: 4s - loss: 0.6933 - accuracy: 0.50 73/163 [============>.................] - ETA: 4s - loss: 0.6933 - accuracy: 0.50 76/163 [============>.................] - ETA: 3s - loss: 0.6933 - accuracy: 0.50 78/163 [=============>................] - ETA: 3s - loss: 0.6933 - accuracy: 0.50 82/163 [==============>...............] - ETA: 3s - loss: 0.6932 - accuracy: 0.50 84/163 [==============>...............] - ETA: 3s - loss: 0.6933 - accuracy: 0.50 86/163 [==============>...............] - ETA: 3s - loss: 0.6932 - accuracy: 0.50 91/163 [===============>..............] - ETA: 2s - loss: 0.6933 - accuracy: 0.50 93/163 [================>.............] - ETA: 2s - loss: 0.6933 - accuracy: 0.50 94/163 [================>.............] - ETA: 2s - loss: 0.6932 - accuracy: 0.50 95/163 [================>.............] - ETA: 2s - loss: 0.6932 - accuracy: 0.50 96/163 [================>.............] - ETA: 2s - loss: 0.6932 - accuracy: 0.50 97/163 [================>.............] - ETA: 2s - loss: 0.6932 - accuracy: 0.50 98/163 [=================>............] - ETA: 2s - loss: 0.6932 - accuracy: 0.50 99/163 [=================>............] - ETA: 2s - loss: 0.6932 - accuracy: 0.50105/163 [==================>...........] - ETA: 2s - loss: 0.6932 - accuracy: 0.50108/163 [==================>...........] - ETA: 2s - loss: 0.6931 - accuracy: 0.50113/163 [===================>..........] - ETA: 1s - loss: 0.6932 - accuracy: 0.50119/163 [====================>.........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50123/163 [=====================>........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50126/163 [======================>.......] - ETA: 1s - loss: 0.6931 - accuracy: 0.50127/163 [======================>.......] - ETA: 1s - loss: 0.6932 - accuracy: 0.50128/163 [======================>.......] - ETA: 1s - loss: 0.6931 - accuracy: 0.50129/163 [======================>.......] - ETA: 1s - loss: 0.6931 - accuracy: 0.50130/163 [======================>.......] - ETA: 1s - loss: 0.6931 - accuracy: 0.50132/163 [=======================>......] - ETA: 1s - loss: 0.6931 - accuracy: 0.51133/163 [=======================>......] - ETA: 1s - loss: 0.6930 - accuracy: 0.51135/163 [=======================>......] - ETA: 1s - loss: 0.6930 - accuracy: 0.51136/163 [========================>.....] - ETA: 1s - loss: 0.6931 - accuracy: 0.51139/163 [========================>.....] - ETA: 0s - loss: 0.6930 - accuracy: 0.51142/163 [=========================>....] - ETA: 0s - loss: 0.6930 - accuracy: 0.51145/163 [=========================>....] - ETA: 0s - loss: 0.6929 - accuracy: 0.51148/163 [==========================>...] - ETA: 0s - loss: 0.6929 - accuracy: 0.51149/163 [==========================>...] - ETA: 0s - loss: 0.6929 - accuracy: 0.51151/163 [==========================>...] - ETA: 0s - loss: 0.6928 - accuracy: 0.51153/163 [===========================>..] - ETA: 0s - loss: 0.6928 - accuracy: 0.51155/163 [===========================>..] - ETA: 0s - loss: 0.6928 - accuracy: 0.51156/163 [===========================>..] - ETA: 0s - loss: 0.6928 - accuracy: 0.51157/163 [===========================>..] - ETA: 0s - loss: 0.6927 - accuracy: 0.51160/163 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.51162/163 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.51163/163 [==============================] - 7s 43ms/step - loss: 0.6927 - accuracy: 0.5190 - val_loss: 0.6936 - val_accuracy: 0.5002\nEpoch 4/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6919 - accuracy: 0.59  2/163 [..............................] - ETA: 5s - loss: 0.6854 - accuracy: 0.60  3/163 [..............................] - ETA: 6s - loss: 0.6864 - accuracy: 0.60  4/163 [..............................] - ETA: 8s - loss: 0.6873 - accuracy: 0.58  5/163 [..............................] - ETA: 10s - loss: 0.6900 - accuracy: 0.556  7/163 [>.............................] - ETA: 9s - loss: 0.6926 - accuracy: 0.53  8/163 [>.............................] - ETA: 9s - loss: 0.6917 - accuracy: 0.53  9/163 [>.............................] - ETA: 10s - loss: 0.6921 - accuracy: 0.538 10/163 [>.............................] - ETA: 11s - loss: 0.6923 - accuracy: 0.534 12/163 [=>............................] - ETA: 10s - loss: 0.6912 - accuracy: 0.531 14/163 [=>............................] - ETA: 9s - loss: 0.6915 - accuracy: 0.53 22/163 [===>..........................] - ETA: 6s - loss: 0.6929 - accuracy: 0.51 26/163 [===>..........................] - ETA: 5s - loss: 0.6920 - accuracy: 0.51 28/163 [====>.........................] - ETA: 5s - loss: 0.6917 - accuracy: 0.52 32/163 [====>.........................] - ETA: 4s - loss: 0.6914 - accuracy: 0.52 36/163 [=====>........................] - ETA: 4s - loss: 0.6910 - accuracy: 0.52 40/163 [======>.......................] - ETA: 3s - loss: 0.6907 - accuracy: 0.53 43/163 [======>.......................] - ETA: 3s - loss: 0.6907 - accuracy: 0.53 44/163 [=======>......................] - ETA: 3s - loss: 0.6908 - accuracy: 0.53 46/163 [=======>......................] - ETA: 3s - loss: 0.6909 - accuracy: 0.53 48/163 [=======>......................] - ETA: 3s - loss: 0.6912 - accuracy: 0.52 50/163 [========>.....................] - ETA: 3s - loss: 0.6914 - accuracy: 0.52 51/163 [========>.....................] - ETA: 4s - loss: 0.6914 - accuracy: 0.52 53/163 [========>.....................] - ETA: 4s - loss: 0.6913 - accuracy: 0.52 57/163 [=========>....................] - ETA: 3s - loss: 0.6914 - accuracy: 0.52 58/163 [=========>....................] - ETA: 3s - loss: 0.6915 - accuracy: 0.52 61/163 [==========>...................] - ETA: 3s - loss: 0.6914 - accuracy: 0.52 63/163 [==========>...................] - ETA: 3s - loss: 0.6916 - accuracy: 0.52 64/163 [==========>...................] - ETA: 3s - loss: 0.6917 - accuracy: 0.52 66/163 [===========>..................] - ETA: 3s - loss: 0.6919 - accuracy: 0.51 68/163 [===========>..................] - ETA: 3s - loss: 0.6920 - accuracy: 0.51 69/163 [===========>..................] - ETA: 3s - loss: 0.6918 - accuracy: 0.51 70/163 [===========>..................] - ETA: 3s - loss: 0.6918 - accuracy: 0.51 72/163 [============>.................] - ETA: 3s - loss: 0.6921 - accuracy: 0.51 73/163 [============>.................] - ETA: 3s - loss: 0.6919 - accuracy: 0.51 74/163 [============>.................] - ETA: 4s - loss: 0.6920 - accuracy: 0.51 75/163 [============>.................] - ETA: 4s - loss: 0.6918 - accuracy: 0.51 76/163 [============>.................] - ETA: 4s - loss: 0.6920 - accuracy: 0.51 77/163 [=============>................] - ETA: 4s - loss: 0.6921 - accuracy: 0.51 78/163 [=============>................] - ETA: 4s - loss: 0.6919 - accuracy: 0.51 80/163 [=============>................] - ETA: 3s - loss: 0.6919 - accuracy: 0.51 81/163 [=============>................] - ETA: 3s - loss: 0.6919 - accuracy: 0.51 84/163 [==============>...............] - ETA: 3s - loss: 0.6920 - accuracy: 0.51 85/163 [==============>...............] - ETA: 3s - loss: 0.6919 - accuracy: 0.51 87/163 [===============>..............] - ETA: 3s - loss: 0.6918 - accuracy: 0.51 90/163 [===============>..............] - ETA: 3s - loss: 0.6918 - accuracy: 0.51 91/163 [===============>..............] - ETA: 3s - loss: 0.6921 - accuracy: 0.51 93/163 [================>.............] - ETA: 3s - loss: 0.6919 - accuracy: 0.51 95/163 [================>.............] - ETA: 3s - loss: 0.6921 - accuracy: 0.51 96/163 [================>.............] - ETA: 3s - loss: 0.6922 - accuracy: 0.51 97/163 [================>.............] - ETA: 3s - loss: 0.6920 - accuracy: 0.51 98/163 [=================>............] - ETA: 3s - loss: 0.6920 - accuracy: 0.51100/163 [=================>............] - ETA: 3s - loss: 0.6921 - accuracy: 0.51103/163 [=================>............] - ETA: 2s - loss: 0.6922 - accuracy: 0.51106/163 [==================>...........] - ETA: 2s - loss: 0.6922 - accuracy: 0.51108/163 [==================>...........] - ETA: 2s - loss: 0.6921 - accuracy: 0.51109/163 [===================>..........] - ETA: 2s - loss: 0.6921 - accuracy: 0.51111/163 [===================>..........] - ETA: 2s - loss: 0.6921 - accuracy: 0.51112/163 [===================>..........] - ETA: 2s - loss: 0.6921 - accuracy: 0.51113/163 [===================>..........] - ETA: 2s - loss: 0.6922 - accuracy: 0.51114/163 [===================>..........] - ETA: 2s - loss: 0.6923 - accuracy: 0.51116/163 [====================>.........] - ETA: 2s - loss: 0.6922 - accuracy: 0.51120/163 [=====================>........] - ETA: 2s - loss: 0.6923 - accuracy: 0.51121/163 [=====================>........] - ETA: 1s - loss: 0.6923 - accuracy: 0.51122/163 [=====================>........] - ETA: 1s - loss: 0.6922 - accuracy: 0.51125/163 [======================>.......] - ETA: 1s - loss: 0.6923 - accuracy: 0.51127/163 [======================>.......] - ETA: 1s - loss: 0.6922 - accuracy: 0.51130/163 [======================>.......] - ETA: 1s - loss: 0.6922 - accuracy: 0.51134/163 [=======================>......] - ETA: 1s - loss: 0.6921 - accuracy: 0.51136/163 [========================>.....] - ETA: 1s - loss: 0.6922 - accuracy: 0.51140/163 [========================>.....] - ETA: 1s - loss: 0.6922 - accuracy: 0.51142/163 [=========================>....] - ETA: 0s - loss: 0.6922 - accuracy: 0.51143/163 [=========================>....] - ETA: 0s - loss: 0.6921 - accuracy: 0.51145/163 [=========================>....] - ETA: 0s - loss: 0.6921 - accuracy: 0.51146/163 [=========================>....] - ETA: 0s - loss: 0.6921 - accuracy: 0.51147/163 [==========================>...] - ETA: 0s - loss: 0.6921 - accuracy: 0.51148/163 [==========================>...] - ETA: 0s - loss: 0.6921 - accuracy: 0.51149/163 [==========================>...] - ETA: 0s - loss: 0.6920 - accuracy: 0.51154/163 [===========================>..] - ETA: 0s - loss: 0.6922 - accuracy: 0.51158/163 [============================>.] - ETA: 0s - loss: 0.6921 - accuracy: 0.51162/163 [============================>.] - ETA: 0s - loss: 0.6922 - accuracy: 0.51163/163 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.51163/163 [==============================] - 8s 47ms/step - loss: 0.6922 - accuracy: 0.5165 - val_loss: 0.6926 - val_accuracy: 0.5253\nEpoch 5/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6989 - accuracy: 0.46  4/163 [..............................] - ETA: 2s - loss: 0.6939 - accuracy: 0.50  7/163 [>.............................] - ETA: 2s - loss: 0.6914 - accuracy: 0.54  8/163 [>.............................] - ETA: 3s - loss: 0.6908 - accuracy: 0.53 10/163 [>.............................] - ETA: 3s - loss: 0.6894 - accuracy: 0.55 14/163 [=>............................] - ETA: 3s - loss: 0.6915 - accuracy: 0.52 16/163 [=>............................] - ETA: 3s - loss: 0.6912 - accuracy: 0.52 20/163 [==>...........................] - ETA: 3s - loss: 0.6916 - accuracy: 0.52 22/163 [===>..........................] - ETA: 3s - loss: 0.6914 - accuracy: 0.52 29/163 [====>.........................] - ETA: 2s - loss: 0.6916 - accuracy: 0.52 32/163 [====>.........................] - ETA: 2s - loss: 0.6920 - accuracy: 0.51 34/163 [=====>........................] - ETA: 2s - loss: 0.6918 - accuracy: 0.52 37/163 [=====>........................] - ETA: 2s - loss: 0.6920 - accuracy: 0.51 38/163 [=====>........................] - ETA: 2s - loss: 0.6921 - accuracy: 0.51 40/163 [======>.......................] - ETA: 2s - loss: 0.6917 - accuracy: 0.51 43/163 [======>.......................] - ETA: 2s - loss: 0.6921 - accuracy: 0.51 47/163 [=======>......................] - ETA: 2s - loss: 0.6918 - accuracy: 0.51 48/163 [=======>......................] - ETA: 2s - loss: 0.6916 - accuracy: 0.51 52/163 [========>.....................] - ETA: 2s - loss: 0.6917 - accuracy: 0.51 57/163 [=========>....................] - ETA: 2s - loss: 0.6916 - accuracy: 0.52 59/163 [=========>....................] - ETA: 2s - loss: 0.6916 - accuracy: 0.51 61/163 [==========>...................] - ETA: 2s - loss: 0.6917 - accuracy: 0.52 64/163 [==========>...................] - ETA: 2s - loss: 0.6917 - accuracy: 0.51 65/163 [==========>...................] - ETA: 2s - loss: 0.6917 - accuracy: 0.51 69/163 [===========>..................] - ETA: 1s - loss: 0.6914 - accuracy: 0.52 72/163 [============>.................] - ETA: 1s - loss: 0.6911 - accuracy: 0.52 76/163 [============>.................] - ETA: 1s - loss: 0.6912 - accuracy: 0.52 78/163 [=============>................] - ETA: 1s - loss: 0.6911 - accuracy: 0.52 82/163 [==============>...............] - ETA: 1s - loss: 0.6913 - accuracy: 0.51 83/163 [==============>...............] - ETA: 1s - loss: 0.6914 - accuracy: 0.52 84/163 [==============>...............] - ETA: 1s - loss: 0.6914 - accuracy: 0.52 86/163 [==============>...............] - ETA: 1s - loss: 0.6918 - accuracy: 0.51 88/163 [===============>..............] - ETA: 1s - loss: 0.6917 - accuracy: 0.51 91/163 [===============>..............] - ETA: 1s - loss: 0.6915 - accuracy: 0.51 95/163 [================>.............] - ETA: 1s - loss: 0.6914 - accuracy: 0.52 98/163 [=================>............] - ETA: 1s - loss: 0.6912 - accuracy: 0.52 99/163 [=================>............] - ETA: 1s - loss: 0.6912 - accuracy: 0.52100/163 [=================>............] - ETA: 1s - loss: 0.6913 - accuracy: 0.52104/163 [==================>...........] - ETA: 1s - loss: 0.6909 - accuracy: 0.52109/163 [===================>..........] - ETA: 1s - loss: 0.6909 - accuracy: 0.52118/163 [====================>.........] - ETA: 0s - loss: 0.6906 - accuracy: 0.52120/163 [=====================>........] - ETA: 0s - loss: 0.6906 - accuracy: 0.52123/163 [=====================>........] - ETA: 0s - loss: 0.6905 - accuracy: 0.52125/163 [======================>.......] - ETA: 0s - loss: 0.6907 - accuracy: 0.52128/163 [======================>.......] - ETA: 0s - loss: 0.6905 - accuracy: 0.52134/163 [=======================>......] - ETA: 0s - loss: 0.6903 - accuracy: 0.52137/163 [========================>.....] - ETA: 0s - loss: 0.6906 - accuracy: 0.52138/163 [========================>.....] - ETA: 0s - loss: 0.6905 - accuracy: 0.52139/163 [========================>.....] - ETA: 0s - loss: 0.6905 - accuracy: 0.52141/163 [========================>.....] - ETA: 0s - loss: 0.6904 - accuracy: 0.52143/163 [=========================>....] - ETA: 0s - loss: 0.6905 - accuracy: 0.52148/163 [==========================>...] - ETA: 0s - loss: 0.6907 - accuracy: 0.52150/163 [==========================>...] - ETA: 0s - loss: 0.6908 - accuracy: 0.52154/163 [===========================>..] - ETA: 0s - loss: 0.6907 - accuracy: 0.52161/163 [============================>.] - ETA: 0s - loss: 0.6908 - accuracy: 0.52163/163 [==============================] - 4s 26ms/step - loss: 0.6907 - accuracy: 0.5271 - val_loss: 0.6941 - val_accuracy: 0.5034\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: 081a83e50e4ddafd03bd5f1a4f73a4bf</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.5253022909164429</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-n_layers: 5</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-n_nodes: 12</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cy: 0.51161/163 [============================>.] - ETA: 0s - loss: 0.6928 - accuracy: 0.51162/163 [============================>.] - ETA: 0s - loss: 0.6928 - accuracy: 0.51163/163 [==============================] - 7s 44ms/step - loss: 0.6928 - accuracy: 0.5109 - val_loss: 0.6926 - val_accuracy: 0.5114\nEpoch 3/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6985 - accuracy: 0.37  4/163 [..............................] - ETA: 2s - loss: 0.6933 - accuracy: 0.46  6/163 [>.............................] - ETA: 6s - loss: 0.6933 - accuracy: 0.48  7/163 [>.............................] - ETA: 6s - loss: 0.6927 - accuracy: 0.50  8/163 [>.............................] - ETA: 7s - loss: 0.6920 - accuracy: 0.51 11/163 [=>............................] - ETA: 5s - loss: 0.6919 - accuracy: 0.52 14/163 [=>............................] - ETA: 5s - loss: 0.6922 - accuracy: 0.51 16/163 [=>............................] - ETA: 4s - loss: 0.6918 - accuracy: 0.52 19/163 [==>...........................] - ETA: 4s - loss: 0.6920 - accuracy: 0.51 22/163 [===>..........................] - ETA: 4s - loss: 0.6912 - accuracy: 0.52 23/163 [===>..........................] - ETA: 4s - loss: 0.6910 - accuracy: 0.52 24/163 [===>..........................] - ETA: 4s - loss: 0.6914 - accuracy: 0.52 26/163 [===>..........................] - ETA: 4s - loss: 0.6915 - accuracy: 0.51 28/163 [====>.........................] - ETA: 4s - loss: 0.6916 - accuracy: 0.51 30/163 [====>.........................] - ETA: 4s - loss: 0.6919 - accuracy: 0.50 32/163 [====>.........................] - ETA: 4s - loss: 0.6913 - accuracy: 0.51 33/163 [=====>........................] - ETA: 4s - loss: 0.6913 - accuracy: 0.51 35/163 [=====>........................] - ETA: 4s - loss: 0.6910 - accuracy: 0.52 36/163 [=====>........................] - ETA: 4s - loss: 0.6908 - accuracy: 0.52 37/163 [=====>........................] - ETA: 4s - loss: 0.6910 - accuracy: 0.52 39/163 [======>.......................] - ETA: 4s - loss: 0.6908 - accuracy: 0.52 40/163 [======>.......................] - ETA: 4s - loss: 0.6906 - accuracy: 0.53 41/163 [======>.......................] - ETA: 5s - loss: 0.6902 - accuracy: 0.53 42/163 [======>.......................] - ETA: 5s - loss: 0.6902 - accuracy: 0.53 43/163 [======>.......................] - ETA: 5s - loss: 0.6901 - accuracy: 0.54 44/163 [=======>......................] - ETA: 6s - loss: 0.6902 - accuracy: 0.53 45/163 [=======>......................] - ETA: 6s - loss: 0.6901 - accuracy: 0.54 46/163 [=======>......................] - ETA: 6s - loss: 0.6899 - accuracy: 0.54 49/163 [========>.....................] - ETA: 6s - loss: 0.6901 - accuracy: 0.54 50/163 [========>.....................] - ETA: 6s - loss: 0.6900 - accuracy: 0.54 53/163 [========>.....................] - ETA: 5s - loss: 0.6895 - accuracy: 0.54 55/163 [=========>....................] - ETA: 5s - loss: 0.6895 - accuracy: 0.54 56/163 [=========>....................] - ETA: 5s - loss: 0.6897 - accuracy: 0.54 57/163 [=========>....................] - ETA: 5s - loss: 0.6899 - accuracy: 0.54 58/163 [=========>....................] - ETA: 5s - loss: 0.6900 - accuracy: 0.54 59/163 [=========>....................] - ETA: 5s - loss: 0.6897 - accuracy: 0.54 60/163 [==========>...................] - ETA: 5s - loss: 0.6897 - accuracy: 0.54 61/163 [==========>...................] - ETA: 5s - loss: 0.6899 - accuracy: 0.53 62/163 [==========>...................] - ETA: 5s - loss: 0.6896 - accuracy: 0.53 64/163 [==========>...................] - ETA: 5s - loss: 0.6895 - accuracy: 0.54 65/163 [==========>...................] - ETA: 5s - loss: 0.6894 - accuracy: 0.54 66/163 [===========>..................] - ETA: 5s - loss: 0.6894 - accuracy: 0.54 68/163 [===========>..................] - ETA: 5s - loss: 0.6898 - accuracy: 0.53 69/163 [===========>..................] - ETA: 5s - loss: 0.6897 - accuracy: 0.53 70/163 [===========>..................] - ETA: 5s - loss: 0.6895 - accuracy: 0.54 71/163 [============>.................] - ETA: 5s - loss: 0.6897 - accuracy: 0.53 72/163 [============>.................] - ETA: 5s - loss: 0.6894 - accuracy: 0.54 76/163 [============>.................] - ETA: 4s - loss: 0.6890 - accuracy: 0.54 77/163 [=============>................] - ETA: 4s - loss: 0.6889 - accuracy: 0.54 79/163 [=============>................] - ETA: 4s - loss: 0.6895 - accuracy: 0.53 81/163 [=============>................] - ETA: 4s - loss: 0.6896 - accuracy: 0.53 83/163 [==============>...............] - ETA: 4s - loss: 0.6891 - accuracy: 0.54 85/163 [==============>...............] - ETA: 4s - loss: 0.6890 - accuracy: 0.54 88/163 [===============>..............] - ETA: 3s - loss: 0.6893 - accuracy: 0.53 92/163 [===============>..............] - ETA: 3s - loss: 0.6903 - accuracy: 0.53 97/163 [================>.............] - ETA: 3s - loss: 0.6903 - accuracy: 0.53 99/163 [=================>............] - ETA: 3s - loss: 0.6904 - accuracy: 0.53101/163 [=================>............] - ETA: 2s - loss: 0.6907 - accuracy: 0.53103/163 [=================>............] - ETA: 2s - loss: 0.6908 - accuracy: 0.53106/163 [==================>...........] - ETA: 2s - loss: 0.6906 - accuracy: 0.53107/163 [==================>...........] - ETA: 2s - loss: 0.6906 - accuracy: 0.53108/163 [==================>...........] - ETA: 2s - loss: 0.6906 - accuracy: 0.53112/163 [===================>..........] - ETA: 2s - loss: 0.6904 - accuracy: 0.53113/163 [===================>..........] - ETA: 2s - loss: 0.6902 - accuracy: 0.53116/163 [====================>.........] - ETA: 2s - loss: 0.6900 - accuracy: 0.53117/163 [====================>.........] - ETA: 2s - loss: 0.6900 - accuracy: 0.53121/163 [=====================>........] - ETA: 1s - loss: 0.6903 - accuracy: 0.53125/163 [======================>.......] - ETA: 1s - loss: 0.6904 - accuracy: 0.53130/163 [======================>.......] - ETA: 1s - loss: 0.6909 - accuracy: 0.53133/163 [=======================>......] - ETA: 1s - loss: 0.6908 - accuracy: 0.53138/163 [========================>.....] - ETA: 1s - loss: 0.6909 - accuracy: 0.53143/163 [=========================>....] - ETA: 0s - loss: 0.6911 - accuracy: 0.53144/163 [=========================>....] - ETA: 0s - loss: 0.6912 - accuracy: 0.52147/163 [==========================>...] - ETA: 0s - loss: 0.6910 - accuracy: 0.53150/163 [==========================>...] - ETA: 0s - loss: 0.6910 - accuracy: 0.53153/163 [===========================>..] - ETA: 0s - loss: 0.6912 - accuracy: 0.52158/163 [============================>.] - ETA: 0s - loss: 0.6911 - accuracy: 0.52163/163 [==============================] - 7s 42ms/step - loss: 0.6911 - accuracy: 0.5294 - val_loss: 0.6944 - val_accuracy: 0.5011\nEpoch 4/5\n  1/163 [..............................] - ETA: 0s - loss: 0.7001 - accuracy: 0.53  2/163 [..............................] - ETA: 7s - loss: 0.6950 - accuracy: 0.50  4/163 [..............................] - ETA: 6s - loss: 0.6906 - accuracy: 0.53  6/163 [>.............................] - ETA: 6s - loss: 0.6912 - accuracy: 0.54  7/163 [>.............................] - ETA: 6s - loss: 0.6909 - accuracy: 0.54  9/163 [>.............................] - ETA: 5s - loss: 0.6874 - accuracy: 0.55 11/163 [=>............................] - ETA: 5s - loss: 0.6883 - accuracy: 0.55 12/163 [=>............................] - ETA: 5s - loss: 0.6884 - accuracy: 0.54 14/163 [=>............................] - ETA: 5s - loss: 0.6898 - accuracy: 0.55 16/163 [=>............................] - ETA: 5s - loss: 0.6899 - accuracy: 0.54 17/163 [==>...........................] - ETA: 5s - loss: 0.6894 - accuracy: 0.54 18/163 [==>...........................] - ETA: 5s - loss: 0.6891 - accuracy: 0.54 19/163 [==>...........................] - ETA: 6s - loss: 0.6895 - accuracy: 0.53 20/163 [==>...........................] - ETA: 6s - loss: 0.6896 - accuracy: 0.53 21/163 [==>...........................] - ETA: 6s - loss: 0.6907 - accuracy: 0.53 23/163 [===>..........................] - ETA: 6s - loss: 0.6897 - accuracy: 0.53 24/163 [===>..........................] - ETA: 6s - loss: 0.6891 - accuracy: 0.53 26/163 [===>..........................] - ETA: 6s - loss: 0.6899 - accuracy: 0.53 27/163 [===>..........................] - ETA: 6s - loss: 0.6897 - accuracy: 0.53 29/163 [====>.........................] - ETA: 6s - loss: 0.6898 - accuracy: 0.53 32/163 [====>.........................] - ETA: 5s - loss: 0.6891 - accuracy: 0.53 33/163 [=====>........................] - ETA: 5s - loss: 0.6890 - accuracy: 0.53 34/163 [=====>........................] - ETA: 5s - loss: 0.6892 - accuracy: 0.53 35/163 [=====>........................] - ETA: 5s - loss: 0.6891 - accuracy: 0.53 38/163 [=====>........................] - ETA: 5s - loss: 0.6888 - accuracy: 0.53 40/163 [======>.......................] - ETA: 5s - loss: 0.6884 - accuracy: 0.53 42/163 [======>.......................] - ETA: 5s - loss: 0.6885 - accuracy: 0.53 47/163 [=======>......................] - ETA: 4s - loss: 0.6875 - accuracy: 0.54 49/163 [========>.....................] - ETA: 4s - loss: 0.6874 - accuracy: 0.54 51/163 [========>.....................] - ETA: 4s - loss: 0.6873 - accuracy: 0.54 52/163 [========>.....................] - ETA: 4s - loss: 0.6874 - accuracy: 0.54 53/163 [========>.....................] - ETA: 4s - loss: 0.6874 - accuracy: 0.54 56/163 [=========>....................] - ETA: 4s - loss: 0.6869 - accuracy: 0.54 57/163 [=========>....................] - ETA: 4s - loss: 0.6868 - accuracy: 0.55 60/163 [==========>...................] - ETA: 4s - loss: 0.6868 - accuracy: 0.55 63/163 [==========>...................] - ETA: 3s - loss: 0.6870 - accuracy: 0.55 64/163 [==========>...................] - ETA: 4s - loss: 0.6872 - accuracy: 0.55 66/163 [===========>..................] - ETA: 3s - loss: 0.6873 - accuracy: 0.55 67/163 [===========>..................] - ETA: 4s - loss: 0.6873 - accuracy: 0.55 69/163 [===========>..................] - ETA: 3s - loss: 0.6875 - accuracy: 0.55 70/163 [===========>..................] - ETA: 4s - loss: 0.6875 - accuracy: 0.55 71/163 [============>.................] - ETA: 3s - loss: 0.6876 - accuracy: 0.55 72/163 [============>.................] - ETA: 3s - loss: 0.6869 - accuracy: 0.55 74/163 [============>.................] - ETA: 3s - loss: 0.6875 - accuracy: 0.55 76/163 [============>.................] - ETA: 3s - loss: 0.6875 - accuracy: 0.55 80/163 [=============>................] - ETA: 3s - loss: 0.6873 - accuracy: 0.55 83/163 [==============>...............] - ETA: 3s - loss: 0.6872 - accuracy: 0.55 84/163 [==============>...............] - ETA: 3s - loss: 0.6870 - accuracy: 0.55 86/163 [==============>...............] - ETA: 3s - loss: 0.6873 - accuracy: 0.55 91/163 [===============>..............] - ETA: 2s - loss: 0.6875 - accuracy: 0.54 94/163 [================>.............] - ETA: 2s - loss: 0.6878 - accuracy: 0.54 95/163 [================>.............] - ETA: 2s - loss: 0.6881 - accuracy: 0.54 98/163 [=================>............] - ETA: 2s - loss: 0.6878 - accuracy: 0.54102/163 [=================>............] - ETA: 2s - loss: 0.6878 - accuracy: 0.54104/163 [==================>...........] - ETA: 2s - loss: 0.6880 - accuracy: 0.54106/163 [==================>...........] - ETA: 2s - loss: 0.6881 - accuracy: 0.54108/163 [==================>...........] - ETA: 2s - loss: 0.6879 - accuracy: 0.54110/163 [===================>..........] - ETA: 1s - loss: 0.6879 - accuracy: 0.54112/163 [===================>..........] - ETA: 1s - loss: 0.6877 - accuracy: 0.54113/163 [===================>..........] - ETA: 1s - loss: 0.6881 - accuracy: 0.54114/163 [===================>..........] - ETA: 1s - loss: 0.6877 - accuracy: 0.54117/163 [====================>.........] - ETA: 1s - loss: 0.6879 - accuracy: 0.54121/163 [=====================>........] - ETA: 1s - loss: 0.6881 - accuracy: 0.54124/163 [=====================>........] - ETA: 1s - loss: 0.6878 - accuracy: 0.54129/163 [======================>.......] - ETA: 1s - loss: 0.6877 - accuracy: 0.54132/163 [=======================>......] - ETA: 1s - loss: 0.6876 - accuracy: 0.54134/163 [=======================>......] - ETA: 1s - loss: 0.6877 - accuracy: 0.54137/163 [========================>.....] - ETA: 0s - loss: 0.6875 - accuracy: 0.54138/163 [========================>.....] - ETA: 0s - loss: 0.6878 - accuracy: 0.54140/163 [========================>.....] - ETA: 0s - loss: 0.6878 - accuracy: 0.54141/163 [========================>.....] - ETA: 0s - loss: 0.6875 - accuracy: 0.54145/163 [=========================>....] - ETA: 0s - loss: 0.6871 - accuracy: 0.54147/163 [==========================>...] - ETA: 0s - loss: 0.6870 - accuracy: 0.54148/163 [==========================>...] - ETA: 0s - loss: 0.6871 - accuracy: 0.54149/163 [==========================>...] - ETA: 0s - loss: 0.6868 - accuracy: 0.55151/163 [==========================>...] - ETA: 0s - loss: 0.6870 - accuracy: 0.54154/163 [===========================>..] - ETA: 0s - loss: 0.6868 - accuracy: 0.55156/163 [===========================>..] - ETA: 0s - loss: 0.6869 - accuracy: 0.54158/163 [============================>.] - ETA: 0s - loss: 0.6868 - accuracy: 0.55160/163 [============================>.] - ETA: 0s - loss: 0.6866 - accuracy: 0.55163/163 [==============================] - ETA: 0s - loss: 0.6866 - accuracy: 0.55163/163 [==============================] - 6s 38ms/step - loss: 0.6866 - accuracy: 0.5507 - val_loss: 0.6977 - val_accuracy: 0.5016\nEpoch 5/5\n  1/163 [..............................] - ETA: 0s - loss: 0.7024 - accuracy: 0.46  4/163 [..............................] - ETA: 2s - loss: 0.6887 - accuracy: 0.50  5/163 [..............................] - ETA: 4s - loss: 0.6883 - accuracy: 0.51  7/163 [>.............................] - ETA: 5s - loss: 0.6879 - accuracy: 0.51  9/163 [>.............................] - ETA: 5s - loss: 0.6885 - accuracy: 0.51 11/163 [=>............................] - ETA: 6s - loss: 0.6849 - accuracy: 0.53 12/163 [=>............................] - ETA: 7s - loss: 0.6852 - accuracy: 0.53 14/163 [=>............................] - ETA: 6s - loss: 0.6839 - accuracy: 0.54 15/163 [=>............................] - ETA: 6s - loss: 0.6821 - accuracy: 0.55 16/163 [=>............................] - ETA: 6s - loss: 0.6813 - accuracy: 0.56 18/163 [==>...........................] - ETA: 6s - loss: 0.6804 - accuracy: 0.56 22/163 [===>..........................] - ETA: 6s - loss: 0.6820 - accuracy: 0.56 23/163 [===>..........................] - ETA: 6s - loss: 0.6820 - accuracy: 0.56 25/163 [===>..........................] - ETA: 5s - loss: 0.6822 - accuracy: 0.56 28/163 [====>.........................] - ETA: 5s - loss: 0.6854 - accuracy: 0.55 31/163 [====>.........................] - ETA: 5s - loss: 0.6875 - accuracy: 0.55 34/163 [=====>........................] - ETA: 4s - loss: 0.6847 - accuracy: 0.55 35/163 [=====>........................] - ETA: 4s - loss: 0.6847 - accuracy: 0.55 36/163 [=====>........................] - ETA: 5s - loss: 0.6840 - accuracy: 0.55 38/163 [=====>........................] - ETA: 5s - loss: 0.6849 - accuracy: 0.55 39/163 [======>.......................] - ETA: 5s - loss: 0.6850 - accuracy: 0.55 40/163 [======>.......................] - ETA: 5s - loss: 0.6833 - accuracy: 0.55 41/163 [======>.......................] - ETA: 5s - loss: 0.6839 - accuracy: 0.55 42/163 [======>.......................] - ETA: 5s - loss: 0.6841 - accuracy: 0.55 44/163 [=======>......................] - ETA: 5s - loss: 0.6845 - accuracy: 0.55 46/163 [=======>......................] - ETA: 4s - loss: 0.6847 - accuracy: 0.55 47/163 [=======>......................] - ETA: 4s - loss: 0.6855 - accuracy: 0.55 49/163 [========>.....................] - ETA: 4s - loss: 0.6860 - accuracy: 0.55 51/163 [========>.....................] - ETA: 4s - loss: 0.6864 - accuracy: 0.55 52/163 [========>.....................] - ETA: 4s - loss: 0.6858 - accuracy: 0.55 53/163 [========>.....................] - ETA: 4s - loss: 0.6859 - accuracy: 0.55 55/163 [=========>....................] - ETA: 4s - loss: 0.6850 - accuracy: 0.55 58/163 [=========>....................] - ETA: 4s - loss: 0.6846 - accuracy: 0.55 63/163 [==========>...................] - ETA: 4s - loss: 0.6840 - accuracy: 0.56 65/163 [==========>...................] - ETA: 3s - loss: 0.6840 - accuracy: 0.56 68/163 [===========>..................] - ETA: 3s - loss: 0.6838 - accuracy: 0.55 71/163 [============>.................] - ETA: 3s - loss: 0.6851 - accuracy: 0.55 74/163 [============>.................] - ETA: 3s - loss: 0.6851 - accuracy: 0.55 77/163 [=============>................] - ETA: 3s - loss: 0.6846 - accuracy: 0.55 80/163 [=============>................] - ETA: 3s - loss: 0.6848 - accuracy: 0.55 81/163 [=============>................] - ETA: 3s - loss: 0.6850 - accuracy: 0.55 83/163 [==============>...............] - ETA: 3s - loss: 0.6848 - accuracy: 0.55 87/163 [===============>..............] - ETA: 2s - loss: 0.6847 - accuracy: 0.55 91/163 [===============>..............] - ETA: 2s - loss: 0.6834 - accuracy: 0.56 94/163 [================>.............] - ETA: 2s - loss: 0.6841 - accuracy: 0.55 96/163 [================>.............] - ETA: 2s - loss: 0.6831 - accuracy: 0.56 97/163 [================>.............] - ETA: 2s - loss: 0.6833 - accuracy: 0.56 99/163 [=================>............] - ETA: 2s - loss: 0.6832 - accuracy: 0.56100/163 [=================>............] - ETA: 2s - loss: 0.6832 - accuracy: 0.56102/163 [=================>............] - ETA: 2s - loss: 0.6829 - accuracy: 0.56103/163 [=================>............] - ETA: 2s - loss: 0.6831 - accuracy: 0.56104/163 [==================>...........] - ETA: 2s - loss: 0.6829 - accuracy: 0.56107/163 [==================>...........] - ETA: 2s - loss: 0.6824 - accuracy: 0.56109/163 [===================>..........] - ETA: 1s - loss: 0.6831 - accuracy: 0.56112/163 [===================>..........] - ETA: 1s - loss: 0.6830 - accuracy: 0.56115/163 [====================>.........] - ETA: 1s - loss: 0.6834 - accuracy: 0.56116/163 [====================>.........] - ETA: 1s - loss: 0.6834 - accuracy: 0.56117/163 [====================>.........] - ETA: 1s - loss: 0.6835 - accuracy: 0.56118/163 [====================>.........] - ETA: 1s - loss: 0.6839 - accuracy: 0.55119/163 [====================>.........] - ETA: 1s - loss: 0.6839 - accuracy: 0.55120/163 [=====================>........] - ETA: 1s - loss: 0.6840 - accuracy: 0.55121/163 [=====================>........] - ETA: 1s - loss: 0.6840 - accuracy: 0.55122/163 [=====================>........] - ETA: 1s - loss: 0.6841 - accuracy: 0.55124/163 [=====================>........] - ETA: 1s - loss: 0.6841 - accuracy: 0.55127/163 [======================>.......] - ETA: 1s - loss: 0.6844 - accuracy: 0.55130/163 [======================>.......] - ETA: 1s - loss: 0.6848 - accuracy: 0.55131/163 [=======================>......] - ETA: 1s - loss: 0.6847 - accuracy: 0.55133/163 [=======================>......] - ETA: 1s - loss: 0.6846 - accuracy: 0.55135/163 [=======================>......] - ETA: 1s - loss: 0.6844 - accuracy: 0.56137/163 [========================>.....] - ETA: 0s - loss: 0.6843 - accuracy: 0.56138/163 [========================>.....] - ETA: 0s - loss: 0.6843 - accuracy: 0.55140/163 [========================>.....] - ETA: 0s - loss: 0.6844 - accuracy: 0.55146/163 [=========================>....] - ETA: 0s - loss: 0.6844 - accuracy: 0.55152/163 [==========================>...] - ETA: 0s - loss: 0.6844 - accuracy: 0.55157/163 [===========================>..] - ETA: 0s - loss: 0.6844 - accuracy: 0.55160/163 [============================>.] - ETA: 0s - loss: 0.6839 - accuracy: 0.55162/163 [============================>.] - ETA: 0s - loss: 0.6839 - accuracy: 0.56163/163 [==============================] - 6s 39ms/step - loss: 0.6840 - accuracy: 0.5597 - val_loss: 0.6990 - val_accuracy: 0.5047\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: aceff0a5df45af79175ed6a1c296d7d3</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.5114195942878723</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-n_layers: 5</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-n_nodes: 17</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "6/163 [============>.................] - ETA: 3s - loss: 0.6926 - accuracy: 0.51 77/163 [=============>................] - ETA: 3s - loss: 0.6929 - accuracy: 0.51 79/163 [=============>................] - ETA: 3s - loss: 0.6928 - accuracy: 0.51 80/163 [=============>................] - ETA: 3s - loss: 0.6929 - accuracy: 0.51 81/163 [=============>................] - ETA: 3s - loss: 0.6931 - accuracy: 0.51 82/163 [==============>...............] - ETA: 3s - loss: 0.6931 - accuracy: 0.50 84/163 [==============>...............] - ETA: 3s - loss: 0.6931 - accuracy: 0.50 86/163 [==============>...............] - ETA: 3s - loss: 0.6930 - accuracy: 0.51 87/163 [===============>..............] - ETA: 3s - loss: 0.6930 - accuracy: 0.51 88/163 [===============>..............] - ETA: 3s - loss: 0.6931 - accuracy: 0.50 91/163 [===============>..............] - ETA: 3s - loss: 0.6931 - accuracy: 0.50 95/163 [================>.............] - ETA: 3s - loss: 0.6932 - accuracy: 0.50 97/163 [================>.............] - ETA: 2s - loss: 0.6933 - accuracy: 0.50 98/163 [=================>............] - ETA: 2s - loss: 0.6933 - accuracy: 0.50103/163 [=================>............] - ETA: 2s - loss: 0.6932 - accuracy: 0.50105/163 [==================>...........] - ETA: 2s - loss: 0.6932 - accuracy: 0.50110/163 [===================>..........] - ETA: 2s - loss: 0.6932 - accuracy: 0.50114/163 [===================>..........] - ETA: 1s - loss: 0.6933 - accuracy: 0.50117/163 [====================>.........] - ETA: 1s - loss: 0.6932 - accuracy: 0.50119/163 [====================>.........] - ETA: 1s - loss: 0.6932 - accuracy: 0.50125/163 [======================>.......] - ETA: 1s - loss: 0.6934 - accuracy: 0.50127/163 [======================>.......] - ETA: 1s - loss: 0.6934 - accuracy: 0.50132/163 [=======================>......] - ETA: 1s - loss: 0.6934 - accuracy: 0.50133/163 [=======================>......] - ETA: 1s - loss: 0.6934 - accuracy: 0.50135/163 [=======================>......] - ETA: 1s - loss: 0.6933 - accuracy: 0.50137/163 [========================>.....] - ETA: 0s - loss: 0.6933 - accuracy: 0.50142/163 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.50146/163 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.50150/163 [==========================>...] - ETA: 0s - loss: 0.6930 - accuracy: 0.51152/163 [==========================>...] - ETA: 0s - loss: 0.6930 - accuracy: 0.51154/163 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.50155/163 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.50157/163 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.50158/163 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.50160/163 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.50163/163 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.50163/163 [==============================] - 7s 41ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6929 - val_accuracy: 0.5069\nEpoch 3/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6894 - accuracy: 0.59  2/163 [..............................] - ETA: 5s - loss: 0.6911 - accuracy: 0.54  3/163 [..............................] - ETA: 8s - loss: 0.6892 - accuracy: 0.61  4/163 [..............................] - ETA: 8s - loss: 0.6908 - accuracy: 0.57  5/163 [..............................] - ETA: 9s - loss: 0.6925 - accuracy: 0.53  6/163 [>.............................] - ETA: 11s - loss: 0.6934 - accuracy: 0.510  7/163 [>.............................] - ETA: 10s - loss: 0.6940 - accuracy: 0.495  8/163 [>.............................] - ETA: 10s - loss: 0.6935 - accuracy: 0.507  9/163 [>.............................] - ETA: 11s - loss: 0.6931 - accuracy: 0.510 12/163 [=>............................] - ETA: 8s - loss: 0.6926 - accuracy: 0.51 14/163 [=>............................] - ETA: 9s - loss: 0.6929 - accuracy: 0.51 15/163 [=>............................] - ETA: 9s - loss: 0.6930 - accuracy: 0.51 16/163 [=>............................] - ETA: 8s - loss: 0.6928 - accuracy: 0.51 18/163 [==>...........................] - ETA: 8s - loss: 0.6928 - accuracy: 0.51 22/163 [===>..........................] - ETA: 7s - loss: 0.6927 - accuracy: 0.51 26/163 [===>..........................] - ETA: 6s - loss: 0.6925 - accuracy: 0.52 29/163 [====>.........................] - ETA: 5s - loss: 0.6928 - accuracy: 0.52 33/163 [=====>........................] - ETA: 5s - loss: 0.6926 - accuracy: 0.52 34/163 [=====>........................] - ETA: 5s - loss: 0.6927 - accuracy: 0.52 35/163 [=====>........................] - ETA: 5s - loss: 0.6928 - accuracy: 0.52 38/163 [=====>........................] - ETA: 5s - loss: 0.6925 - accuracy: 0.52 39/163 [======>.......................] - ETA: 5s - loss: 0.6924 - accuracy: 0.52 45/163 [=======>......................] - ETA: 4s - loss: 0.6922 - accuracy: 0.53 47/163 [=======>......................] - ETA: 4s - loss: 0.6918 - accuracy: 0.54 49/163 [========>.....................] - ETA: 4s - loss: 0.6915 - accuracy: 0.54 50/163 [========>.....................] - ETA: 4s - loss: 0.6915 - accuracy: 0.54 51/163 [========>.....................] - ETA: 4s - loss: 0.6915 - accuracy: 0.54 54/163 [========>.....................] - ETA: 4s - loss: 0.6918 - accuracy: 0.54 56/163 [=========>....................] - ETA: 4s - loss: 0.6914 - accuracy: 0.54 57/163 [=========>....................] - ETA: 4s - loss: 0.6915 - accuracy: 0.54 59/163 [=========>....................] - ETA: 4s - loss: 0.6914 - accuracy: 0.54 61/163 [==========>...................] - ETA: 3s - loss: 0.6915 - accuracy: 0.54 65/163 [==========>...................] - ETA: 3s - loss: 0.6912 - accuracy: 0.54 68/163 [===========>..................] - ETA: 3s - loss: 0.6910 - accuracy: 0.55 71/163 [============>.................] - ETA: 3s - loss: 0.6909 - accuracy: 0.54 75/163 [============>.................] - ETA: 3s - loss: 0.6908 - accuracy: 0.54 78/163 [=============>................] - ETA: 2s - loss: 0.6914 - accuracy: 0.54 79/163 [=============>................] - ETA: 2s - loss: 0.6910 - accuracy: 0.54 80/163 [=============>................] - ETA: 2s - loss: 0.6910 - accuracy: 0.54 81/163 [=============>................] - ETA: 2s - loss: 0.6909 - accuracy: 0.54 83/163 [==============>...............] - ETA: 2s - loss: 0.6909 - accuracy: 0.54 84/163 [==============>...............] - ETA: 2s - loss: 0.6911 - accuracy: 0.54 86/163 [==============>...............] - ETA: 2s - loss: 0.6909 - accuracy: 0.54 87/163 [===============>..............] - ETA: 2s - loss: 0.6905 - accuracy: 0.54 88/163 [===============>..............] - ETA: 2s - loss: 0.6907 - accuracy: 0.54 89/163 [===============>..............] - ETA: 2s - loss: 0.6910 - accuracy: 0.54 91/163 [===============>..............] - ETA: 2s - loss: 0.6917 - accuracy: 0.54 92/163 [===============>..............] - ETA: 2s - loss: 0.6915 - accuracy: 0.54 93/163 [================>.............] - ETA: 2s - loss: 0.6917 - accuracy: 0.54 95/163 [================>.............] - ETA: 2s - loss: 0.6918 - accuracy: 0.54 97/163 [================>.............] - ETA: 2s - loss: 0.6919 - accuracy: 0.53 99/163 [=================>............] - ETA: 2s - loss: 0.6919 - accuracy: 0.53104/163 [==================>...........] - ETA: 2s - loss: 0.6918 - accuracy: 0.53107/163 [==================>...........] - ETA: 1s - loss: 0.6917 - accuracy: 0.54111/163 [===================>..........] - ETA: 1s - loss: 0.6916 - accuracy: 0.53113/163 [===================>..........] - ETA: 1s - loss: 0.6916 - accuracy: 0.53114/163 [===================>..........] - ETA: 1s - loss: 0.6915 - accuracy: 0.53115/163 [====================>.........] - ETA: 1s - loss: 0.6915 - accuracy: 0.53120/163 [=====================>........] - ETA: 1s - loss: 0.6917 - accuracy: 0.53122/163 [=====================>........] - ETA: 1s - loss: 0.6916 - accuracy: 0.53127/163 [======================>.......] - ETA: 1s - loss: 0.6916 - accuracy: 0.53128/163 [======================>.......] - ETA: 1s - loss: 0.6917 - accuracy: 0.53130/163 [======================>.......] - ETA: 1s - loss: 0.6917 - accuracy: 0.53136/163 [========================>.....] - ETA: 0s - loss: 0.6916 - accuracy: 0.53144/163 [=========================>....] - ETA: 0s - loss: 0.6914 - accuracy: 0.53145/163 [=========================>....] - ETA: 0s - loss: 0.6912 - accuracy: 0.53151/163 [==========================>...] - ETA: 0s - loss: 0.6913 - accuracy: 0.53154/163 [===========================>..] - ETA: 0s - loss: 0.6914 - accuracy: 0.53155/163 [===========================>..] - ETA: 0s - loss: 0.6914 - accuracy: 0.53156/163 [===========================>..] - ETA: 0s - loss: 0.6913 - accuracy: 0.53160/163 [============================>.] - ETA: 0s - loss: 0.6913 - accuracy: 0.53161/163 [============================>.] - ETA: 0s - loss: 0.6913 - accuracy: 0.53162/163 [============================>.] - ETA: 0s - loss: 0.6913 - accuracy: 0.53163/163 [==============================] - ETA: 0s - loss: 0.6915 - accuracy: 0.53163/163 [==============================] - 6s 38ms/step - loss: 0.6915 - accuracy: 0.5315 - val_loss: 0.6953 - val_accuracy: 0.5069\nEpoch 4/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6988 - accuracy: 0.56  2/163 [..............................] - ETA: 11s - loss: 0.6950 - accuracy: 0.531  8/163 [>.............................] - ETA: 3s - loss: 0.6926 - accuracy: 0.52 12/163 [=>............................] - ETA: 3s - loss: 0.6925 - accuracy: 0.49 14/163 [=>............................] - ETA: 3s - loss: 0.6922 - accuracy: 0.50 17/163 [==>...........................] - ETA: 3s - loss: 0.6923 - accuracy: 0.50 21/163 [==>...........................] - ETA: 3s - loss: 0.6919 - accuracy: 0.51 24/163 [===>..........................] - ETA: 3s - loss: 0.6917 - accuracy: 0.51 26/163 [===>..........................] - ETA: 3s - loss: 0.6917 - accuracy: 0.51 28/163 [====>.........................] - ETA: 3s - loss: 0.6915 - accuracy: 0.52 30/163 [====>.........................] - ETA: 3s - loss: 0.6917 - accuracy: 0.52 32/163 [====>.........................] - ETA: 3s - loss: 0.6921 - accuracy: 0.51 34/163 [=====>........................] - ETA: 3s - loss: 0.6918 - accuracy: 0.51 38/163 [=====>........................] - ETA: 3s - loss: 0.6914 - accuracy: 0.51 40/163 [======>.......................] - ETA: 3s - loss: 0.6918 - accuracy: 0.51 44/163 [=======>......................] - ETA: 2s - loss: 0.6916 - accuracy: 0.51 45/163 [=======>......................] - ETA: 2s - loss: 0.6912 - accuracy: 0.51 46/163 [=======>......................] - ETA: 2s - loss: 0.6913 - accuracy: 0.51 48/163 [=======>......................] - ETA: 2s - loss: 0.6910 - accuracy: 0.52 50/163 [========>.....................] - ETA: 2s - loss: 0.6905 - accuracy: 0.52 55/163 [=========>....................] - ETA: 2s - loss: 0.6906 - accuracy: 0.52 57/163 [=========>....................] - ETA: 2s - loss: 0.6907 - accuracy: 0.52 60/163 [==========>...................] - ETA: 2s - loss: 0.6905 - accuracy: 0.52 62/163 [==========>...................] - ETA: 2s - loss: 0.6905 - accuracy: 0.52 63/163 [==========>...................] - ETA: 2s - loss: 0.6904 - accuracy: 0.52 64/163 [==========>...................] - ETA: 2s - loss: 0.6903 - accuracy: 0.52 65/163 [==========>...................] - ETA: 2s - loss: 0.6903 - accuracy: 0.52 66/163 [===========>..................] - ETA: 2s - loss: 0.6905 - accuracy: 0.52 67/163 [===========>..................] - ETA: 2s - loss: 0.6904 - accuracy: 0.52 68/163 [===========>..................] - ETA: 2s - loss: 0.6902 - accuracy: 0.52 69/163 [===========>..................] - ETA: 2s - loss: 0.6901 - accuracy: 0.52 70/163 [===========>..................] - ETA: 2s - loss: 0.6902 - accuracy: 0.52 71/163 [============>.................] - ETA: 2s - loss: 0.6905 - accuracy: 0.52 72/163 [============>.................] - ETA: 2s - loss: 0.6905 - accuracy: 0.52 73/163 [============>.................] - ETA: 2s - loss: 0.6904 - accuracy: 0.52 76/163 [============>.................] - ETA: 2s - loss: 0.6904 - accuracy: 0.52 77/163 [=============>................] - ETA: 2s - loss: 0.6903 - accuracy: 0.52 80/163 [=============>................] - ETA: 2s - loss: 0.6905 - accuracy: 0.52 83/163 [==============>...............] - ETA: 2s - loss: 0.6904 - accuracy: 0.52 84/163 [==============>...............] - ETA: 2s - loss: 0.6906 - accuracy: 0.52 85/163 [==============>...............] - ETA: 2s - loss: 0.6907 - accuracy: 0.52 87/163 [===============>..............] - ETA: 2s - loss: 0.6903 - accuracy: 0.52 90/163 [===============>..............] - ETA: 2s - loss: 0.6902 - accuracy: 0.52 91/163 [===============>..............] - ETA: 2s - loss: 0.6902 - accuracy: 0.52 93/163 [================>.............] - ETA: 2s - loss: 0.6900 - accuracy: 0.52 94/163 [================>.............] - ETA: 2s - loss: 0.6899 - accuracy: 0.52 95/163 [================>.............] - ETA: 2s - loss: 0.6899 - accuracy: 0.52 99/163 [=================>............] - ETA: 2s - loss: 0.6899 - accuracy: 0.52102/163 [=================>............] - ETA: 2s - loss: 0.6899 - accuracy: 0.52107/163 [==================>...........] - ETA: 1s - loss: 0.6896 - accuracy: 0.52109/163 [===================>..........] - ETA: 1s - loss: 0.6892 - accuracy: 0.53110/163 [===================>..........] - ETA: 1s - loss: 0.6889 - accuracy: 0.53114/163 [===================>..........] - ETA: 1s - loss: 0.6895 - accuracy: 0.52118/163 [====================>.........] - ETA: 1s - loss: 0.6897 - accuracy: 0.52120/163 [=====================>........] - ETA: 1s - loss: 0.6897 - accuracy: 0.52127/163 [======================>.......] - ETA: 1s - loss: 0.6897 - accuracy: 0.52132/163 [=======================>......] - ETA: 0s - loss: 0.6896 - accuracy: 0.53137/163 [========================>.....] - ETA: 0s - loss: 0.6896 - accuracy: 0.53140/163 [========================>.....] - ETA: 0s - loss: 0.6897 - accuracy: 0.53141/163 [========================>.....] - ETA: 0s - loss: 0.6897 - accuracy: 0.53142/163 [=========================>....] - ETA: 0s - loss: 0.6898 - accuracy: 0.53146/163 [=========================>....] - ETA: 0s - loss: 0.6898 - accuracy: 0.52147/163 [==========================>...] - ETA: 0s - loss: 0.6898 - accuracy: 0.52150/163 [==========================>...] - ETA: 0s - loss: 0.6900 - accuracy: 0.52152/163 [==========================>...] - ETA: 0s - loss: 0.6899 - accuracy: 0.52155/163 [===========================>..] - ETA: 0s - loss: 0.6897 - accuracy: 0.53157/163 [===========================>..] - ETA: 0s - loss: 0.6896 - accuracy: 0.53159/163 [============================>.] - ETA: 0s - loss: 0.6894 - accuracy: 0.53160/163 [============================>.] - ETA: 0s - loss: 0.6894 - accuracy: 0.53161/163 [============================>.] - ETA: 0s - loss: 0.6894 - accuracy: 0.53162/163 [============================>.] - ETA: 0s - loss: 0.6893 - accuracy: 0.53163/163 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.53163/163 [==============================] - 6s 37ms/step - loss: 0.6893 - accuracy: 0.5334 - val_loss: 0.6995 - val_accuracy: 0.5029\nEpoch 5/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6955 - accuracy: 0.43  5/163 [..............................] - ETA: 1s - loss: 0.6928 - accuracy: 0.52  7/163 [>.............................] - ETA: 2s - loss: 0.6936 - accuracy: 0.52 10/163 [>.............................] - ETA: 2s - loss: 0.6935 - accuracy: 0.49 13/163 [=>............................] - ETA: 2s - loss: 0.6901 - accuracy: 0.51 19/163 [==>...........................] - ETA: 2s - loss: 0.6860 - accuracy: 0.54 24/163 [===>..........................] - ETA: 2s - loss: 0.6868 - accuracy: 0.53 26/163 [===>..........................] - ETA: 2s - loss: 0.6869 - accuracy: 0.53 31/163 [====>.........................] - ETA: 2s - loss: 0.6883 - accuracy: 0.53 33/163 [=====>........................] - ETA: 2s - loss: 0.6877 - accuracy: 0.53 35/163 [=====>........................] - ETA: 2s - loss: 0.6876 - accuracy: 0.53 36/163 [=====>........................] - ETA: 2s - loss: 0.6877 - accuracy: 0.53 38/163 [=====>........................] - ETA: 2s - loss: 0.6881 - accuracy: 0.53 42/163 [======>.......................] - ETA: 2s - loss: 0.6865 - accuracy: 0.53 45/163 [=======>......................] - ETA: 2s - loss: 0.6864 - accuracy: 0.53 46/163 [=======>......................] - ETA: 2s - loss: 0.6870 - accuracy: 0.53 49/163 [========>.....................] - ETA: 2s - loss: 0.6872 - accuracy: 0.53 50/163 [========>.....................] - ETA: 2s - loss: 0.6872 - accuracy: 0.53 51/163 [========>.....................] - ETA: 2s - loss: 0.6874 - accuracy: 0.53 52/163 [========>.....................] - ETA: 2s - loss: 0.6876 - accuracy: 0.53 53/163 [========>.....................] - ETA: 2s - loss: 0.6879 - accuracy: 0.53 55/163 [=========>....................] - ETA: 2s - loss: 0.6879 - accuracy: 0.53 59/163 [=========>....................] - ETA: 2s - loss: 0.6870 - accuracy: 0.54 62/163 [==========>...................] - ETA: 2s - loss: 0.6873 - accuracy: 0.53 66/163 [===========>..................] - ETA: 2s - loss: 0.6866 - accuracy: 0.54 71/163 [============>.................] - ETA: 2s - loss: 0.6870 - accuracy: 0.53 77/163 [=============>................] - ETA: 1s - loss: 0.6871 - accuracy: 0.54 81/163 [=============>................] - ETA: 1s - loss: 0.6878 - accuracy: 0.53 84/163 [==============>...............] - ETA: 1s - loss: 0.6880 - accuracy: 0.53 86/163 [==============>...............] - ETA: 1s - loss: 0.6877 - accuracy: 0.53 88/163 [===============>..............] - ETA: 1s - loss: 0.6880 - accuracy: 0.53 91/163 [===============>..............] - ETA: 1s - loss: 0.6877 - accuracy: 0.53 95/163 [================>.............] - ETA: 1s - loss: 0.6874 - accuracy: 0.54 96/163 [================>.............] - ETA: 1s - loss: 0.6873 - accuracy: 0.54 98/163 [=================>............] - ETA: 1s - loss: 0.6874 - accuracy: 0.54104/163 [==================>...........] - ETA: 1s - loss: 0.6868 - accuracy: 0.54107/163 [==================>...........] - ETA: 1s - loss: 0.6868 - accuracy: 0.54108/163 [==================>...........] - ETA: 1s - loss: 0.6869 - accuracy: 0.54111/163 [===================>..........] - ETA: 1s - loss: 0.6867 - accuracy: 0.54112/163 [===================>..........] - ETA: 1s - loss: 0.6869 - accuracy: 0.54116/163 [====================>.........] - ETA: 1s - loss: 0.6867 - accuracy: 0.54120/163 [=====================>........] - ETA: 1s - loss: 0.6867 - accuracy: 0.54123/163 [=====================>........] - ETA: 0s - loss: 0.6872 - accuracy: 0.54125/163 [======================>.......] - ETA: 0s - loss: 0.6874 - accuracy: 0.54127/163 [======================>.......] - ETA: 0s - loss: 0.6874 - accuracy: 0.54130/163 [======================>.......] - ETA: 0s - loss: 0.6871 - accuracy: 0.54134/163 [=======================>......] - ETA: 0s - loss: 0.6875 - accuracy: 0.54140/163 [========================>.....] - ETA: 0s - loss: 0.6868 - accuracy: 0.54144/163 [=========================>....] - ETA: 0s - loss: 0.6870 - accuracy: 0.54145/163 [=========================>....] - ETA: 0s - loss: 0.6870 - accuracy: 0.54148/163 [==========================>...] - ETA: 0s - loss: 0.6871 - accuracy: 0.54152/163 [==========================>...] - ETA: 0s - loss: 0.6867 - accuracy: 0.54157/163 [===========================>..] - ETA: 0s - loss: 0.6867 - accuracy: 0.54160/163 [============================>.] - ETA: 0s - loss: 0.6866 - accuracy: 0.54163/163 [==============================] - ETA: 0s - loss: 0.6865 - accuracy: 0.54163/163 [==============================] - 4s 25ms/step - loss: 0.6865 - accuracy: 0.5466 - val_loss: 0.6969 - val_accuracy: 0.5132\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: 85e9f8d4c35f605587eed447e73ef9a6</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.5132109522819519</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-n_layers: 6</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-n_nodes: 12</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "=======>.................] - ETA: 1s - loss: 0.6926 - accuracy: 0.50 75/163 [============>.................] - ETA: 1s - loss: 0.6925 - accuracy: 0.50 76/163 [============>.................] - ETA: 1s - loss: 0.6924 - accuracy: 0.51 82/163 [==============>...............] - ETA: 1s - loss: 0.6926 - accuracy: 0.50 87/163 [===============>..............] - ETA: 1s - loss: 0.6927 - accuracy: 0.50 92/163 [===============>..............] - ETA: 1s - loss: 0.6926 - accuracy: 0.51 94/163 [================>.............] - ETA: 1s - loss: 0.6926 - accuracy: 0.51 98/163 [=================>............] - ETA: 1s - loss: 0.6927 - accuracy: 0.50101/163 [=================>............] - ETA: 1s - loss: 0.6926 - accuracy: 0.50102/163 [=================>............] - ETA: 1s - loss: 0.6926 - accuracy: 0.50103/163 [=================>............] - ETA: 1s - loss: 0.6925 - accuracy: 0.51106/163 [==================>...........] - ETA: 1s - loss: 0.6924 - accuracy: 0.51107/163 [==================>...........] - ETA: 1s - loss: 0.6924 - accuracy: 0.51110/163 [===================>..........] - ETA: 1s - loss: 0.6924 - accuracy: 0.51111/163 [===================>..........] - ETA: 1s - loss: 0.6924 - accuracy: 0.51113/163 [===================>..........] - ETA: 1s - loss: 0.6924 - accuracy: 0.51114/163 [===================>..........] - ETA: 1s - loss: 0.6924 - accuracy: 0.51115/163 [====================>.........] - ETA: 1s - loss: 0.6923 - accuracy: 0.51116/163 [====================>.........] - ETA: 1s - loss: 0.6923 - accuracy: 0.51117/163 [====================>.........] - ETA: 1s - loss: 0.6923 - accuracy: 0.51118/163 [====================>.........] - ETA: 1s - loss: 0.6922 - accuracy: 0.51122/163 [=====================>........] - ETA: 0s - loss: 0.6921 - accuracy: 0.51124/163 [=====================>........] - ETA: 0s - loss: 0.6920 - accuracy: 0.51126/163 [======================>.......] - ETA: 0s - loss: 0.6918 - accuracy: 0.51127/163 [======================>.......] - ETA: 0s - loss: 0.6919 - accuracy: 0.51129/163 [======================>.......] - ETA: 0s - loss: 0.6919 - accuracy: 0.51133/163 [=======================>......] - ETA: 0s - loss: 0.6920 - accuracy: 0.51137/163 [========================>.....] - ETA: 0s - loss: 0.6919 - accuracy: 0.51138/163 [========================>.....] - ETA: 0s - loss: 0.6920 - accuracy: 0.51141/163 [========================>.....] - ETA: 0s - loss: 0.6921 - accuracy: 0.51143/163 [=========================>....] - ETA: 0s - loss: 0.6920 - accuracy: 0.51146/163 [=========================>....] - ETA: 0s - loss: 0.6920 - accuracy: 0.51148/163 [==========================>...] - ETA: 0s - loss: 0.6919 - accuracy: 0.51150/163 [==========================>...] - ETA: 0s - loss: 0.6919 - accuracy: 0.51151/163 [==========================>...] - ETA: 0s - loss: 0.6919 - accuracy: 0.51152/163 [==========================>...] - ETA: 0s - loss: 0.6919 - accuracy: 0.51155/163 [===========================>..] - ETA: 0s - loss: 0.6921 - accuracy: 0.51157/163 [===========================>..] - ETA: 0s - loss: 0.6921 - accuracy: 0.51159/163 [============================>.] - ETA: 0s - loss: 0.6922 - accuracy: 0.51161/163 [============================>.] - ETA: 0s - loss: 0.6921 - accuracy: 0.51163/163 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.51163/163 [==============================] - 5s 32ms/step - loss: 0.6922 - accuracy: 0.5155 - val_loss: 0.6964 - val_accuracy: 0.4859\nEpoch 4/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6967 - accuracy: 0.53  2/163 [..............................] - ETA: 4s - loss: 0.7019 - accuracy: 0.46  3/163 [..............................] - ETA: 6s - loss: 0.6967 - accuracy: 0.50  5/163 [..............................] - ETA: 5s - loss: 0.6958 - accuracy: 0.48  6/163 [>.............................] - ETA: 5s - loss: 0.6948 - accuracy: 0.51  8/163 [>.............................] - ETA: 5s - loss: 0.6918 - accuracy: 0.54  9/163 [>.............................] - ETA: 5s - loss: 0.6917 - accuracy: 0.54 11/163 [=>............................] - ETA: 5s - loss: 0.6917 - accuracy: 0.54 13/163 [=>............................] - ETA: 5s - loss: 0.6927 - accuracy: 0.52 16/163 [=>............................] - ETA: 5s - loss: 0.6920 - accuracy: 0.52 19/163 [==>...........................] - ETA: 4s - loss: 0.6914 - accuracy: 0.52 21/163 [==>...........................] - ETA: 4s - loss: 0.6908 - accuracy: 0.53 23/163 [===>..........................] - ETA: 4s - loss: 0.6911 - accuracy: 0.52 26/163 [===>..........................] - ETA: 4s - loss: 0.6912 - accuracy: 0.52 28/163 [====>.........................] - ETA: 4s - loss: 0.6912 - accuracy: 0.52 32/163 [====>.........................] - ETA: 3s - loss: 0.6913 - accuracy: 0.53 34/163 [=====>........................] - ETA: 3s - loss: 0.6912 - accuracy: 0.53 37/163 [=====>........................] - ETA: 3s - loss: 0.6910 - accuracy: 0.53 38/163 [=====>........................] - ETA: 3s - loss: 0.6908 - accuracy: 0.53 40/163 [======>.......................] - ETA: 3s - loss: 0.6907 - accuracy: 0.53 42/163 [======>.......................] - ETA: 3s - loss: 0.6907 - accuracy: 0.53 44/163 [=======>......................] - ETA: 3s - loss: 0.6905 - accuracy: 0.53 45/163 [=======>......................] - ETA: 3s - loss: 0.6905 - accuracy: 0.53 46/163 [=======>......................] - ETA: 3s - loss: 0.6908 - accuracy: 0.53 47/163 [=======>......................] - ETA: 3s - loss: 0.6908 - accuracy: 0.53 49/163 [========>.....................] - ETA: 3s - loss: 0.6906 - accuracy: 0.53 50/163 [========>.....................] - ETA: 3s - loss: 0.6905 - accuracy: 0.53 51/163 [========>.....................] - ETA: 4s - loss: 0.6905 - accuracy: 0.53 52/163 [========>.....................] - ETA: 4s - loss: 0.6905 - accuracy: 0.53 53/163 [========>.....................] - ETA: 4s - loss: 0.6903 - accuracy: 0.53 54/163 [========>.....................] - ETA: 5s - loss: 0.6904 - accuracy: 0.53 55/163 [=========>....................] - ETA: 5s - loss: 0.6904 - accuracy: 0.53 57/163 [=========>....................] - ETA: 5s - loss: 0.6904 - accuracy: 0.53 58/163 [=========>....................] - ETA: 5s - loss: 0.6903 - accuracy: 0.53 59/163 [=========>....................] - ETA: 5s - loss: 0.6905 - accuracy: 0.53 61/163 [==========>...................] - ETA: 5s - loss: 0.6907 - accuracy: 0.53 63/163 [==========>...................] - ETA: 5s - loss: 0.6906 - accuracy: 0.53 64/163 [==========>...................] - ETA: 4s - loss: 0.6907 - accuracy: 0.53 65/163 [==========>...................] - ETA: 4s - loss: 0.6906 - accuracy: 0.53 66/163 [===========>..................] - ETA: 4s - loss: 0.6908 - accuracy: 0.53 67/163 [===========>..................] - ETA: 4s - loss: 0.6908 - accuracy: 0.53 68/163 [===========>..................] - ETA: 4s - loss: 0.6907 - accuracy: 0.53 69/163 [===========>..................] - ETA: 4s - loss: 0.6905 - accuracy: 0.53 70/163 [===========>..................] - ETA: 4s - loss: 0.6902 - accuracy: 0.53 71/163 [============>.................] - ETA: 4s - loss: 0.6903 - accuracy: 0.53 72/163 [============>.................] - ETA: 4s - loss: 0.6903 - accuracy: 0.53 73/163 [============>.................] - ETA: 4s - loss: 0.6902 - accuracy: 0.53 74/163 [============>.................] - ETA: 4s - loss: 0.6903 - accuracy: 0.53 75/163 [============>.................] - ETA: 4s - loss: 0.6904 - accuracy: 0.53 77/163 [=============>................] - ETA: 4s - loss: 0.6900 - accuracy: 0.53 78/163 [=============>................] - ETA: 4s - loss: 0.6901 - accuracy: 0.53 79/163 [=============>................] - ETA: 4s - loss: 0.6899 - accuracy: 0.53 80/163 [=============>................] - ETA: 4s - loss: 0.6899 - accuracy: 0.53 81/163 [=============>................] - ETA: 4s - loss: 0.6898 - accuracy: 0.54 82/163 [==============>...............] - ETA: 4s - loss: 0.6897 - accuracy: 0.54 83/163 [==============>...............] - ETA: 4s - loss: 0.6898 - accuracy: 0.53 85/163 [==============>...............] - ETA: 4s - loss: 0.6896 - accuracy: 0.54 86/163 [==============>...............] - ETA: 4s - loss: 0.6897 - accuracy: 0.54 87/163 [===============>..............] - ETA: 4s - loss: 0.6898 - accuracy: 0.53 88/163 [===============>..............] - ETA: 4s - loss: 0.6898 - accuracy: 0.53 89/163 [===============>..............] - ETA: 4s - loss: 0.6898 - accuracy: 0.53 90/163 [===============>..............] - ETA: 4s - loss: 0.6898 - accuracy: 0.53 91/163 [===============>..............] - ETA: 4s - loss: 0.6900 - accuracy: 0.53 92/163 [===============>..............] - ETA: 4s - loss: 0.6901 - accuracy: 0.53 94/163 [================>.............] - ETA: 4s - loss: 0.6899 - accuracy: 0.53 97/163 [================>.............] - ETA: 3s - loss: 0.6898 - accuracy: 0.53100/163 [=================>............] - ETA: 3s - loss: 0.6901 - accuracy: 0.53102/163 [=================>............] - ETA: 3s - loss: 0.6900 - accuracy: 0.53104/163 [==================>...........] - ETA: 3s - loss: 0.6898 - accuracy: 0.53105/163 [==================>...........] - ETA: 3s - loss: 0.6897 - accuracy: 0.53106/163 [==================>...........] - ETA: 3s - loss: 0.6896 - accuracy: 0.53107/163 [==================>...........] - ETA: 3s - loss: 0.6895 - accuracy: 0.53108/163 [==================>...........] - ETA: 3s - loss: 0.6894 - accuracy: 0.53109/163 [===================>..........] - ETA: 3s - loss: 0.6893 - accuracy: 0.53111/163 [===================>..........] - ETA: 2s - loss: 0.6894 - accuracy: 0.53113/163 [===================>..........] - ETA: 2s - loss: 0.6896 - accuracy: 0.53115/163 [====================>.........] - ETA: 2s - loss: 0.6896 - accuracy: 0.53116/163 [====================>.........] - ETA: 2s - loss: 0.6896 - accuracy: 0.53119/163 [====================>.........] - ETA: 2s - loss: 0.6895 - accuracy: 0.53121/163 [=====================>........] - ETA: 2s - loss: 0.6897 - accuracy: 0.53122/163 [=====================>........] - ETA: 2s - loss: 0.6899 - accuracy: 0.53123/163 [=====================>........] - ETA: 2s - loss: 0.6899 - accuracy: 0.53124/163 [=====================>........] - ETA: 2s - loss: 0.6899 - accuracy: 0.53126/163 [======================>.......] - ETA: 2s - loss: 0.6898 - accuracy: 0.53127/163 [======================>.......] - ETA: 2s - loss: 0.6899 - accuracy: 0.53128/163 [======================>.......] - ETA: 1s - loss: 0.6900 - accuracy: 0.53129/163 [======================>.......] - ETA: 1s - loss: 0.6903 - accuracy: 0.53130/163 [======================>.......] - ETA: 1s - loss: 0.6903 - accuracy: 0.53131/163 [=======================>......] - ETA: 1s - loss: 0.6902 - accuracy: 0.53132/163 [=======================>......] - ETA: 1s - loss: 0.6902 - accuracy: 0.53133/163 [=======================>......] - ETA: 1s - loss: 0.6902 - accuracy: 0.53135/163 [=======================>......] - ETA: 1s - loss: 0.6901 - accuracy: 0.53136/163 [========================>.....] - ETA: 1s - loss: 0.6901 - accuracy: 0.53137/163 [========================>.....] - ETA: 1s - loss: 0.6901 - accuracy: 0.53140/163 [========================>.....] - ETA: 1s - loss: 0.6902 - accuracy: 0.53144/163 [=========================>....] - ETA: 1s - loss: 0.6901 - accuracy: 0.53147/163 [==========================>...] - ETA: 0s - loss: 0.6900 - accuracy: 0.53148/163 [==========================>...] - ETA: 0s - loss: 0.6899 - accuracy: 0.53151/163 [==========================>...] - ETA: 0s - loss: 0.6901 - accuracy: 0.53153/163 [===========================>..] - ETA: 0s - loss: 0.6901 - accuracy: 0.53154/163 [===========================>..] - ETA: 0s - loss: 0.6901 - accuracy: 0.53157/163 [===========================>..] - ETA: 0s - loss: 0.6900 - accuracy: 0.53158/163 [============================>.] - ETA: 0s - loss: 0.6899 - accuracy: 0.53160/163 [============================>.] - ETA: 0s - loss: 0.6899 - accuracy: 0.53161/163 [============================>.] - ETA: 0s - loss: 0.6900 - accuracy: 0.53163/163 [==============================] - 9s 58ms/step - loss: 0.6903 - accuracy: 0.5332 - val_loss: 0.6994 - val_accuracy: 0.5052\nEpoch 5/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6916 - accuracy: 0.56  2/163 [..............................] - ETA: 4s - loss: 0.6893 - accuracy: 0.53  4/163 [..............................] - ETA: 4s - loss: 0.6790 - accuracy: 0.60  8/163 [>.............................] - ETA: 3s - loss: 0.6724 - accuracy: 0.60  9/163 [>.............................] - ETA: 3s - loss: 0.6720 - accuracy: 0.61 11/163 [=>............................] - ETA: 3s - loss: 0.6735 - accuracy: 0.60 13/163 [=>............................] - ETA: 3s - loss: 0.6754 - accuracy: 0.58 14/163 [=>............................] - ETA: 4s - loss: 0.6776 - accuracy: 0.57 16/163 [=>............................] - ETA: 4s - loss: 0.6775 - accuracy: 0.57 17/163 [==>...........................] - ETA: 4s - loss: 0.6786 - accuracy: 0.57 18/163 [==>...........................] - ETA: 5s - loss: 0.6784 - accuracy: 0.57 19/163 [==>...........................] - ETA: 5s - loss: 0.6786 - accuracy: 0.57 24/163 [===>..........................] - ETA: 4s - loss: 0.6810 - accuracy: 0.56 27/163 [===>..........................] - ETA: 4s - loss: 0.6823 - accuracy: 0.55 29/163 [====>.........................] - ETA: 4s - loss: 0.6833 - accuracy: 0.55 30/163 [====>.........................] - ETA: 4s - loss: 0.6838 - accuracy: 0.54 31/163 [====>.........................] - ETA: 4s - loss: 0.6839 - accuracy: 0.54 32/163 [====>.........................] - ETA: 4s - loss: 0.6835 - accuracy: 0.54 33/163 [=====>........................] - ETA: 4s - loss: 0.6835 - accuracy: 0.55 34/163 [=====>........................] - ETA: 4s - loss: 0.6835 - accuracy: 0.55 35/163 [=====>........................] - ETA: 4s - loss: 0.6838 - accuracy: 0.55 36/163 [=====>........................] - ETA: 4s - loss: 0.6846 - accuracy: 0.54 37/163 [=====>........................] - ETA: 4s - loss: 0.6843 - accuracy: 0.55 40/163 [======>.......................] - ETA: 4s - loss: 0.6840 - accuracy: 0.55 41/163 [======>.......................] - ETA: 4s - loss: 0.6844 - accuracy: 0.55 43/163 [======>.......................] - ETA: 4s - loss: 0.6842 - accuracy: 0.55 44/163 [=======>......................] - ETA: 4s - loss: 0.6842 - accuracy: 0.55 47/163 [=======>......................] - ETA: 4s - loss: 0.6852 - accuracy: 0.54 48/163 [=======>......................] - ETA: 4s - loss: 0.6855 - accuracy: 0.54 49/163 [========>.....................] - ETA: 4s - loss: 0.6853 - accuracy: 0.54 52/163 [========>.....................] - ETA: 4s - loss: 0.6857 - accuracy: 0.54 53/163 [========>.....................] - ETA: 4s - loss: 0.6856 - accuracy: 0.54 55/163 [=========>....................] - ETA: 4s - loss: 0.6860 - accuracy: 0.54 57/163 [=========>....................] - ETA: 4s - loss: 0.6863 - accuracy: 0.53 60/163 [==========>...................] - ETA: 4s - loss: 0.6863 - accuracy: 0.53 62/163 [==========>...................] - ETA: 3s - loss: 0.6862 - accuracy: 0.54 65/163 [==========>...................] - ETA: 3s - loss: 0.6856 - accuracy: 0.54 66/163 [===========>..................] - ETA: 3s - loss: 0.6855 - accuracy: 0.54 67/163 [===========>..................] - ETA: 3s - loss: 0.6852 - accuracy: 0.54 69/163 [===========>..................] - ETA: 3s - loss: 0.6846 - accuracy: 0.54 71/163 [============>.................] - ETA: 3s - loss: 0.6847 - accuracy: 0.54 72/163 [============>.................] - ETA: 3s - loss: 0.6852 - accuracy: 0.54 73/163 [============>.................] - ETA: 3s - loss: 0.6852 - accuracy: 0.54 76/163 [============>.................] - ETA: 3s - loss: 0.6850 - accuracy: 0.54 77/163 [=============>................] - ETA: 3s - loss: 0.6854 - accuracy: 0.54 78/163 [=============>................] - ETA: 3s - loss: 0.6856 - accuracy: 0.54 81/163 [=============>................] - ETA: 3s - loss: 0.6854 - accuracy: 0.54 83/163 [==============>...............] - ETA: 3s - loss: 0.6854 - accuracy: 0.54 86/163 [==============>...............] - ETA: 2s - loss: 0.6850 - accuracy: 0.54 92/163 [===============>..............] - ETA: 2s - loss: 0.6851 - accuracy: 0.54 93/163 [================>.............] - ETA: 2s - loss: 0.6855 - accuracy: 0.54 95/163 [================>.............] - ETA: 2s - loss: 0.6856 - accuracy: 0.54 96/163 [================>.............] - ETA: 2s - loss: 0.6855 - accuracy: 0.54100/163 [=================>............] - ETA: 2s - loss: 0.6857 - accuracy: 0.54101/163 [=================>............] - ETA: 2s - loss: 0.6857 - accuracy: 0.54102/163 [=================>............] - ETA: 2s - loss: 0.6857 - accuracy: 0.54103/163 [=================>............] - ETA: 2s - loss: 0.6857 - accuracy: 0.54104/163 [==================>...........] - ETA: 2s - loss: 0.6859 - accuracy: 0.54107/163 [==================>...........] - ETA: 2s - loss: 0.6857 - accuracy: 0.54109/163 [===================>..........] - ETA: 2s - loss: 0.6860 - accuracy: 0.54113/163 [===================>..........] - ETA: 1s - loss: 0.6860 - accuracy: 0.54114/163 [===================>..........] - ETA: 1s - loss: 0.6862 - accuracy: 0.54115/163 [====================>.........] - ETA: 1s - loss: 0.6864 - accuracy: 0.54116/163 [====================>.........] - ETA: 1s - loss: 0.6864 - accuracy: 0.54118/163 [====================>.........] - ETA: 1s - loss: 0.6865 - accuracy: 0.54119/163 [====================>.........] - ETA: 1s - loss: 0.6864 - accuracy: 0.54120/163 [=====================>........] - ETA: 1s - loss: 0.6864 - accuracy: 0.54122/163 [=====================>........] - ETA: 1s - loss: 0.6866 - accuracy: 0.54125/163 [======================>.......] - ETA: 1s - loss: 0.6868 - accuracy: 0.53126/163 [======================>.......] - ETA: 1s - loss: 0.6868 - accuracy: 0.53130/163 [======================>.......] - ETA: 1s - loss: 0.6870 - accuracy: 0.53131/163 [=======================>......] - ETA: 1s - loss: 0.6871 - accuracy: 0.53132/163 [=======================>......] - ETA: 1s - loss: 0.6873 - accuracy: 0.53133/163 [=======================>......] - ETA: 1s - loss: 0.6874 - accuracy: 0.53135/163 [=======================>......] - ETA: 1s - loss: 0.6876 - accuracy: 0.53136/163 [========================>.....] - ETA: 1s - loss: 0.6875 - accuracy: 0.53138/163 [========================>.....] - ETA: 0s - loss: 0.6875 - accuracy: 0.53140/163 [========================>.....] - ETA: 0s - loss: 0.6877 - accuracy: 0.53141/163 [========================>.....] - ETA: 0s - loss: 0.6877 - accuracy: 0.53143/163 [=========================>....] - ETA: 0s - loss: 0.6878 - accuracy: 0.53144/163 [=========================>....] - ETA: 0s - loss: 0.6879 - accuracy: 0.53145/163 [=========================>....] - ETA: 0s - loss: 0.6878 - accuracy: 0.53146/163 [=========================>....] - ETA: 0s - loss: 0.6879 - accuracy: 0.53148/163 [==========================>...] - ETA: 0s - loss: 0.6878 - accuracy: 0.53150/163 [==========================>...] - ETA: 0s - loss: 0.6878 - accuracy: 0.53152/163 [==========================>...] - ETA: 0s - loss: 0.6877 - accuracy: 0.53155/163 [===========================>..] - ETA: 0s - loss: 0.6878 - accuracy: 0.53156/163 [===========================>..] - ETA: 0s - loss: 0.6878 - accuracy: 0.53158/163 [============================>.] - ETA: 0s - loss: 0.6878 - accuracy: 0.53159/163 [============================>.] - ETA: 0s - loss: 0.6879 - accuracy: 0.53160/163 [============================>.] - ETA: 0s - loss: 0.6881 - accuracy: 0.53162/163 [============================>.] - ETA: 0s - loss: 0.6879 - accuracy: 0.53163/163 [==============================] - ETA: 0s - loss: 0.6879 - accuracy: 0.53163/163 [==============================] - 7s 45ms/step - loss: 0.6879 - accuracy: 0.5355 - val_loss: 0.6982 - val_accuracy: 0.4948\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: f821a3def9313b82c4e904339e6891ce</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.5051500201225281</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-n_layers: 5</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-n_nodes: 11</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cy: 0.50163/163 [==============================] - 5s 33ms/step - loss: 0.6934 - accuracy: 0.5044 - val_loss: 0.6927 - val_accuracy: 0.5056\nEpoch 3/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6903 - accuracy: 0.53  4/163 [..............................] - ETA: 2s - loss: 0.6934 - accuracy: 0.47  5/163 [..............................] - ETA: 3s - loss: 0.6932 - accuracy: 0.48  7/163 [>.............................] - ETA: 3s - loss: 0.6922 - accuracy: 0.52 10/163 [>.............................] - ETA: 3s - loss: 0.6924 - accuracy: 0.51 13/163 [=>............................] - ETA: 3s - loss: 0.6926 - accuracy: 0.50 15/163 [=>............................] - ETA: 3s - loss: 0.6922 - accuracy: 0.52 16/163 [=>............................] - ETA: 3s - loss: 0.6924 - accuracy: 0.51 18/163 [==>...........................] - ETA: 3s - loss: 0.6929 - accuracy: 0.50 19/163 [==>...........................] - ETA: 4s - loss: 0.6929 - accuracy: 0.50 22/163 [===>..........................] - ETA: 3s - loss: 0.6931 - accuracy: 0.49 23/163 [===>..........................] - ETA: 3s - loss: 0.6933 - accuracy: 0.49 25/163 [===>..........................] - ETA: 3s - loss: 0.6934 - accuracy: 0.49 26/163 [===>..........................] - ETA: 4s - loss: 0.6933 - accuracy: 0.49 28/163 [====>.........................] - ETA: 3s - loss: 0.6931 - accuracy: 0.50 29/163 [====>.........................] - ETA: 4s - loss: 0.6932 - accuracy: 0.50 34/163 [=====>........................] - ETA: 3s - loss: 0.6931 - accuracy: 0.50 35/163 [=====>........................] - ETA: 3s - loss: 0.6931 - accuracy: 0.50 37/163 [=====>........................] - ETA: 3s - loss: 0.6932 - accuracy: 0.50 38/163 [=====>........................] - ETA: 3s - loss: 0.6932 - accuracy: 0.50 40/163 [======>.......................] - ETA: 3s - loss: 0.6931 - accuracy: 0.51 41/163 [======>.......................] - ETA: 4s - loss: 0.6930 - accuracy: 0.51 42/163 [======>.......................] - ETA: 4s - loss: 0.6930 - accuracy: 0.51 44/163 [=======>......................] - ETA: 4s - loss: 0.6930 - accuracy: 0.51 45/163 [=======>......................] - ETA: 4s - loss: 0.6930 - accuracy: 0.51 48/163 [=======>......................] - ETA: 4s - loss: 0.6930 - accuracy: 0.51 54/163 [========>.....................] - ETA: 3s - loss: 0.6930 - accuracy: 0.51 55/163 [=========>....................] - ETA: 3s - loss: 0.6930 - accuracy: 0.51 58/163 [=========>....................] - ETA: 3s - loss: 0.6930 - accuracy: 0.51 61/163 [==========>...................] - ETA: 3s - loss: 0.6928 - accuracy: 0.52 64/163 [==========>...................] - ETA: 3s - loss: 0.6928 - accuracy: 0.52 65/163 [==========>...................] - ETA: 3s - loss: 0.6929 - accuracy: 0.51 66/163 [===========>..................] - ETA: 3s - loss: 0.6929 - accuracy: 0.51 68/163 [===========>..................] - ETA: 3s - loss: 0.6929 - accuracy: 0.51 71/163 [============>.................] - ETA: 2s - loss: 0.6929 - accuracy: 0.51 77/163 [=============>................] - ETA: 2s - loss: 0.6929 - accuracy: 0.51 79/163 [=============>................] - ETA: 2s - loss: 0.6930 - accuracy: 0.51 80/163 [=============>................] - ETA: 2s - loss: 0.6930 - accuracy: 0.51 81/163 [=============>................] - ETA: 2s - loss: 0.6929 - accuracy: 0.51 82/163 [==============>...............] - ETA: 2s - loss: 0.6930 - accuracy: 0.51 84/163 [==============>...............] - ETA: 2s - loss: 0.6930 - accuracy: 0.51 85/163 [==============>...............] - ETA: 2s - loss: 0.6930 - accuracy: 0.51 90/163 [===============>..............] - ETA: 2s - loss: 0.6930 - accuracy: 0.51 91/163 [===============>..............] - ETA: 2s - loss: 0.6929 - accuracy: 0.51 92/163 [===============>..............] - ETA: 2s - loss: 0.6930 - accuracy: 0.51 98/163 [=================>............] - ETA: 2s - loss: 0.6927 - accuracy: 0.51 99/163 [=================>............] - ETA: 2s - loss: 0.6926 - accuracy: 0.51103/163 [=================>............] - ETA: 1s - loss: 0.6927 - accuracy: 0.51107/163 [==================>...........] - ETA: 1s - loss: 0.6927 - accuracy: 0.51109/163 [===================>..........] - ETA: 1s - loss: 0.6927 - accuracy: 0.51110/163 [===================>..........] - ETA: 1s - loss: 0.6926 - accuracy: 0.51112/163 [===================>..........] - ETA: 1s - loss: 0.6926 - accuracy: 0.51115/163 [====================>.........] - ETA: 1s - loss: 0.6928 - accuracy: 0.51117/163 [====================>.........] - ETA: 1s - loss: 0.6929 - accuracy: 0.51119/163 [====================>.........] - ETA: 1s - loss: 0.6928 - accuracy: 0.51123/163 [=====================>........] - ETA: 1s - loss: 0.6927 - accuracy: 0.51127/163 [======================>.......] - ETA: 1s - loss: 0.6926 - accuracy: 0.51130/163 [======================>.......] - ETA: 1s - loss: 0.6926 - accuracy: 0.51131/163 [=======================>......] - ETA: 1s - loss: 0.6925 - accuracy: 0.51132/163 [=======================>......] - ETA: 0s - loss: 0.6926 - accuracy: 0.51133/163 [=======================>......] - ETA: 0s - loss: 0.6926 - accuracy: 0.51135/163 [=======================>......] - ETA: 0s - loss: 0.6926 - accuracy: 0.51136/163 [========================>.....] - ETA: 0s - loss: 0.6927 - accuracy: 0.51138/163 [========================>.....] - ETA: 0s - loss: 0.6927 - accuracy: 0.51139/163 [========================>.....] - ETA: 0s - loss: 0.6926 - accuracy: 0.51140/163 [========================>.....] - ETA: 0s - loss: 0.6926 - accuracy: 0.51141/163 [========================>.....] - ETA: 0s - loss: 0.6925 - accuracy: 0.51142/163 [=========================>....] - ETA: 0s - loss: 0.6925 - accuracy: 0.51144/163 [=========================>....] - ETA: 0s - loss: 0.6926 - accuracy: 0.51145/163 [=========================>....] - ETA: 0s - loss: 0.6926 - accuracy: 0.51147/163 [==========================>...] - ETA: 0s - loss: 0.6926 - accuracy: 0.51149/163 [==========================>...] - ETA: 0s - loss: 0.6927 - accuracy: 0.51150/163 [==========================>...] - ETA: 0s - loss: 0.6926 - accuracy: 0.51151/163 [==========================>...] - ETA: 0s - loss: 0.6925 - accuracy: 0.51153/163 [===========================>..] - ETA: 0s - loss: 0.6925 - accuracy: 0.51156/163 [===========================>..] - ETA: 0s - loss: 0.6924 - accuracy: 0.51159/163 [============================>.] - ETA: 0s - loss: 0.6924 - accuracy: 0.51162/163 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.51163/163 [==============================] - 7s 41ms/step - loss: 0.6927 - accuracy: 0.5159 - val_loss: 0.6959 - val_accuracy: 0.5069\nEpoch 4/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6936 - accuracy: 0.50  3/163 [..............................] - ETA: 5s - loss: 0.6998 - accuracy: 0.46  6/163 [>.............................] - ETA: 4s - loss: 0.6952 - accuracy: 0.49  8/163 [>.............................] - ETA: 4s - loss: 0.6951 - accuracy: 0.50 16/163 [=>............................] - ETA: 3s - loss: 0.6937 - accuracy: 0.51 17/163 [==>...........................] - ETA: 3s - loss: 0.6936 - accuracy: 0.50 19/163 [==>...........................] - ETA: 3s - loss: 0.6934 - accuracy: 0.51 20/163 [==>...........................] - ETA: 4s - loss: 0.6940 - accuracy: 0.50 22/163 [===>..........................] - ETA: 4s - loss: 0.6944 - accuracy: 0.49 24/163 [===>..........................] - ETA: 4s - loss: 0.6938 - accuracy: 0.50 25/163 [===>..........................] - ETA: 4s - loss: 0.6939 - accuracy: 0.50 26/163 [===>..........................] - ETA: 4s - loss: 0.6942 - accuracy: 0.49 28/163 [====>.........................] - ETA: 5s - loss: 0.6941 - accuracy: 0.49 31/163 [====>.........................] - ETA: 4s - loss: 0.6945 - accuracy: 0.48 33/163 [=====>........................] - ETA: 4s - loss: 0.6944 - accuracy: 0.48 34/163 [=====>........................] - ETA: 4s - loss: 0.6944 - accuracy: 0.48 37/163 [=====>........................] - ETA: 4s - loss: 0.6938 - accuracy: 0.50 38/163 [=====>........................] - ETA: 4s - loss: 0.6937 - accuracy: 0.49 43/163 [======>.......................] - ETA: 4s - loss: 0.6934 - accuracy: 0.50 45/163 [=======>......................] - ETA: 4s - loss: 0.6933 - accuracy: 0.50 48/163 [=======>......................] - ETA: 4s - loss: 0.6929 - accuracy: 0.50 49/163 [========>.....................] - ETA: 5s - loss: 0.6929 - accuracy: 0.50 50/163 [========>.....................] - ETA: 5s - loss: 0.6928 - accuracy: 0.50 51/163 [========>.....................] - ETA: 5s - loss: 0.6928 - accuracy: 0.50 52/163 [========>.....................] - ETA: 5s - loss: 0.6928 - accuracy: 0.50 55/163 [=========>....................] - ETA: 5s - loss: 0.6926 - accuracy: 0.51 58/163 [=========>....................] - ETA: 4s - loss: 0.6926 - accuracy: 0.51 59/163 [=========>....................] - ETA: 4s - loss: 0.6929 - accuracy: 0.51 61/163 [==========>...................] - ETA: 4s - loss: 0.6926 - accuracy: 0.51 63/163 [==========>...................] - ETA: 4s - loss: 0.6928 - accuracy: 0.51 67/163 [===========>..................] - ETA: 4s - loss: 0.6926 - accuracy: 0.51 71/163 [============>.................] - ETA: 3s - loss: 0.6927 - accuracy: 0.51 76/163 [============>.................] - ETA: 3s - loss: 0.6928 - accuracy: 0.51 81/163 [=============>................] - ETA: 3s - loss: 0.6929 - accuracy: 0.51 83/163 [==============>...............] - ETA: 3s - loss: 0.6929 - accuracy: 0.51 84/163 [==============>...............] - ETA: 3s - loss: 0.6929 - accuracy: 0.51 85/163 [==============>...............] - ETA: 3s - loss: 0.6929 - accuracy: 0.50 88/163 [===============>..............] - ETA: 2s - loss: 0.6928 - accuracy: 0.51 90/163 [===============>..............] - ETA: 2s - loss: 0.6927 - accuracy: 0.51 92/163 [===============>..............] - ETA: 2s - loss: 0.6928 - accuracy: 0.51 93/163 [================>.............] - ETA: 2s - loss: 0.6927 - accuracy: 0.51 94/163 [================>.............] - ETA: 2s - loss: 0.6927 - accuracy: 0.51 95/163 [================>.............] - ETA: 2s - loss: 0.6927 - accuracy: 0.51 96/163 [================>.............] - ETA: 2s - loss: 0.6927 - accuracy: 0.51 97/163 [================>.............] - ETA: 2s - loss: 0.6927 - accuracy: 0.51 98/163 [=================>............] - ETA: 2s - loss: 0.6927 - accuracy: 0.51 99/163 [=================>............] - ETA: 2s - loss: 0.6926 - accuracy: 0.51100/163 [=================>............] - ETA: 2s - loss: 0.6926 - accuracy: 0.51102/163 [=================>............] - ETA: 2s - loss: 0.6924 - accuracy: 0.51103/163 [=================>............] - ETA: 2s - loss: 0.6925 - accuracy: 0.51107/163 [==================>...........] - ETA: 2s - loss: 0.6925 - accuracy: 0.51108/163 [==================>...........] - ETA: 2s - loss: 0.6925 - accuracy: 0.51110/163 [===================>..........] - ETA: 2s - loss: 0.6924 - accuracy: 0.52112/163 [===================>..........] - ETA: 2s - loss: 0.6923 - accuracy: 0.52117/163 [====================>.........] - ETA: 1s - loss: 0.6920 - accuracy: 0.52118/163 [====================>.........] - ETA: 1s - loss: 0.6920 - accuracy: 0.52120/163 [=====================>........] - ETA: 1s - loss: 0.6920 - accuracy: 0.52122/163 [=====================>........] - ETA: 1s - loss: 0.6921 - accuracy: 0.52123/163 [=====================>........] - ETA: 1s - loss: 0.6921 - accuracy: 0.52124/163 [=====================>........] - ETA: 1s - loss: 0.6920 - accuracy: 0.52126/163 [======================>.......] - ETA: 1s - loss: 0.6921 - accuracy: 0.52131/163 [=======================>......] - ETA: 1s - loss: 0.6922 - accuracy: 0.52133/163 [=======================>......] - ETA: 1s - loss: 0.6922 - accuracy: 0.52134/163 [=======================>......] - ETA: 1s - loss: 0.6921 - accuracy: 0.52135/163 [=======================>......] - ETA: 1s - loss: 0.6921 - accuracy: 0.52137/163 [========================>.....] - ETA: 1s - loss: 0.6921 - accuracy: 0.52138/163 [========================>.....] - ETA: 0s - loss: 0.6920 - accuracy: 0.52140/163 [========================>.....] - ETA: 0s - loss: 0.6921 - accuracy: 0.52142/163 [=========================>....] - ETA: 0s - loss: 0.6921 - accuracy: 0.52146/163 [=========================>....] - ETA: 0s - loss: 0.6922 - accuracy: 0.52150/163 [==========================>...] - ETA: 0s - loss: 0.6922 - accuracy: 0.52153/163 [===========================>..] - ETA: 0s - loss: 0.6922 - accuracy: 0.52155/163 [===========================>..] - ETA: 0s - loss: 0.6922 - accuracy: 0.52156/163 [===========================>..] - ETA: 0s - loss: 0.6921 - accuracy: 0.52157/163 [===========================>..] - ETA: 0s - loss: 0.6921 - accuracy: 0.52160/163 [============================>.] - ETA: 0s - loss: 0.6919 - accuracy: 0.52163/163 [==============================] - 7s 41ms/step - loss: 0.6918 - accuracy: 0.5265 - val_loss: 0.6945 - val_accuracy: 0.4993\nEpoch 5/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6900 - accuracy: 0.56  3/163 [..............................] - ETA: 4s - loss: 0.6915 - accuracy: 0.55  4/163 [..............................] - ETA: 5s - loss: 0.6865 - accuracy: 0.58  5/163 [..............................] - ETA: 6s - loss: 0.6887 - accuracy: 0.56  6/163 [>.............................] - ETA: 6s - loss: 0.6916 - accuracy: 0.53  7/163 [>.............................] - ETA: 7s - loss: 0.6873 - accuracy: 0.55  9/163 [>.............................] - ETA: 7s - loss: 0.6839 - accuracy: 0.58 12/163 [=>............................] - ETA: 6s - loss: 0.6886 - accuracy: 0.55 15/163 [=>............................] - ETA: 5s - loss: 0.6874 - accuracy: 0.55 16/163 [=>............................] - ETA: 5s - loss: 0.6878 - accuracy: 0.54 18/163 [==>...........................] - ETA: 5s - loss: 0.6903 - accuracy: 0.53 19/163 [==>...........................] - ETA: 6s - loss: 0.6900 - accuracy: 0.53 21/163 [==>...........................] - ETA: 5s - loss: 0.6894 - accuracy: 0.53 23/163 [===>..........................] - ETA: 5s - loss: 0.6884 - accuracy: 0.54 25/163 [===>..........................] - ETA: 5s - loss: 0.6881 - accuracy: 0.55 27/163 [===>..........................] - ETA: 5s - loss: 0.6877 - accuracy: 0.55 30/163 [====>.........................] - ETA: 5s - loss: 0.6871 - accuracy: 0.56 31/163 [====>.........................] - ETA: 5s - loss: 0.6868 - accuracy: 0.57 36/163 [=====>........................] - ETA: 4s - loss: 0.6868 - accuracy: 0.56 37/163 [=====>........................] - ETA: 4s - loss: 0.6870 - accuracy: 0.56 39/163 [======>.......................] - ETA: 4s - loss: 0.6873 - accuracy: 0.56 42/163 [======>.......................] - ETA: 4s - loss: 0.6874 - accuracy: 0.56 44/163 [=======>......................] - ETA: 4s - loss: 0.6870 - accuracy: 0.56 45/163 [=======>......................] - ETA: 4s - loss: 0.6871 - accuracy: 0.56 49/163 [========>.....................] - ETA: 4s - loss: 0.6870 - accuracy: 0.56 51/163 [========>.....................] - ETA: 3s - loss: 0.6871 - accuracy: 0.56 54/163 [========>.....................] - ETA: 3s - loss: 0.6881 - accuracy: 0.55 55/163 [=========>....................] - ETA: 3s - loss: 0.6880 - accuracy: 0.55 57/163 [=========>....................] - ETA: 3s - loss: 0.6876 - accuracy: 0.56 61/163 [==========>...................] - ETA: 3s - loss: 0.6883 - accuracy: 0.55 65/163 [==========>...................] - ETA: 3s - loss: 0.6887 - accuracy: 0.55 66/163 [===========>..................] - ETA: 3s - loss: 0.6889 - accuracy: 0.55 68/163 [===========>..................] - ETA: 3s - loss: 0.6888 - accuracy: 0.55 69/163 [===========>..................] - ETA: 3s - loss: 0.6890 - accuracy: 0.55 70/163 [===========>..................] - ETA: 3s - loss: 0.6889 - accuracy: 0.55 72/163 [============>.................] - ETA: 3s - loss: 0.6890 - accuracy: 0.55 73/163 [============>.................] - ETA: 3s - loss: 0.6891 - accuracy: 0.55 74/163 [============>.................] - ETA: 3s - loss: 0.6890 - accuracy: 0.55 75/163 [============>.................] - ETA: 3s - loss: 0.6890 - accuracy: 0.55 77/163 [=============>................] - ETA: 3s - loss: 0.6896 - accuracy: 0.54 78/163 [=============>................] - ETA: 3s - loss: 0.6897 - accuracy: 0.54 79/163 [=============>................] - ETA: 3s - loss: 0.6900 - accuracy: 0.54 81/163 [=============>................] - ETA: 3s - loss: 0.6898 - accuracy: 0.54 82/163 [==============>...............] - ETA: 3s - loss: 0.6898 - accuracy: 0.54 83/163 [==============>...............] - ETA: 3s - loss: 0.6898 - accuracy: 0.54 84/163 [==============>...............] - ETA: 3s - loss: 0.6897 - accuracy: 0.55 85/163 [==============>...............] - ETA: 3s - loss: 0.6896 - accuracy: 0.55 88/163 [===============>..............] - ETA: 3s - loss: 0.6893 - accuracy: 0.55 89/163 [===============>..............] - ETA: 3s - loss: 0.6892 - accuracy: 0.55 91/163 [===============>..............] - ETA: 3s - loss: 0.6893 - accuracy: 0.55 92/163 [===============>..............] - ETA: 3s - loss: 0.6892 - accuracy: 0.55 94/163 [================>.............] - ETA: 2s - loss: 0.6893 - accuracy: 0.55 95/163 [================>.............] - ETA: 2s - loss: 0.6892 - accuracy: 0.54 96/163 [================>.............] - ETA: 2s - loss: 0.6892 - accuracy: 0.55 99/163 [=================>............] - ETA: 2s - loss: 0.6892 - accuracy: 0.54102/163 [=================>............] - ETA: 2s - loss: 0.6892 - accuracy: 0.54103/163 [=================>............] - ETA: 2s - loss: 0.6892 - accuracy: 0.54105/163 [==================>...........] - ETA: 2s - loss: 0.6893 - accuracy: 0.54108/163 [==================>...........] - ETA: 2s - loss: 0.6893 - accuracy: 0.54110/163 [===================>..........] - ETA: 2s - loss: 0.6889 - accuracy: 0.54112/163 [===================>..........] - ETA: 2s - loss: 0.6890 - accuracy: 0.54116/163 [====================>.........] - ETA: 1s - loss: 0.6888 - accuracy: 0.55118/163 [====================>.........] - ETA: 1s - loss: 0.6889 - accuracy: 0.54119/163 [====================>.........] - ETA: 1s - loss: 0.6888 - accuracy: 0.54122/163 [=====================>........] - ETA: 1s - loss: 0.6888 - accuracy: 0.54126/163 [======================>.......] - ETA: 1s - loss: 0.6890 - accuracy: 0.54129/163 [======================>.......] - ETA: 1s - loss: 0.6892 - accuracy: 0.54130/163 [======================>.......] - ETA: 1s - loss: 0.6892 - accuracy: 0.54134/163 [=======================>......] - ETA: 1s - loss: 0.6893 - accuracy: 0.54137/163 [========================>.....] - ETA: 0s - loss: 0.6895 - accuracy: 0.54140/163 [========================>.....] - ETA: 0s - loss: 0.6893 - accuracy: 0.55143/163 [=========================>....] - ETA: 0s - loss: 0.6892 - accuracy: 0.55144/163 [=========================>....] - ETA: 0s - loss: 0.6892 - accuracy: 0.55147/163 [==========================>...] - ETA: 0s - loss: 0.6891 - accuracy: 0.55148/163 [==========================>...] - ETA: 0s - loss: 0.6893 - accuracy: 0.55149/163 [==========================>...] - ETA: 0s - loss: 0.6891 - accuracy: 0.55150/163 [==========================>...] - ETA: 0s - loss: 0.6892 - accuracy: 0.55152/163 [==========================>...] - ETA: 0s - loss: 0.6893 - accuracy: 0.54153/163 [===========================>..] - ETA: 0s - loss: 0.6892 - accuracy: 0.54157/163 [===========================>..] - ETA: 0s - loss: 0.6892 - accuracy: 0.54158/163 [============================>.] - ETA: 0s - loss: 0.6891 - accuracy: 0.55161/163 [============================>.] - ETA: 0s - loss: 0.6892 - accuracy: 0.54163/163 [==============================] - ETA: 0s - loss: 0.6891 - accuracy: 0.54163/163 [==============================] - 7s 41ms/step - loss: 0.6891 - accuracy: 0.5491 - val_loss: 0.6974 - val_accuracy: 0.5074\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: e1dea1d059ad229a086174d28b316fc4</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.5073891878128052</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-n_layers: 6</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-n_nodes: 14</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "....] - ETA: 3s - loss: 0.6927 - accuracy: 0.51103/163 [=================>............] - ETA: 3s - loss: 0.6928 - accuracy: 0.51104/163 [==================>...........] - ETA: 3s - loss: 0.6928 - accuracy: 0.51105/163 [==================>...........] - ETA: 3s - loss: 0.6928 - accuracy: 0.51106/163 [==================>...........] - ETA: 3s - loss: 0.6928 - accuracy: 0.51107/163 [==================>...........] - ETA: 3s - loss: 0.6929 - accuracy: 0.51109/163 [===================>..........] - ETA: 3s - loss: 0.6930 - accuracy: 0.51110/163 [===================>..........] - ETA: 3s - loss: 0.6930 - accuracy: 0.51111/163 [===================>..........] - ETA: 3s - loss: 0.6930 - accuracy: 0.51112/163 [===================>..........] - ETA: 3s - loss: 0.6930 - accuracy: 0.50114/163 [===================>..........] - ETA: 2s - loss: 0.6930 - accuracy: 0.51115/163 [====================>.........] - ETA: 2s - loss: 0.6930 - accuracy: 0.51116/163 [====================>.........] - ETA: 2s - loss: 0.6930 - accuracy: 0.50117/163 [====================>.........] - ETA: 2s - loss: 0.6930 - accuracy: 0.50118/163 [====================>.........] - ETA: 2s - loss: 0.6930 - accuracy: 0.50119/163 [====================>.........] - ETA: 2s - loss: 0.6930 - accuracy: 0.50120/163 [=====================>........] - ETA: 2s - loss: 0.6931 - accuracy: 0.50121/163 [=====================>........] - ETA: 2s - loss: 0.6931 - accuracy: 0.50124/163 [=====================>........] - ETA: 2s - loss: 0.6931 - accuracy: 0.50126/163 [======================>.......] - ETA: 2s - loss: 0.6930 - accuracy: 0.50127/163 [======================>.......] - ETA: 2s - loss: 0.6930 - accuracy: 0.50128/163 [======================>.......] - ETA: 2s - loss: 0.6930 - accuracy: 0.50129/163 [======================>.......] - ETA: 2s - loss: 0.6931 - accuracy: 0.50130/163 [======================>.......] - ETA: 2s - loss: 0.6931 - accuracy: 0.50131/163 [=======================>......] - ETA: 2s - loss: 0.6930 - accuracy: 0.50132/163 [=======================>......] - ETA: 2s - loss: 0.6930 - accuracy: 0.50133/163 [=======================>......] - ETA: 1s - loss: 0.6930 - accuracy: 0.51134/163 [=======================>......] - ETA: 1s - loss: 0.6930 - accuracy: 0.51135/163 [=======================>......] - ETA: 1s - loss: 0.6930 - accuracy: 0.51136/163 [========================>.....] - ETA: 1s - loss: 0.6930 - accuracy: 0.51138/163 [========================>.....] - ETA: 1s - loss: 0.6930 - accuracy: 0.51139/163 [========================>.....] - ETA: 1s - loss: 0.6930 - accuracy: 0.51140/163 [========================>.....] - ETA: 1s - loss: 0.6930 - accuracy: 0.51141/163 [========================>.....] - ETA: 1s - loss: 0.6930 - accuracy: 0.51142/163 [=========================>....] - ETA: 1s - loss: 0.6930 - accuracy: 0.51143/163 [=========================>....] - ETA: 1s - loss: 0.6930 - accuracy: 0.51144/163 [=========================>....] - ETA: 1s - loss: 0.6930 - accuracy: 0.51145/163 [=========================>....] - ETA: 1s - loss: 0.6930 - accuracy: 0.51147/163 [==========================>...] - ETA: 1s - loss: 0.6930 - accuracy: 0.51148/163 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.51151/163 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.51154/163 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.51155/163 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.50156/163 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.50157/163 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.50158/163 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.50159/163 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.50161/163 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.50163/163 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.50163/163 [==============================] - 11s 68ms/step - loss: 0.6931 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5020\nEpoch 4/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6929 - accuracy: 0.53  3/163 [..............................] - ETA: 5s - loss: 0.6908 - accuracy: 0.60  4/163 [..............................] - ETA: 6s - loss: 0.6907 - accuracy: 0.61  5/163 [..............................] - ETA: 6s - loss: 0.6908 - accuracy: 0.61  6/163 [>.............................] - ETA: 7s - loss: 0.6912 - accuracy: 0.59  7/163 [>.............................] - ETA: 7s - loss: 0.6919 - accuracy: 0.56  8/163 [>.............................] - ETA: 7s - loss: 0.6920 - accuracy: 0.56  9/163 [>.............................] - ETA: 8s - loss: 0.6922 - accuracy: 0.55 11/163 [=>............................] - ETA: 7s - loss: 0.6924 - accuracy: 0.54 12/163 [=>............................] - ETA: 8s - loss: 0.6925 - accuracy: 0.54 13/163 [=>............................] - ETA: 8s - loss: 0.6925 - accuracy: 0.54 14/163 [=>............................] - ETA: 8s - loss: 0.6926 - accuracy: 0.53 16/163 [=>............................] - ETA: 7s - loss: 0.6928 - accuracy: 0.52 19/163 [==>...........................] - ETA: 7s - loss: 0.6929 - accuracy: 0.51 20/163 [==>...........................] - ETA: 7s - loss: 0.6929 - accuracy: 0.51 21/163 [==>...........................] - ETA: 7s - loss: 0.6928 - accuracy: 0.52 22/163 [===>..........................] - ETA: 8s - loss: 0.6929 - accuracy: 0.51 24/163 [===>..........................] - ETA: 7s - loss: 0.6931 - accuracy: 0.51 25/163 [===>..........................] - ETA: 7s - loss: 0.6930 - accuracy: 0.51 26/163 [===>..........................] - ETA: 7s - loss: 0.6930 - accuracy: 0.51 27/163 [===>..........................] - ETA: 7s - loss: 0.6930 - accuracy: 0.51 28/163 [====>.........................] - ETA: 8s - loss: 0.6930 - accuracy: 0.51 29/163 [====>.........................] - ETA: 8s - loss: 0.6931 - accuracy: 0.51 31/163 [====>.........................] - ETA: 8s - loss: 0.6929 - accuracy: 0.51 33/163 [=====>........................] - ETA: 7s - loss: 0.6929 - accuracy: 0.51 34/163 [=====>........................] - ETA: 7s - loss: 0.6928 - accuracy: 0.52 37/163 [=====>........................] - ETA: 7s - loss: 0.6926 - accuracy: 0.52 38/163 [=====>........................] - ETA: 7s - loss: 0.6927 - accuracy: 0.52 40/163 [======>.......................] - ETA: 6s - loss: 0.6928 - accuracy: 0.52 42/163 [======>.......................] - ETA: 6s - loss: 0.6928 - accuracy: 0.52 44/163 [=======>......................] - ETA: 6s - loss: 0.6930 - accuracy: 0.51 46/163 [=======>......................] - ETA: 6s - loss: 0.6931 - accuracy: 0.51 47/163 [=======>......................] - ETA: 6s - loss: 0.6931 - accuracy: 0.51 48/163 [=======>......................] - ETA: 6s - loss: 0.6930 - accuracy: 0.51 49/163 [========>.....................] - ETA: 6s - loss: 0.6931 - accuracy: 0.51 50/163 [========>.....................] - ETA: 6s - loss: 0.6931 - accuracy: 0.51 51/163 [========>.....................] - ETA: 6s - loss: 0.6931 - accuracy: 0.51 52/163 [========>.....................] - ETA: 6s - loss: 0.6930 - accuracy: 0.51 53/163 [========>.....................] - ETA: 6s - loss: 0.6931 - accuracy: 0.51 55/163 [=========>....................] - ETA: 6s - loss: 0.6931 - accuracy: 0.51 58/163 [=========>....................] - ETA: 6s - loss: 0.6931 - accuracy: 0.50 60/163 [==========>...................] - ETA: 5s - loss: 0.6931 - accuracy: 0.51 63/163 [==========>...................] - ETA: 5s - loss: 0.6931 - accuracy: 0.51 64/163 [==========>...................] - ETA: 5s - loss: 0.6931 - accuracy: 0.51 65/163 [==========>...................] - ETA: 5s - loss: 0.6932 - accuracy: 0.50 68/163 [===========>..................] - ETA: 5s - loss: 0.6931 - accuracy: 0.51 69/163 [===========>..................] - ETA: 5s - loss: 0.6931 - accuracy: 0.51 71/163 [============>.................] - ETA: 4s - loss: 0.6932 - accuracy: 0.50 73/163 [============>.................] - ETA: 4s - loss: 0.6932 - accuracy: 0.50 76/163 [============>.................] - ETA: 4s - loss: 0.6931 - accuracy: 0.50 78/163 [=============>................] - ETA: 4s - loss: 0.6932 - accuracy: 0.50 80/163 [=============>................] - ETA: 4s - loss: 0.6931 - accuracy: 0.50 83/163 [==============>...............] - ETA: 3s - loss: 0.6931 - accuracy: 0.51 86/163 [==============>...............] - ETA: 3s - loss: 0.6931 - accuracy: 0.50 88/163 [===============>..............] - ETA: 3s - loss: 0.6931 - accuracy: 0.50 93/163 [================>.............] - ETA: 3s - loss: 0.6932 - accuracy: 0.50 94/163 [================>.............] - ETA: 3s - loss: 0.6932 - accuracy: 0.50 98/163 [=================>............] - ETA: 2s - loss: 0.6932 - accuracy: 0.50102/163 [=================>............] - ETA: 2s - loss: 0.6932 - accuracy: 0.50103/163 [=================>............] - ETA: 2s - loss: 0.6931 - accuracy: 0.50107/163 [==================>...........] - ETA: 2s - loss: 0.6931 - accuracy: 0.50108/163 [==================>...........] - ETA: 2s - loss: 0.6931 - accuracy: 0.50110/163 [===================>..........] - ETA: 2s - loss: 0.6931 - accuracy: 0.50111/163 [===================>..........] - ETA: 2s - loss: 0.6931 - accuracy: 0.50114/163 [===================>..........] - ETA: 2s - loss: 0.6931 - accuracy: 0.50116/163 [====================>.........] - ETA: 2s - loss: 0.6930 - accuracy: 0.50117/163 [====================>.........] - ETA: 1s - loss: 0.6930 - accuracy: 0.50118/163 [====================>.........] - ETA: 1s - loss: 0.6930 - accuracy: 0.50119/163 [====================>.........] - ETA: 1s - loss: 0.6930 - accuracy: 0.50120/163 [=====================>........] - ETA: 1s - loss: 0.6930 - accuracy: 0.50121/163 [=====================>........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50122/163 [=====================>........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50123/163 [=====================>........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50124/163 [=====================>........] - ETA: 1s - loss: 0.6931 - accuracy: 0.50125/163 [======================>.......] - ETA: 1s - loss: 0.6931 - accuracy: 0.50126/163 [======================>.......] - ETA: 1s - loss: 0.6930 - accuracy: 0.50127/163 [======================>.......] - ETA: 1s - loss: 0.6931 - accuracy: 0.50128/163 [======================>.......] - ETA: 1s - loss: 0.6930 - accuracy: 0.50130/163 [======================>.......] - ETA: 1s - loss: 0.6929 - accuracy: 0.50131/163 [=======================>......] - ETA: 1s - loss: 0.6929 - accuracy: 0.50133/163 [=======================>......] - ETA: 1s - loss: 0.6929 - accuracy: 0.50135/163 [=======================>......] - ETA: 1s - loss: 0.6931 - accuracy: 0.50137/163 [========================>.....] - ETA: 1s - loss: 0.6931 - accuracy: 0.50138/163 [========================>.....] - ETA: 1s - loss: 0.6931 - accuracy: 0.50139/163 [========================>.....] - ETA: 1s - loss: 0.6931 - accuracy: 0.50140/163 [========================>.....] - ETA: 1s - loss: 0.6931 - accuracy: 0.50143/163 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.50145/163 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.50146/163 [=========================>....] - ETA: 0s - loss: 0.6931 - accuracy: 0.50148/163 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.50150/163 [==========================>...] - ETA: 0s - loss: 0.6932 - accuracy: 0.50152/163 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.50153/163 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.50155/163 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.50157/163 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.50159/163 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.50160/163 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.50162/163 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.50163/163 [==============================] - 8s 52ms/step - loss: 0.6931 - accuracy: 0.5065 - val_loss: 0.6933 - val_accuracy: 0.4931\nEpoch 5/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6937 - accuracy: 0.56  2/163 [..............................] - ETA: 8s - loss: 0.6914 - accuracy: 0.57  3/163 [..............................] - ETA: 9s - loss: 0.6915 - accuracy: 0.56  4/163 [..............................] - ETA: 10s - loss: 0.6914 - accuracy: 0.570  5/163 [..............................] - ETA: 11s - loss: 0.6915 - accuracy: 0.568  6/163 [>.............................] - ETA: 13s - loss: 0.6915 - accuracy: 0.562  7/163 [>.............................] - ETA: 13s - loss: 0.6920 - accuracy: 0.531  8/163 [>.............................] - ETA: 13s - loss: 0.6922 - accuracy: 0.527  9/163 [>.............................] - ETA: 13s - loss: 0.6926 - accuracy: 0.510 10/163 [>.............................] - ETA: 12s - loss: 0.6929 - accuracy: 0.500 11/163 [=>............................] - ETA: 12s - loss: 0.6927 - accuracy: 0.502 13/163 [=>............................] - ETA: 11s - loss: 0.6926 - accuracy: 0.512 14/163 [=>............................] - ETA: 11s - loss: 0.6923 - accuracy: 0.522 17/163 [==>...........................] - ETA: 9s - loss: 0.6922 - accuracy: 0.52 18/163 [==>...........................] - ETA: 9s - loss: 0.6922 - accuracy: 0.52 20/163 [==>...........................] - ETA: 8s - loss: 0.6926 - accuracy: 0.51 21/163 [==>...........................] - ETA: 8s - loss: 0.6927 - accuracy: 0.50 22/163 [===>..........................] - ETA: 8s - loss: 0.6927 - accuracy: 0.50 24/163 [===>..........................] - ETA: 8s - loss: 0.6927 - accuracy: 0.51 25/163 [===>..........................] - ETA: 8s - loss: 0.6926 - accuracy: 0.51 26/163 [===>..........................] - ETA: 8s - loss: 0.6926 - accuracy: 0.51 27/163 [===>..........................] - ETA: 8s - loss: 0.6926 - accuracy: 0.51 28/163 [====>.........................] - ETA: 8s - loss: 0.6926 - accuracy: 0.51 29/163 [====>.........................] - ETA: 8s - loss: 0.6926 - accuracy: 0.51 30/163 [====>.........................] - ETA: 8s - loss: 0.6925 - accuracy: 0.51 32/163 [====>.........................] - ETA: 7s - loss: 0.6925 - accuracy: 0.52 33/163 [=====>........................] - ETA: 7s - loss: 0.6924 - accuracy: 0.52 35/163 [=====>........................] - ETA: 7s - loss: 0.6924 - accuracy: 0.52 36/163 [=====>........................] - ETA: 7s - loss: 0.6924 - accuracy: 0.52 37/163 [=====>........................] - ETA: 7s - loss: 0.6925 - accuracy: 0.52 38/163 [=====>........................] - ETA: 7s - loss: 0.6924 - accuracy: 0.52 39/163 [======>.......................] - ETA: 7s - loss: 0.6925 - accuracy: 0.52 42/163 [======>.......................] - ETA: 6s - loss: 0.6926 - accuracy: 0.52 44/163 [=======>......................] - ETA: 6s - loss: 0.6926 - accuracy: 0.51 46/163 [=======>......................] - ETA: 6s - loss: 0.6926 - accuracy: 0.51 47/163 [=======>......................] - ETA: 6s - loss: 0.6926 - accuracy: 0.51 49/163 [========>.....................] - ETA: 6s - loss: 0.6926 - accuracy: 0.51 51/163 [========>.....................] - ETA: 5s - loss: 0.6925 - accuracy: 0.52 52/163 [========>.....................] - ETA: 5s - loss: 0.6926 - accuracy: 0.51 53/163 [========>.....................] - ETA: 5s - loss: 0.6925 - accuracy: 0.52 54/163 [========>.....................] - ETA: 5s - loss: 0.6926 - accuracy: 0.51 55/163 [=========>....................] - ETA: 5s - loss: 0.6926 - accuracy: 0.51 56/163 [=========>....................] - ETA: 5s - loss: 0.6926 - accuracy: 0.51 58/163 [=========>....................] - ETA: 5s - loss: 0.6926 - accuracy: 0.51 59/163 [=========>....................] - ETA: 5s - loss: 0.6925 - accuracy: 0.51 60/163 [==========>...................] - ETA: 5s - loss: 0.6926 - accuracy: 0.51 61/163 [==========>...................] - ETA: 5s - loss: 0.6925 - accuracy: 0.51 63/163 [==========>...................] - ETA: 5s - loss: 0.6925 - accuracy: 0.51 65/163 [==========>...................] - ETA: 5s - loss: 0.6924 - accuracy: 0.52 67/163 [===========>..................] - ETA: 5s - loss: 0.6923 - accuracy: 0.52 68/163 [===========>..................] - ETA: 5s - loss: 0.6923 - accuracy: 0.52 72/163 [============>.................] - ETA: 4s - loss: 0.6922 - accuracy: 0.51 75/163 [============>.................] - ETA: 4s - loss: 0.6926 - accuracy: 0.51 77/163 [=============>................] - ETA: 4s - loss: 0.6925 - accuracy: 0.51 82/163 [==============>...............] - ETA: 3s - loss: 0.6924 - accuracy: 0.51 85/163 [==============>...............] - ETA: 3s - loss: 0.6922 - accuracy: 0.51 87/163 [===============>..............] - ETA: 3s - loss: 0.6922 - accuracy: 0.52 92/163 [===============>..............] - ETA: 3s - loss: 0.6922 - accuracy: 0.51 97/163 [================>.............] - ETA: 2s - loss: 0.6922 - accuracy: 0.51 98/163 [=================>............] - ETA: 2s - loss: 0.6922 - accuracy: 0.51101/163 [=================>............] - ETA: 2s - loss: 0.6921 - accuracy: 0.52102/163 [=================>............] - ETA: 2s - loss: 0.6921 - accuracy: 0.52104/163 [==================>...........] - ETA: 2s - loss: 0.6920 - accuracy: 0.52105/163 [==================>...........] - ETA: 2s - loss: 0.6920 - accuracy: 0.52106/163 [==================>...........] - ETA: 2s - loss: 0.6920 - accuracy: 0.52108/163 [==================>...........] - ETA: 2s - loss: 0.6921 - accuracy: 0.52114/163 [===================>..........] - ETA: 1s - loss: 0.6921 - accuracy: 0.52117/163 [====================>.........] - ETA: 1s - loss: 0.6921 - accuracy: 0.52122/163 [=====================>........] - ETA: 1s - loss: 0.6923 - accuracy: 0.51123/163 [=====================>........] - ETA: 1s - loss: 0.6922 - accuracy: 0.51124/163 [=====================>........] - ETA: 1s - loss: 0.6923 - accuracy: 0.51125/163 [======================>.......] - ETA: 1s - loss: 0.6924 - accuracy: 0.51128/163 [======================>.......] - ETA: 1s - loss: 0.6924 - accuracy: 0.51130/163 [======================>.......] - ETA: 1s - loss: 0.6924 - accuracy: 0.51132/163 [=======================>......] - ETA: 1s - loss: 0.6923 - accuracy: 0.51135/163 [=======================>......] - ETA: 1s - loss: 0.6923 - accuracy: 0.51137/163 [========================>.....] - ETA: 0s - loss: 0.6923 - accuracy: 0.51138/163 [========================>.....] - ETA: 0s - loss: 0.6924 - accuracy: 0.51139/163 [========================>.....] - ETA: 0s - loss: 0.6924 - accuracy: 0.51140/163 [========================>.....] - ETA: 0s - loss: 0.6924 - accuracy: 0.51143/163 [=========================>....] - ETA: 0s - loss: 0.6924 - accuracy: 0.51148/163 [==========================>...] - ETA: 0s - loss: 0.6925 - accuracy: 0.51149/163 [==========================>...] - ETA: 0s - loss: 0.6925 - accuracy: 0.51150/163 [==========================>...] - ETA: 0s - loss: 0.6925 - accuracy: 0.51151/163 [==========================>...] - ETA: 0s - loss: 0.6925 - accuracy: 0.51154/163 [===========================>..] - ETA: 0s - loss: 0.6924 - accuracy: 0.51155/163 [===========================>..] - ETA: 0s - loss: 0.6924 - accuracy: 0.51156/163 [===========================>..] - ETA: 0s - loss: 0.6924 - accuracy: 0.51157/163 [===========================>..] - ETA: 0s - loss: 0.6925 - accuracy: 0.51159/163 [============================>.] - ETA: 0s - loss: 0.6924 - accuracy: 0.51161/163 [============================>.] - ETA: 0s - loss: 0.6924 - accuracy: 0.51163/163 [==============================] - ETA: 0s - loss: 0.6924 - accuracy: 0.51163/163 [==============================] - 8s 47ms/step - loss: 0.6924 - accuracy: 0.5188 - val_loss: 0.6932 - val_accuracy: 0.4984\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: 1dde377320f392d570944fb04686125a</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.5033587217330933</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-n_layers: 7</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-n_nodes: 9</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ccuracy: 0.5015 - val_loss: 0.6931 - val_accuracy: 0.5083\nEpoch 3/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6931 - accuracy: 0.50  3/163 [..............................] - ETA: 6s - loss: 0.6929 - accuracy: 0.46  4/163 [..............................] - ETA: 9s - loss: 0.6927 - accuracy: 0.48  7/163 [>.............................] - ETA: 6s - loss: 0.6928 - accuracy: 0.49  9/163 [>.............................] - ETA: 6s - loss: 0.6930 - accuracy: 0.49 10/163 [>.............................] - ETA: 6s - loss: 0.6932 - accuracy: 0.48 11/163 [=>............................] - ETA: 7s - loss: 0.6933 - accuracy: 0.49 12/163 [=>............................] - ETA: 7s - loss: 0.6933 - accuracy: 0.48 13/163 [=>............................] - ETA: 7s - loss: 0.6932 - accuracy: 0.48 14/163 [=>............................] - ETA: 7s - loss: 0.6931 - accuracy: 0.48 15/163 [=>............................] - ETA: 7s - loss: 0.6930 - accuracy: 0.49 16/163 [=>............................] - ETA: 7s - loss: 0.6933 - accuracy: 0.48 18/163 [==>...........................] - ETA: 7s - loss: 0.6932 - accuracy: 0.48 19/163 [==>...........................] - ETA: 7s - loss: 0.6932 - accuracy: 0.48 21/163 [==>...........................] - ETA: 7s - loss: 0.6931 - accuracy: 0.49 22/163 [===>..........................] - ETA: 7s - loss: 0.6934 - accuracy: 0.48 25/163 [===>..........................] - ETA: 6s - loss: 0.6932 - accuracy: 0.48 26/163 [===>..........................] - ETA: 7s - loss: 0.6932 - accuracy: 0.48 27/163 [===>..........................] - ETA: 7s - loss: 0.6931 - accuracy: 0.49 28/163 [====>.........................] - ETA: 7s - loss: 0.6931 - accuracy: 0.49 30/163 [====>.........................] - ETA: 6s - loss: 0.6931 - accuracy: 0.49 31/163 [====>.........................] - ETA: 7s - loss: 0.6931 - accuracy: 0.49 33/163 [=====>........................] - ETA: 6s - loss: 0.6931 - accuracy: 0.49 35/163 [=====>........................] - ETA: 6s - loss: 0.6931 - accuracy: 0.49 37/163 [=====>........................] - ETA: 6s - loss: 0.6931 - accuracy: 0.50 38/163 [=====>........................] - ETA: 6s - loss: 0.6931 - accuracy: 0.50 40/163 [======>.......................] - ETA: 6s - loss: 0.6932 - accuracy: 0.50 41/163 [======>.......................] - ETA: 6s - loss: 0.6932 - accuracy: 0.50 42/163 [======>.......................] - ETA: 6s - loss: 0.6932 - accuracy: 0.50 43/163 [======>.......................] - ETA: 6s - loss: 0.6932 - accuracy: 0.50 44/163 [=======>......................] - ETA: 6s - loss: 0.6932 - accuracy: 0.50 45/163 [=======>......................] - ETA: 6s - loss: 0.6931 - accuracy: 0.50 47/163 [=======>......................] - ETA: 6s - loss: 0.6931 - accuracy: 0.50 48/163 [=======>......................] - ETA: 6s - loss: 0.6932 - accuracy: 0.50 50/163 [========>.....................] - ETA: 6s - loss: 0.6931 - accuracy: 0.51 51/163 [========>.....................] - ETA: 6s - loss: 0.6931 - accuracy: 0.51 53/163 [========>.....................] - ETA: 5s - loss: 0.6931 - accuracy: 0.51 54/163 [========>.....................] - ETA: 5s - loss: 0.6930 - accuracy: 0.51 55/163 [=========>....................] - ETA: 5s - loss: 0.6930 - accuracy: 0.51 58/163 [=========>....................] - ETA: 5s - loss: 0.6931 - accuracy: 0.50 62/163 [==========>...................] - ETA: 5s - loss: 0.6930 - accuracy: 0.51 66/163 [===========>..................] - ETA: 4s - loss: 0.6930 - accuracy: 0.51 73/163 [============>.................] - ETA: 3s - loss: 0.6930 - accuracy: 0.51 75/163 [============>.................] - ETA: 3s - loss: 0.6930 - accuracy: 0.51 77/163 [=============>................] - ETA: 3s - loss: 0.6929 - accuracy: 0.51 79/163 [=============>................] - ETA: 3s - loss: 0.6929 - accuracy: 0.51 83/163 [==============>...............] - ETA: 3s - loss: 0.6930 - accuracy: 0.51 86/163 [==============>...............] - ETA: 3s - loss: 0.6930 - accuracy: 0.51 88/163 [===============>..............] - ETA: 3s - loss: 0.6930 - accuracy: 0.51 93/163 [================>.............] - ETA: 2s - loss: 0.6930 - accuracy: 0.51 95/163 [================>.............] - ETA: 2s - loss: 0.6930 - accuracy: 0.50101/163 [=================>............] - ETA: 2s - loss: 0.6930 - accuracy: 0.51108/163 [==================>...........] - ETA: 1s - loss: 0.6930 - accuracy: 0.51111/163 [===================>..........] - ETA: 1s - loss: 0.6929 - accuracy: 0.51113/163 [===================>..........] - ETA: 1s - loss: 0.6929 - accuracy: 0.51118/163 [====================>.........] - ETA: 1s - loss: 0.6929 - accuracy: 0.51120/163 [=====================>........] - ETA: 1s - loss: 0.6929 - accuracy: 0.51124/163 [=====================>........] - ETA: 1s - loss: 0.6928 - accuracy: 0.51126/163 [======================>.......] - ETA: 1s - loss: 0.6928 - accuracy: 0.51127/163 [======================>.......] - ETA: 1s - loss: 0.6928 - accuracy: 0.51128/163 [======================>.......] - ETA: 1s - loss: 0.6928 - accuracy: 0.51129/163 [======================>.......] - ETA: 1s - loss: 0.6927 - accuracy: 0.51131/163 [=======================>......] - ETA: 1s - loss: 0.6928 - accuracy: 0.51132/163 [=======================>......] - ETA: 1s - loss: 0.6927 - accuracy: 0.51133/163 [=======================>......] - ETA: 1s - loss: 0.6927 - accuracy: 0.51136/163 [========================>.....] - ETA: 0s - loss: 0.6927 - accuracy: 0.51137/163 [========================>.....] - ETA: 0s - loss: 0.6927 - accuracy: 0.51139/163 [========================>.....] - ETA: 0s - loss: 0.6928 - accuracy: 0.51142/163 [=========================>....] - ETA: 0s - loss: 0.6927 - accuracy: 0.51144/163 [=========================>....] - ETA: 0s - loss: 0.6928 - accuracy: 0.51146/163 [=========================>....] - ETA: 0s - loss: 0.6927 - accuracy: 0.51147/163 [==========================>...] - ETA: 0s - loss: 0.6927 - accuracy: 0.51148/163 [==========================>...] - ETA: 0s - loss: 0.6926 - accuracy: 0.51150/163 [==========================>...] - ETA: 0s - loss: 0.6929 - accuracy: 0.51151/163 [==========================>...] - ETA: 0s - loss: 0.6929 - accuracy: 0.51152/163 [==========================>...] - ETA: 0s - loss: 0.6929 - accuracy: 0.51153/163 [===========================>..] - ETA: 0s - loss: 0.6929 - accuracy: 0.51154/163 [===========================>..] - ETA: 0s - loss: 0.6929 - accuracy: 0.51155/163 [===========================>..] - ETA: 0s - loss: 0.6930 - accuracy: 0.51156/163 [===========================>..] - ETA: 0s - loss: 0.6930 - accuracy: 0.51157/163 [===========================>..] - ETA: 0s - loss: 0.6930 - accuracy: 0.51158/163 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.51160/163 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.51163/163 [==============================] - 7s 41ms/step - loss: 0.6929 - accuracy: 0.5107 - val_loss: 0.6934 - val_accuracy: 0.5074\nEpoch 4/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6875 - accuracy: 0.62  2/163 [..............................] - ETA: 4s - loss: 0.6879 - accuracy: 0.60  4/163 [..............................] - ETA: 4s - loss: 0.6892 - accuracy: 0.56  6/163 [>.............................] - ETA: 4s - loss: 0.6891 - accuracy: 0.54  8/163 [>.............................] - ETA: 4s - loss: 0.6904 - accuracy: 0.53  9/163 [>.............................] - ETA: 5s - loss: 0.6904 - accuracy: 0.53 10/163 [>.............................] - ETA: 5s - loss: 0.6900 - accuracy: 0.55 12/163 [=>............................] - ETA: 5s - loss: 0.6910 - accuracy: 0.53 13/163 [=>............................] - ETA: 5s - loss: 0.6909 - accuracy: 0.53 15/163 [=>............................] - ETA: 5s - loss: 0.6905 - accuracy: 0.53 19/163 [==>...........................] - ETA: 4s - loss: 0.6907 - accuracy: 0.52 21/163 [==>...........................] - ETA: 4s - loss: 0.6908 - accuracy: 0.52 24/163 [===>..........................] - ETA: 4s - loss: 0.6910 - accuracy: 0.51 27/163 [===>..........................] - ETA: 4s - loss: 0.6911 - accuracy: 0.52 29/163 [====>.........................] - ETA: 4s - loss: 0.6915 - accuracy: 0.52 32/163 [====>.........................] - ETA: 3s - loss: 0.6918 - accuracy: 0.51 35/163 [=====>........................] - ETA: 3s - loss: 0.6919 - accuracy: 0.51 37/163 [=====>........................] - ETA: 3s - loss: 0.6918 - accuracy: 0.51 41/163 [======>.......................] - ETA: 3s - loss: 0.6919 - accuracy: 0.51 42/163 [======>.......................] - ETA: 3s - loss: 0.6918 - accuracy: 0.51 44/163 [=======>......................] - ETA: 3s - loss: 0.6921 - accuracy: 0.50 45/163 [=======>......................] - ETA: 3s - loss: 0.6921 - accuracy: 0.50 47/163 [=======>......................] - ETA: 3s - loss: 0.6925 - accuracy: 0.50 51/163 [========>.....................] - ETA: 3s - loss: 0.6926 - accuracy: 0.49 53/163 [========>.....................] - ETA: 3s - loss: 0.6925 - accuracy: 0.50 54/163 [========>.....................] - ETA: 3s - loss: 0.6925 - accuracy: 0.50 56/163 [=========>....................] - ETA: 3s - loss: 0.6925 - accuracy: 0.50 58/163 [=========>....................] - ETA: 3s - loss: 0.6924 - accuracy: 0.50 64/163 [==========>...................] - ETA: 2s - loss: 0.6923 - accuracy: 0.51 66/163 [===========>..................] - ETA: 2s - loss: 0.6925 - accuracy: 0.50 72/163 [============>.................] - ETA: 2s - loss: 0.6924 - accuracy: 0.51 80/163 [=============>................] - ETA: 2s - loss: 0.6923 - accuracy: 0.50 85/163 [==============>...............] - ETA: 1s - loss: 0.6924 - accuracy: 0.50 87/163 [===============>..............] - ETA: 1s - loss: 0.6922 - accuracy: 0.51 91/163 [===============>..............] - ETA: 1s - loss: 0.6921 - accuracy: 0.51 92/163 [===============>..............] - ETA: 1s - loss: 0.6921 - accuracy: 0.51 97/163 [================>.............] - ETA: 1s - loss: 0.6921 - accuracy: 0.51 98/163 [=================>............] - ETA: 1s - loss: 0.6922 - accuracy: 0.51101/163 [=================>............] - ETA: 1s - loss: 0.6922 - accuracy: 0.51103/163 [=================>............] - ETA: 1s - loss: 0.6924 - accuracy: 0.51108/163 [==================>...........] - ETA: 1s - loss: 0.6925 - accuracy: 0.51110/163 [===================>..........] - ETA: 1s - loss: 0.6925 - accuracy: 0.51114/163 [===================>..........] - ETA: 1s - loss: 0.6927 - accuracy: 0.50117/163 [====================>.........] - ETA: 1s - loss: 0.6927 - accuracy: 0.50119/163 [====================>.........] - ETA: 1s - loss: 0.6927 - accuracy: 0.50122/163 [=====================>........] - ETA: 0s - loss: 0.6927 - accuracy: 0.51124/163 [=====================>........] - ETA: 0s - loss: 0.6927 - accuracy: 0.51127/163 [======================>.......] - ETA: 0s - loss: 0.6927 - accuracy: 0.50128/163 [======================>.......] - ETA: 0s - loss: 0.6927 - accuracy: 0.50131/163 [=======================>......] - ETA: 0s - loss: 0.6928 - accuracy: 0.50134/163 [=======================>......] - ETA: 0s - loss: 0.6928 - accuracy: 0.50135/163 [=======================>......] - ETA: 0s - loss: 0.6928 - accuracy: 0.50137/163 [========================>.....] - ETA: 0s - loss: 0.6928 - accuracy: 0.50139/163 [========================>.....] - ETA: 0s - loss: 0.6927 - accuracy: 0.50141/163 [========================>.....] - ETA: 0s - loss: 0.6927 - accuracy: 0.50142/163 [=========================>....] - ETA: 0s - loss: 0.6928 - accuracy: 0.50144/163 [=========================>....] - ETA: 0s - loss: 0.6928 - accuracy: 0.50147/163 [==========================>...] - ETA: 0s - loss: 0.6928 - accuracy: 0.50149/163 [==========================>...] - ETA: 0s - loss: 0.6928 - accuracy: 0.50150/163 [==========================>...] - ETA: 0s - loss: 0.6927 - accuracy: 0.50151/163 [==========================>...] - ETA: 0s - loss: 0.6928 - accuracy: 0.50152/163 [==========================>...] - ETA: 0s - loss: 0.6928 - accuracy: 0.50153/163 [===========================>..] - ETA: 0s - loss: 0.6928 - accuracy: 0.50159/163 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.50162/163 [============================>.] - ETA: 0s - loss: 0.6928 - accuracy: 0.50163/163 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.50163/163 [==============================] - 6s 34ms/step - loss: 0.6928 - accuracy: 0.5073 - val_loss: 0.6936 - val_accuracy: 0.4922\nEpoch 5/5\n  1/163 [..............................] - ETA: 0s - loss: 0.6942 - accuracy: 0.50  2/163 [..............................] - ETA: 6s - loss: 0.6926 - accuracy: 0.51  4/163 [..............................] - ETA: 6s - loss: 0.6913 - accuracy: 0.52  6/163 [>.............................] - ETA: 5s - loss: 0.6914 - accuracy: 0.51  8/163 [>.............................] - ETA: 5s - loss: 0.6899 - accuracy: 0.53  9/163 [>.............................] - ETA: 5s - loss: 0.6908 - accuracy: 0.51 10/163 [>.............................] - ETA: 5s - loss: 0.6917 - accuracy: 0.51 12/163 [=>............................] - ETA: 5s - loss: 0.6920 - accuracy: 0.52 15/163 [=>............................] - ETA: 5s - loss: 0.6919 - accuracy: 0.52 18/163 [==>...........................] - ETA: 4s - loss: 0.6919 - accuracy: 0.52 21/163 [==>...........................] - ETA: 4s - loss: 0.6916 - accuracy: 0.53 24/163 [===>..........................] - ETA: 4s - loss: 0.6911 - accuracy: 0.54 25/163 [===>..........................] - ETA: 4s - loss: 0.6912 - accuracy: 0.53 26/163 [===>..........................] - ETA: 4s - loss: 0.6911 - accuracy: 0.53 27/163 [===>..........................] - ETA: 5s - loss: 0.6905 - accuracy: 0.53 28/163 [====>.........................] - ETA: 5s - loss: 0.6905 - accuracy: 0.53 29/163 [====>.........................] - ETA: 5s - loss: 0.6909 - accuracy: 0.52 32/163 [====>.........................] - ETA: 5s - loss: 0.6907 - accuracy: 0.52 33/163 [=====>........................] - ETA: 5s - loss: 0.6907 - accuracy: 0.52 34/163 [=====>........................] - ETA: 5s - loss: 0.6906 - accuracy: 0.52 36/163 [=====>........................] - ETA: 5s - loss: 0.6910 - accuracy: 0.52 40/163 [======>.......................] - ETA: 5s - loss: 0.6913 - accuracy: 0.52 46/163 [=======>......................] - ETA: 4s - loss: 0.6908 - accuracy: 0.52 48/163 [=======>......................] - ETA: 4s - loss: 0.6911 - accuracy: 0.52 49/163 [========>.....................] - ETA: 4s - loss: 0.6911 - accuracy: 0.52 50/163 [========>.....................] - ETA: 4s - loss: 0.6912 - accuracy: 0.52 51/163 [========>.....................] - ETA: 4s - loss: 0.6913 - accuracy: 0.52 52/163 [========>.....................] - ETA: 4s - loss: 0.6914 - accuracy: 0.52 58/163 [=========>....................] - ETA: 3s - loss: 0.6912 - accuracy: 0.52 60/163 [==========>...................] - ETA: 3s - loss: 0.6910 - accuracy: 0.52 61/163 [==========>...................] - ETA: 3s - loss: 0.6909 - accuracy: 0.52 62/163 [==========>...................] - ETA: 3s - loss: 0.6910 - accuracy: 0.52 63/163 [==========>...................] - ETA: 3s - loss: 0.6911 - accuracy: 0.52 64/163 [==========>...................] - ETA: 3s - loss: 0.6911 - accuracy: 0.52 65/163 [==========>...................] - ETA: 4s - loss: 0.6911 - accuracy: 0.52 66/163 [===========>..................] - ETA: 4s - loss: 0.6909 - accuracy: 0.52 67/163 [===========>..................] - ETA: 4s - loss: 0.6909 - accuracy: 0.52 68/163 [===========>..................] - ETA: 4s - loss: 0.6909 - accuracy: 0.52 69/163 [===========>..................] - ETA: 4s - loss: 0.6909 - accuracy: 0.52 70/163 [===========>..................] - ETA: 4s - loss: 0.6910 - accuracy: 0.52 76/163 [============>.................] - ETA: 3s - loss: 0.6911 - accuracy: 0.52 78/163 [=============>................] - ETA: 3s - loss: 0.6911 - accuracy: 0.52 81/163 [=============>................] - ETA: 3s - loss: 0.6911 - accuracy: 0.52 83/163 [==============>...............] - ETA: 3s - loss: 0.6912 - accuracy: 0.52 84/163 [==============>...............] - ETA: 3s - loss: 0.6911 - accuracy: 0.52 85/163 [==============>...............] - ETA: 3s - loss: 0.6910 - accuracy: 0.52 86/163 [==============>...............] - ETA: 3s - loss: 0.6910 - accuracy: 0.52 90/163 [===============>..............] - ETA: 2s - loss: 0.6908 - accuracy: 0.52 92/163 [===============>..............] - ETA: 2s - loss: 0.6909 - accuracy: 0.52 95/163 [================>.............] - ETA: 2s - loss: 0.6912 - accuracy: 0.52 97/163 [================>.............] - ETA: 2s - loss: 0.6912 - accuracy: 0.52 98/163 [=================>............] - ETA: 2s - loss: 0.6913 - accuracy: 0.52100/163 [=================>............] - ETA: 2s - loss: 0.6912 - accuracy: 0.52103/163 [=================>............] - ETA: 2s - loss: 0.6912 - accuracy: 0.52104/163 [==================>...........] - ETA: 2s - loss: 0.6911 - accuracy: 0.52105/163 [==================>...........] - ETA: 2s - loss: 0.6910 - accuracy: 0.52106/163 [==================>...........] - ETA: 2s - loss: 0.6909 - accuracy: 0.52108/163 [==================>...........] - ETA: 2s - loss: 0.6908 - accuracy: 0.53109/163 [===================>..........] - ETA: 2s - loss: 0.6908 - accuracy: 0.53111/163 [===================>..........] - ETA: 2s - loss: 0.6907 - accuracy: 0.53113/163 [===================>..........] - ETA: 2s - loss: 0.6908 - accuracy: 0.52114/163 [===================>..........] - ETA: 1s - loss: 0.6908 - accuracy: 0.53115/163 [====================>.........] - ETA: 1s - loss: 0.6912 - accuracy: 0.52116/163 [====================>.........] - ETA: 1s - loss: 0.6910 - accuracy: 0.52117/163 [====================>.........] - ETA: 1s - loss: 0.6910 - accuracy: 0.52118/163 [====================>.........] - ETA: 1s - loss: 0.6910 - accuracy: 0.52119/163 [====================>.........] - ETA: 1s - loss: 0.6910 - accuracy: 0.53120/163 [=====================>........] - ETA: 1s - loss: 0.6911 - accuracy: 0.53124/163 [=====================>........] - ETA: 1s - loss: 0.6912 - accuracy: 0.53125/163 [======================>.......] - ETA: 1s - loss: 0.6913 - accuracy: 0.53128/163 [======================>.......] - ETA: 1s - loss: 0.6913 - accuracy: 0.52130/163 [======================>.......] - ETA: 1s - loss: 0.6912 - accuracy: 0.52131/163 [=======================>......] - ETA: 1s - loss: 0.6913 - accuracy: 0.52132/163 [=======================>......] - ETA: 1s - loss: 0.6912 - accuracy: 0.52133/163 [=======================>......] - ETA: 1s - loss: 0.6911 - accuracy: 0.52135/163 [=======================>......] - ETA: 1s - loss: 0.6910 - accuracy: 0.53137/163 [========================>.....] - ETA: 1s - loss: 0.6909 - accuracy: 0.53140/163 [========================>.....] - ETA: 0s - loss: 0.6911 - accuracy: 0.52141/163 [========================>.....] - ETA: 0s - loss: 0.6911 - accuracy: 0.52142/163 [=========================>....] - ETA: 0s - loss: 0.6912 - accuracy: 0.52143/163 [=========================>....] - ETA: 0s - loss: 0.6913 - accuracy: 0.52151/163 [==========================>...] - ETA: 0s - loss: 0.6912 - accuracy: 0.52152/163 [==========================>...] - ETA: 0s - loss: 0.6913 - accuracy: 0.52153/163 [===========================>..] - ETA: 0s - loss: 0.6912 - accuracy: 0.52154/163 [===========================>..] - ETA: 0s - loss: 0.6913 - accuracy: 0.52158/163 [============================>.] - ETA: 0s - loss: 0.6914 - accuracy: 0.52159/163 [============================>.] - ETA: 0s - loss: 0.6914 - accuracy: 0.52162/163 [============================>.] - ETA: 0s - loss: 0.6913 - accuracy: 0.52163/163 [==============================] - ETA: 0s - loss: 0.6913 - accuracy: 0.52163/163 [==============================] - 8s 48ms/step - loss: 0.6913 - accuracy: 0.5282 - val_loss: 0.6944 - val_accuracy: 0.5047\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: 8a425123e9471f3e148882dca84636aa</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.5082848072052002</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-n_layers: 5</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-n_nodes: 8</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Oracle triggered exit\n"
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y/%m/%d-%H:%M:%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "tuner.search(preprocessed,\n",
    "y_bin,\n",
    "validation_split=0.3,\n",
    "epochs=5,\n",
    "batch_size=32,\n",
    "callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597795312217",
   "display_name": "Python 3.8.3 64-bit ('PHD': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}